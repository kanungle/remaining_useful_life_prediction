{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e63857-3eed-4a1e-af2f-df12e1807bb7",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac2d5b02-6443-454c-a886-4ad0828677ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f08d588-3d34-4284-82fe-32b2055f4827",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0c51c7a7-a209-4499-8158-d868c42fc8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Train Data Shape: (17731, 30, 14)\n",
      "Processed Train Target Shape: (17731,)\n",
      "Processed Test Data Shape: (100, 30, 14)\n",
      "True RUL Shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "# define the directory where the pickle files are stored\n",
    "folder_path = '../batched_data_pickle_files/'\n",
    "\n",
    "# define the filenames for the pickle files\n",
    "file_names = ['processed_train_data.pkl', 'processed_train_targets.pkl', 'processed_test_data.pkl', 'true_rul.pkl']\n",
    "\n",
    "# loop through each file and load its contents as arrays\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # read the pickle file\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    \n",
    "    # ensure data is a numpy array, if not convert it\n",
    "    if isinstance(data, np.ndarray):\n",
    "        globals()[file_name.replace('.pkl', '')] = data\n",
    "    else:\n",
    "        globals()[file_name.replace('.pkl', '')] = np.array(data)\n",
    "\n",
    "print(\"Processed Train Data Shape:\", processed_train_data.shape)\n",
    "print(\"Processed Train Target Shape:\", processed_train_targets.shape)\n",
    "print(\"Processed Test Data Shape:\", processed_test_data.shape)\n",
    "print(\"True RUL Shape:\", true_rul.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9245711c-852c-489a-bc53-5f8f24250693",
   "metadata": {},
   "source": [
    "## Process Datasets and Build SDAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "56943503-d169-4fa6-ae1a-8ffb73b9015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we assign the processed data to X and y\n",
    "# X contains the features (input data) and y contains the target variable (processed_train_targets)\n",
    "X = processed_train_data\n",
    "y = processed_train_targets\n",
    "\n",
    "# convert the numpy arrays to PyTorch tensors, since PyTorch models expect inputs as tensors\n",
    "X_tensor = torch.FloatTensor(X)\n",
    "y_tensor = torch.FloatTensor(y)\n",
    "\n",
    "# split the data into training and validation sets\n",
    "# here, we use sklearn's train_test_split to create a training set and a validation set\n",
    "# 80% of the data goes into the training set, and 20% goes into the validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# create DataLoader objects to handle batching during training and evaluation\n",
    "# DataLoader is used to load data in batches during training, which is more memory-efficient and faster\n",
    "# here, we create datasets using TensorDataset, which combines input (X) and target (y) tensors into a dataset\n",
    "# then, we create the DataLoader objects, specifying batch sizes and whether to shuffle the data\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)  # create training dataset\n",
    "val_dataset = TensorDataset(X_val, y_val)  # create validation dataset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)  # shuffle for training set to ensure randomness\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)  # no shuffling for validation set\n",
    "\n",
    "# define the Stacked Denoising Autoencoder (SDAE) model class\n",
    "# SDAE is a type of autoencoder that adds noise to the input during training and forces the network to denoise it\n",
    "# this helps the model learn more robust features and avoid overfitting\n",
    "\n",
    "class SDAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, dropout_rate):\n",
    "        super(SDAE, self).__init__()\n",
    "\n",
    "        # input_dim is the number of features in the input data\n",
    "        # hidden_dims is a list of integers representing the size of each hidden layer in the encoder/decoder\n",
    "        # dropout_rate is the dropout probability to prevent overfitting\n",
    "\n",
    "        self.input_dim = input_dim  # save input dimension for reference\n",
    "        self.hidden_dims = hidden_dims  # save hidden layer dimensions for reference\n",
    "\n",
    "        # initialize the encoder layers\n",
    "        # the encoder maps the input data to a smaller representation (latent space)\n",
    "        encoder_layers = []\n",
    "        for i in range(len(hidden_dims)):\n",
    "            # the first layer will take the input data, the rest will take the output of the previous layer\n",
    "            if i == 0:\n",
    "                encoder_layers.append(nn.Linear(input_dim, hidden_dims[i]))  # fully connected layer\n",
    "            else:\n",
    "                encoder_layers.append(nn.Linear(hidden_dims[i-1], hidden_dims[i]))  # another fully connected layer\n",
    "            encoder_layers.append(nn.ReLU())  # apply ReLU activation after each layer\n",
    "            encoder_layers.append(nn.Dropout(dropout_rate))  # apply dropout after each layer for regularization\n",
    "\n",
    "        # define the encoder as a sequence of layers\n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "\n",
    "        # initialize the decoder layers\n",
    "        # the decoder takes the encoded (compressed) representation and reconstructs the input data\n",
    "        decoder_layers = []\n",
    "        for i in range(len(hidden_dims)-1, -1, -1):\n",
    "            # reverse the encoder layers to reconstruct the data\n",
    "            if i == 0:\n",
    "                decoder_layers.append(nn.Linear(hidden_dims[i], input_dim))  # final layer to map to input dimension\n",
    "            else:\n",
    "                decoder_layers.append(nn.Linear(hidden_dims[i], hidden_dims[i-1]))  # intermediate layers\n",
    "            decoder_layers.append(nn.ReLU())  # ReLU activation after each layer\n",
    "            decoder_layers.append(nn.Dropout(dropout_rate))  # dropout for regularization\n",
    "\n",
    "        # define the decoder as a sequence of layers\n",
    "        self.decoder = nn.Sequential(*decoder_layers)\n",
    "\n",
    "        # define the predictor (regressor)\n",
    "        # the predictor will take the output of the encoder and map it to a single value (the predicted RUL)\n",
    "        self.predictor = nn.Linear(hidden_dims[-1], 1)  # output layer with a single unit (for regression)\n",
    "\n",
    "    # the forward method defines the forward pass of the network\n",
    "    def forward(self, x):\n",
    "        # flatten the input data to a 2D tensor of shape [batch_size, input_dim]\n",
    "        # this is necessary because the Linear layers expect 2D input (batch_size x features)\n",
    "        x = x.view(x.size(0), -1)  # flatten the input (keeping the batch size dimension intact)\n",
    "\n",
    "        # pass the input through the encoder to get the encoded (latent) representation\n",
    "        encoded = self.encoder(x)\n",
    "\n",
    "        # pass the encoded representation through the decoder to reconstruct the input (for autoencoding)\n",
    "        decoded = self.decoder(encoded)\n",
    "\n",
    "        # pass the encoded representation through the predictor to get the predicted RUL\n",
    "        prediction = self.predictor(encoded)\n",
    "\n",
    "        # return both the reconstructed input (for training the autoencoder) and the predicted RUL\n",
    "        return decoded, prediction.squeeze()  # squeeze to remove the extra dimension from the output\n",
    "\n",
    "# define a function to add noise to the input data\n",
    "# this is part of the denoising autoencoder approach\n",
    "# the idea is to train the model to reconstruct the original input from noisy data, making it more robust\n",
    "def add_noise(x, noise_factor=0.3):\n",
    "    # generate random noise with the same shape as the input x\n",
    "    noise = torch.randn_like(x) * noise_factor\n",
    "    # add the noise to the input data and return the noisy version\n",
    "    return x + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdd60e5-9f10-42f7-a775-0d6c605a1055",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bde8fcdb-9251-4d9f-a85c-e985afe3787f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-14 04:04:56,892] A new study created in memory with name: no-name-3b6a0f5b-ac39-493f-a284-b8b3457e4fe7\n",
      "/tmp/ipykernel_155328/2588598532.py:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.3)\n",
      "/tmp/ipykernel_155328/2588598532.py:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
      "[I 2024-11-14 04:05:13,336] Trial 0 finished with value: 16.609278917312622 and parameters: {'hidden_dim_1': 160, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.15922720170060026, 'learning_rate': 0.00022075549335688925}. Best is trial 0 with value: 16.609278917312622.\n",
      "[I 2024-11-14 04:05:31,304] Trial 1 finished with value: 15.158706222261701 and parameters: {'hidden_dim_1': 224, 'hidden_dim_2': 96, 'hidden_dim_3': 48, 'dropout_rate': 0.09451900214052883, 'learning_rate': 0.0005878405836620545}. Best is trial 1 with value: 15.158706222261701.\n",
      "[I 2024-11-14 04:05:46,922] Trial 2 finished with value: 34.661446707589285 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 96, 'hidden_dim_3': 112, 'dropout_rate': 0.19983394685048053, 'learning_rate': 3.93465234701075e-05}. Best is trial 1 with value: 15.158706222261701.\n",
      "[I 2024-11-14 04:06:06,135] Trial 3 finished with value: 20.81656585420881 and parameters: {'hidden_dim_1': 256, 'hidden_dim_2': 128, 'hidden_dim_3': 112, 'dropout_rate': 0.2207635981964371, 'learning_rate': 6.279606036110575e-05}. Best is trial 1 with value: 15.158706222261701.\n",
      "[I 2024-11-14 04:06:23,680] Trial 4 finished with value: 26.672367777143204 and parameters: {'hidden_dim_1': 160, 'hidden_dim_2': 128, 'hidden_dim_3': 80, 'dropout_rate': 0.1737381379668925, 'learning_rate': 4.37290842255838e-05}. Best is trial 1 with value: 15.158706222261701.\n",
      "[I 2024-11-14 04:06:42,396] Trial 5 finished with value: 16.46471040589469 and parameters: {'hidden_dim_1': 256, 'hidden_dim_2': 96, 'hidden_dim_3': 48, 'dropout_rate': 0.24531519774403074, 'learning_rate': 0.0008151007908005191}. Best is trial 1 with value: 15.158706222261701.\n",
      "[I 2024-11-14 04:06:58,358] Trial 6 finished with value: 56.65990788596017 and parameters: {'hidden_dim_1': 160, 'hidden_dim_2': 32, 'hidden_dim_3': 16, 'dropout_rate': 0.011204225402667523, 'learning_rate': 1.5472137172479098e-05}. Best is trial 1 with value: 15.158706222261701.\n",
      "[I 2024-11-14 04:07:16,079] Trial 7 finished with value: 16.6771924836295 and parameters: {'hidden_dim_1': 192, 'hidden_dim_2': 96, 'hidden_dim_3': 112, 'dropout_rate': 0.1825401364969975, 'learning_rate': 0.00048420782996912517}. Best is trial 1 with value: 15.158706222261701.\n",
      "[I 2024-11-14 04:07:31,816] Trial 8 finished with value: 37.91087532043457 and parameters: {'hidden_dim_1': 128, 'hidden_dim_2': 64, 'hidden_dim_3': 16, 'dropout_rate': 0.10518633066254579, 'learning_rate': 5.894887399804114e-05}. Best is trial 1 with value: 15.158706222261701.\n",
      "[I 2024-11-14 04:07:48,559] Trial 9 finished with value: 14.73051050731114 and parameters: {'hidden_dim_1': 96, 'hidden_dim_2': 128, 'hidden_dim_3': 80, 'dropout_rate': 0.043852861400874805, 'learning_rate': 0.000676548076330385}. Best is trial 9 with value: 14.73051050731114.\n",
      "[I 2024-11-14 04:08:04,713] Trial 10 finished with value: 16.225209508623397 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 128, 'hidden_dim_3': 80, 'dropout_rate': 0.010036834324925158, 'learning_rate': 0.00021061402655104148}. Best is trial 9 with value: 14.73051050731114.\n",
      "[I 2024-11-14 04:08:21,107] Trial 11 finished with value: 15.31322547367641 and parameters: {'hidden_dim_1': 96, 'hidden_dim_2': 128, 'hidden_dim_3': 48, 'dropout_rate': 0.10389261205635944, 'learning_rate': 0.0008649199999816812}. Best is trial 9 with value: 14.73051050731114.\n",
      "[I 2024-11-14 04:08:38,979] Trial 12 finished with value: 15.083711079188756 and parameters: {'hidden_dim_1': 224, 'hidden_dim_2': 96, 'hidden_dim_3': 48, 'dropout_rate': 0.06488077897378479, 'learning_rate': 0.0002914636644137162}. Best is trial 9 with value: 14.73051050731114.\n",
      "[I 2024-11-14 04:08:54,381] Trial 13 finished with value: 15.469769171306066 and parameters: {'hidden_dim_1': 96, 'hidden_dim_2': 64, 'hidden_dim_3': 48, 'dropout_rate': 0.0562009518275699, 'learning_rate': 0.00027955231610321914}. Best is trial 9 with value: 14.73051050731114.\n",
      "[I 2024-11-14 04:09:13,301] Trial 14 finished with value: 16.829135247639247 and parameters: {'hidden_dim_1': 224, 'hidden_dim_2': 128, 'hidden_dim_3': 80, 'dropout_rate': 0.06768678086093635, 'learning_rate': 0.00013037682530789302}. Best is trial 9 with value: 14.73051050731114.\n",
      "[I 2024-11-14 04:09:29,473] Trial 15 finished with value: 15.064633199146815 and parameters: {'hidden_dim_1': 128, 'hidden_dim_2': 96, 'hidden_dim_3': 16, 'dropout_rate': 0.04403244460915007, 'learning_rate': 0.00030908398469972306}. Best is trial 9 with value: 14.73051050731114.\n",
      "[I 2024-11-14 04:09:44,837] Trial 16 finished with value: 18.736034733908518 and parameters: {'hidden_dim_1': 128, 'hidden_dim_2': 32, 'hidden_dim_3': 16, 'dropout_rate': 0.2802477436106125, 'learning_rate': 0.000370466709542552}. Best is trial 9 with value: 14.73051050731114.\n",
      "[I 2024-11-14 04:10:01,097] Trial 17 finished with value: 23.288534096309117 and parameters: {'hidden_dim_1': 96, 'hidden_dim_2': 128, 'hidden_dim_3': 16, 'dropout_rate': 0.12944000683526824, 'learning_rate': 0.00012815633479562296}. Best is trial 9 with value: 14.73051050731114.\n",
      "[I 2024-11-14 04:10:18,033] Trial 18 finished with value: 15.259817668369838 and parameters: {'hidden_dim_1': 128, 'hidden_dim_2': 96, 'hidden_dim_3': 80, 'dropout_rate': 0.021935423333822344, 'learning_rate': 0.0005743526379706861}. Best is trial 9 with value: 14.73051050731114.\n",
      "[I 2024-11-14 04:10:33,980] Trial 19 finished with value: 14.802405629839216 and parameters: {'hidden_dim_1': 96, 'hidden_dim_2': 64, 'hidden_dim_3': 112, 'dropout_rate': 0.032996859076354856, 'learning_rate': 0.000953150314844129}. Best is trial 9 with value: 14.73051050731114.\n",
      "[I 2024-11-14 04:10:49,455] Trial 20 finished with value: 14.563694817679268 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 64, 'hidden_dim_3': 112, 'dropout_rate': 0.036988519806344156, 'learning_rate': 0.0009205777723723097}. Best is trial 20 with value: 14.563694817679268.\n",
      "[I 2024-11-14 04:11:04,943] Trial 21 finished with value: 14.86755667413984 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 64, 'hidden_dim_3': 112, 'dropout_rate': 0.03303172832465955, 'learning_rate': 0.0009519867839297234}. Best is trial 20 with value: 14.563694817679268.\n",
      "[I 2024-11-14 04:11:20,368] Trial 22 finished with value: 14.779213394437518 and parameters: {'hidden_dim_1': 96, 'hidden_dim_2': 32, 'hidden_dim_3': 112, 'dropout_rate': 0.07635968484491212, 'learning_rate': 0.0009930099837515461}. Best is trial 20 with value: 14.563694817679268.\n",
      "[I 2024-11-14 04:11:35,372] Trial 23 finished with value: 15.164929866790771 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 32, 'hidden_dim_3': 112, 'dropout_rate': 0.0817297557030416, 'learning_rate': 0.0005184488636643469}. Best is trial 20 with value: 14.563694817679268.\n",
      "[I 2024-11-14 04:11:50,755] Trial 24 finished with value: 15.573319707598005 and parameters: {'hidden_dim_1': 96, 'hidden_dim_2': 32, 'hidden_dim_3': 112, 'dropout_rate': 0.13194481311321213, 'learning_rate': 0.0006953994336130633}. Best is trial 20 with value: 14.563694817679268.\n",
      "[I 2024-11-14 04:12:05,679] Trial 25 finished with value: 15.854457548686437 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 32, 'hidden_dim_3': 80, 'dropout_rate': 0.12783504887309577, 'learning_rate': 0.00039069244402785907}. Best is trial 20 with value: 14.563694817679268.\n",
      "[I 2024-11-14 04:12:21,481] Trial 26 finished with value: 53.14614718300955 and parameters: {'hidden_dim_1': 96, 'hidden_dim_2': 64, 'hidden_dim_3': 112, 'dropout_rate': 0.0017541214087641796, 'learning_rate': 1.1524063417865977e-05}. Best is trial 20 with value: 14.563694817679268.\n",
      "[I 2024-11-14 04:12:37,173] Trial 27 finished with value: 18.839306695120676 and parameters: {'hidden_dim_1': 128, 'hidden_dim_2': 32, 'hidden_dim_3': 80, 'dropout_rate': 0.08007574142243186, 'learning_rate': 0.00016610359717649366}. Best is trial 20 with value: 14.563694817679268.\n",
      "[I 2024-11-14 04:12:52,502] Trial 28 finished with value: 14.78645328113011 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 64, 'hidden_dim_3': 112, 'dropout_rate': 0.038705511574597895, 'learning_rate': 0.00043778561375682867}. Best is trial 20 with value: 14.563694817679268.\n",
      "[I 2024-11-14 04:13:08,588] Trial 29 finished with value: 15.7183564049857 and parameters: {'hidden_dim_1': 160, 'hidden_dim_2': 32, 'hidden_dim_3': 80, 'dropout_rate': 0.14728584755608265, 'learning_rate': 0.0006740647921856121}. Best is trial 20 with value: 14.563694817679268.\n",
      "[I 2024-11-14 04:13:24,405] Trial 30 finished with value: 16.124756710869924 and parameters: {'hidden_dim_1': 96, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.0564819395530332, 'learning_rate': 0.00021182077419237082}. Best is trial 20 with value: 14.563694817679268.\n",
      "[I 2024-11-14 04:13:40,119] Trial 31 finished with value: 15.129350287573677 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 64, 'hidden_dim_3': 112, 'dropout_rate': 0.03288043767425658, 'learning_rate': 0.00043663367853290864}. Best is trial 20 with value: 14.563694817679268.\n",
      "[I 2024-11-14 04:13:55,813] Trial 32 finished with value: 15.042681694030762 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 64, 'hidden_dim_3': 112, 'dropout_rate': 0.04679025611369764, 'learning_rate': 0.0006276623609052207}. Best is trial 20 with value: 14.563694817679268.\n",
      "[I 2024-11-14 04:14:11,221] Trial 33 finished with value: 14.446390901293073 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 64, 'hidden_dim_3': 112, 'dropout_rate': 0.08762668244667624, 'learning_rate': 0.0009752252475659483}. Best is trial 33 with value: 14.446390901293073.\n",
      "[I 2024-11-14 04:14:27,797] Trial 34 finished with value: 14.954907042639595 and parameters: {'hidden_dim_1': 96, 'hidden_dim_2': 96, 'hidden_dim_3': 112, 'dropout_rate': 0.08584031255964325, 'learning_rate': 0.0009706016345945902}. Best is trial 33 with value: 14.446390901293073.\n",
      "[I 2024-11-14 04:14:43,353] Trial 35 finished with value: 15.036583832332067 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 64, 'hidden_dim_3': 112, 'dropout_rate': 0.10953318775181688, 'learning_rate': 0.0006972463240523083}. Best is trial 33 with value: 14.446390901293073.\n",
      "[I 2024-11-14 04:14:58,747] Trial 36 finished with value: 42.92403316497803 and parameters: {'hidden_dim_1': 96, 'hidden_dim_2': 32, 'hidden_dim_3': 112, 'dropout_rate': 0.0779497506734487, 'learning_rate': 2.2452079193078518e-05}. Best is trial 33 with value: 14.446390901293073.\n",
      "[I 2024-11-14 04:15:14,518] Trial 37 finished with value: 15.406323569161552 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 96, 'hidden_dim_3': 80, 'dropout_rate': 0.11458173652516801, 'learning_rate': 0.0006919622893532916}. Best is trial 33 with value: 14.446390901293073.\n",
      "[I 2024-11-14 04:15:30,341] Trial 38 finished with value: 24.541598115648544 and parameters: {'hidden_dim_1': 128, 'hidden_dim_2': 32, 'hidden_dim_3': 112, 'dropout_rate': 0.1540270186276529, 'learning_rate': 7.768789754440829e-05}. Best is trial 33 with value: 14.446390901293073.\n",
      "[I 2024-11-14 04:15:46,057] Trial 39 finished with value: 15.061814921242851 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 96, 'hidden_dim_3': 80, 'dropout_rate': 0.09360424278603907, 'learning_rate': 0.0007931977876568769}. Best is trial 33 with value: 14.446390901293073.\n",
      "[I 2024-11-14 04:16:03,574] Trial 40 finished with value: 15.000285148620605 and parameters: {'hidden_dim_1': 192, 'hidden_dim_2': 64, 'hidden_dim_3': 112, 'dropout_rate': 0.01796531426701797, 'learning_rate': 0.0005250393399137905}. Best is trial 33 with value: 14.446390901293073.\n",
      "[I 2024-11-14 04:16:19,202] Trial 41 finished with value: 14.364590781075615 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 64, 'hidden_dim_3': 112, 'dropout_rate': 0.04775383735487844, 'learning_rate': 0.0009987504586624833}. Best is trial 41 with value: 14.364590781075615.\n",
      "[I 2024-11-14 04:16:34,691] Trial 42 finished with value: 14.872478553227015 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 64, 'hidden_dim_3': 112, 'dropout_rate': 0.06551026173911699, 'learning_rate': 0.0008209585923902429}. Best is trial 41 with value: 14.364590781075615.\n",
      "[I 2024-11-14 04:16:50,661] Trial 43 finished with value: 15.588775532586235 and parameters: {'hidden_dim_1': 96, 'hidden_dim_2': 64, 'hidden_dim_3': 112, 'dropout_rate': 0.05194529994016599, 'learning_rate': 0.0005738339386070488}. Best is trial 41 with value: 14.364590781075615.\n",
      "[I 2024-11-14 04:17:06,755] Trial 44 finished with value: 15.167563302176339 and parameters: {'hidden_dim_1': 96, 'hidden_dim_2': 64, 'hidden_dim_3': 112, 'dropout_rate': 0.21239041670829928, 'learning_rate': 0.0008044666515556369}. Best is trial 41 with value: 14.364590781075615.\n",
      "[I 2024-11-14 04:17:23,180] Trial 45 finished with value: 14.206310885293144 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 96, 'hidden_dim_3': 112, 'dropout_rate': 0.020967270251759117, 'learning_rate': 0.0009923121408667696}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:17:39,021] Trial 46 finished with value: 39.40613733019148 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 128, 'hidden_dim_3': 80, 'dropout_rate': 0.022011910565692638, 'learning_rate': 2.720128423263782e-05}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:17:54,989] Trial 47 finished with value: 15.51900029182434 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 96, 'hidden_dim_3': 112, 'dropout_rate': 0.010389408934379438, 'learning_rate': 0.00031949243427821343}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:18:13,328] Trial 48 finished with value: 14.731887306485858 and parameters: {'hidden_dim_1': 192, 'hidden_dim_2': 128, 'hidden_dim_3': 48, 'dropout_rate': 0.0032613313659452525, 'learning_rate': 0.0007531970498793513}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:18:28,726] Trial 49 finished with value: 17.012553725923812 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 96, 'hidden_dim_3': 48, 'dropout_rate': 0.17537689651415278, 'learning_rate': 0.0002549649385614512}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:18:44,921] Trial 50 finished with value: 15.405100584030151 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 128, 'hidden_dim_3': 112, 'dropout_rate': 0.026642405636198636, 'learning_rate': 0.00048458888440952065}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:19:04,645] Trial 51 finished with value: 15.384844745908465 and parameters: {'hidden_dim_1': 256, 'hidden_dim_2': 128, 'hidden_dim_3': 48, 'dropout_rate': 0.0009230702812884151, 'learning_rate': 0.0007839901372836554}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:19:22,618] Trial 52 finished with value: 14.82220380646842 and parameters: {'hidden_dim_1': 192, 'hidden_dim_2': 128, 'hidden_dim_3': 48, 'dropout_rate': 0.055411534862503414, 'learning_rate': 0.0006435650478520672}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:19:40,913] Trial 53 finished with value: 15.091035740716118 and parameters: {'hidden_dim_1': 192, 'hidden_dim_2': 128, 'hidden_dim_3': 48, 'dropout_rate': 0.04085487485797376, 'learning_rate': 0.0009729879530840715}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:19:59,896] Trial 54 finished with value: 15.369115625108991 and parameters: {'hidden_dim_1': 224, 'hidden_dim_2': 128, 'hidden_dim_3': 48, 'dropout_rate': 0.014815196743151026, 'learning_rate': 0.0007771327326220722}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:20:18,240] Trial 55 finished with value: 15.935693195887975 and parameters: {'hidden_dim_1': 192, 'hidden_dim_2': 128, 'hidden_dim_3': 80, 'dropout_rate': 0.067786389802553, 'learning_rate': 0.00035731804260142415}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:20:36,196] Trial 56 finished with value: 15.314981460571289 and parameters: {'hidden_dim_1': 224, 'hidden_dim_2': 96, 'hidden_dim_3': 48, 'dropout_rate': 0.02665498448250308, 'learning_rate': 0.0005455979092745969}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:20:53,054] Trial 57 finished with value: 14.350209270204816 and parameters: {'hidden_dim_1': 160, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.009488988418272015, 'learning_rate': 0.0008631887148685669}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:21:09,963] Trial 58 finished with value: 14.621178661073957 and parameters: {'hidden_dim_1': 160, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.04168283294189795, 'learning_rate': 0.000878737718427906}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:21:26,731] Trial 59 finished with value: 15.0036666733878 and parameters: {'hidden_dim_1': 160, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.06154204755083198, 'learning_rate': 0.0008734803832017218}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:21:43,335] Trial 60 finished with value: 31.9708149092538 and parameters: {'hidden_dim_1': 160, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.29825757615617243, 'learning_rate': 4.5709613428039266e-05}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:22:00,135] Trial 61 finished with value: 14.623839480536324 and parameters: {'hidden_dim_1': 160, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.044363058797286956, 'learning_rate': 0.000996079382641853}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:22:16,811] Trial 62 finished with value: 14.609415463038854 and parameters: {'hidden_dim_1': 160, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.04547701394155023, 'learning_rate': 0.0008919306101060489}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:22:33,665] Trial 63 finished with value: 14.767368827547346 and parameters: {'hidden_dim_1': 160, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.03224653020625392, 'learning_rate': 0.0006200091121112645}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:22:50,285] Trial 64 finished with value: 15.368743044989449 and parameters: {'hidden_dim_1': 128, 'hidden_dim_2': 64, 'hidden_dim_3': 112, 'dropout_rate': 0.013707050452765504, 'learning_rate': 0.0005828342356210984}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:23:07,136] Trial 65 finished with value: 14.797610078539167 and parameters: {'hidden_dim_1': 160, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.09521382670145355, 'learning_rate': 0.0008695729418210591}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:23:23,989] Trial 66 finished with value: 15.114255121776036 and parameters: {'hidden_dim_1': 160, 'hidden_dim_2': 64, 'hidden_dim_3': 112, 'dropout_rate': 0.04917731874575966, 'learning_rate': 0.00044049922437728293}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:23:40,279] Trial 67 finished with value: 14.838930334363665 and parameters: {'hidden_dim_1': 128, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.037152611758032056, 'learning_rate': 0.0008636609620931118}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:23:56,923] Trial 68 finished with value: 14.959897109440394 and parameters: {'hidden_dim_1': 128, 'hidden_dim_2': 64, 'hidden_dim_3': 112, 'dropout_rate': 0.06945037402463605, 'learning_rate': 0.0006912848817227696}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:24:14,119] Trial 69 finished with value: 15.34001796586173 and parameters: {'hidden_dim_1': 160, 'hidden_dim_2': 64, 'hidden_dim_3': 112, 'dropout_rate': 0.026461075241379424, 'learning_rate': 0.0004738892174889285}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:24:30,061] Trial 70 finished with value: 15.418849774769374 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 96, 'hidden_dim_3': 80, 'dropout_rate': 0.008482557426231205, 'learning_rate': 0.0007241490035799022}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:24:46,816] Trial 71 finished with value: 14.571297475269862 and parameters: {'hidden_dim_1': 160, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.04278412338836901, 'learning_rate': 0.000957008797425535}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:25:03,539] Trial 72 finished with value: 15.18828821182251 and parameters: {'hidden_dim_1': 160, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.05400872259144235, 'learning_rate': 0.0008927788463029191}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:25:20,249] Trial 73 finished with value: 14.863250119345528 and parameters: {'hidden_dim_1': 160, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.019784236814408187, 'learning_rate': 0.0006200905829273711}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:25:37,189] Trial 74 finished with value: 16.61976671218872 and parameters: {'hidden_dim_1': 160, 'hidden_dim_2': 64, 'hidden_dim_3': 112, 'dropout_rate': 0.2483096774357852, 'learning_rate': 0.0009893908697126508}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:25:55,440] Trial 75 finished with value: 14.654095002583094 and parameters: {'hidden_dim_1': 256, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.03910666821176071, 'learning_rate': 0.0008287717959930365}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:26:12,998] Trial 76 finished with value: 15.286414759499687 and parameters: {'hidden_dim_1': 192, 'hidden_dim_2': 64, 'hidden_dim_3': 112, 'dropout_rate': 0.02854817094410378, 'learning_rate': 0.0007294506447489412}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:26:28,309] Trial 77 finished with value: 17.322776351656234 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.07247688413688488, 'learning_rate': 0.00017597172674264626}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:26:44,755] Trial 78 finished with value: 15.743953704833984 and parameters: {'hidden_dim_1': 128, 'hidden_dim_2': 64, 'hidden_dim_3': 112, 'dropout_rate': 0.08760962574518712, 'learning_rate': 0.0009948327942376817}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:27:00,996] Trial 79 finished with value: 20.760398728506907 and parameters: {'hidden_dim_1': 96, 'hidden_dim_2': 96, 'hidden_dim_3': 112, 'dropout_rate': 0.06236397521323998, 'learning_rate': 8.72804248493693e-05}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:27:16,398] Trial 80 finished with value: 15.510519198008947 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.047266222310877806, 'learning_rate': 0.0005438662819689645}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:27:33,284] Trial 81 finished with value: 14.844546113695417 and parameters: {'hidden_dim_1': 160, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.04278510872427653, 'learning_rate': 0.0008944667190474964}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:27:49,952] Trial 82 finished with value: 14.694157906941005 and parameters: {'hidden_dim_1': 160, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.01980993143415185, 'learning_rate': 0.0007398529573448211}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:28:06,766] Trial 83 finished with value: 14.41971594946725 and parameters: {'hidden_dim_1': 160, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.05938443123615856, 'learning_rate': 0.0009028730399163612}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:28:23,957] Trial 84 finished with value: 14.879874297550746 and parameters: {'hidden_dim_1': 192, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.059401125055671196, 'learning_rate': 0.0006630814477510802}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:28:41,288] Trial 85 finished with value: 15.067912135805402 and parameters: {'hidden_dim_1': 160, 'hidden_dim_2': 64, 'hidden_dim_3': 112, 'dropout_rate': 0.008503263499860227, 'learning_rate': 0.0008712717225821534}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:28:57,661] Trial 86 finished with value: 14.820557083402361 and parameters: {'hidden_dim_1': 128, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.03392373444816427, 'learning_rate': 0.0007808141167362297}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:29:12,654] Trial 87 finished with value: 14.388792174203056 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 64, 'hidden_dim_3': 16, 'dropout_rate': 0.04975686163538732, 'learning_rate': 0.0006279313812727451}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:29:27,726] Trial 88 finished with value: 16.487879242215836 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 64, 'hidden_dim_3': 16, 'dropout_rate': 0.12024137604324434, 'learning_rate': 0.0006109109894961332}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:29:42,516] Trial 89 finished with value: 24.206833566938126 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 64, 'hidden_dim_3': 16, 'dropout_rate': 0.07368563835134101, 'learning_rate': 0.00012833769873839924}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:29:58,977] Trial 90 finished with value: 15.565401690346855 and parameters: {'hidden_dim_1': 96, 'hidden_dim_2': 96, 'hidden_dim_3': 112, 'dropout_rate': 0.09904661419204397, 'learning_rate': 0.0004034029193196354}. Best is trial 45 with value: 14.206310885293144.\n",
      "[I 2024-11-14 04:30:14,632] Trial 91 finished with value: 14.186381884983607 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.05155521210111333, 'learning_rate': 0.0009057370211032963}. Best is trial 91 with value: 14.186381884983607.\n",
      "[I 2024-11-14 04:30:29,838] Trial 92 finished with value: 15.630342347281319 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 64, 'hidden_dim_3': 16, 'dropout_rate': 0.05300499332652376, 'learning_rate': 0.0007885719528632384}. Best is trial 91 with value: 14.186381884983607.\n",
      "[I 2024-11-14 04:30:45,147] Trial 93 finished with value: 14.630768571581159 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.08157102274626551, 'learning_rate': 0.0009053362194410607}. Best is trial 91 with value: 14.186381884983607.\n",
      "[I 2024-11-14 04:31:00,477] Trial 94 finished with value: 14.764569793428693 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.04793203748561576, 'learning_rate': 0.0006757233617527249}. Best is trial 91 with value: 14.186381884983607.\n",
      "[I 2024-11-14 04:31:16,062] Trial 95 finished with value: 14.377440316336495 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 64, 'hidden_dim_3': 112, 'dropout_rate': 0.05826093690936355, 'learning_rate': 0.0009931445160564914}. Best is trial 91 with value: 14.186381884983607.\n",
      "[I 2024-11-14 04:31:31,751] Trial 96 finished with value: 15.784325225012642 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 64, 'hidden_dim_3': 112, 'dropout_rate': 0.19223180066523732, 'learning_rate': 0.0009834524243266857}. Best is trial 91 with value: 14.186381884983607.\n",
      "[I 2024-11-14 04:31:47,076] Trial 97 finished with value: 14.541790246963501 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 32, 'hidden_dim_3': 112, 'dropout_rate': 0.0595211616250408, 'learning_rate': 0.000745164171305872}. Best is trial 91 with value: 14.186381884983607.\n",
      "[I 2024-11-14 04:32:02,108] Trial 98 finished with value: 15.34521654673985 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 32, 'hidden_dim_3': 112, 'dropout_rate': 0.0635119728012751, 'learning_rate': 0.0005236373117604138}. Best is trial 91 with value: 14.186381884983607.\n",
      "[I 2024-11-14 04:32:17,174] Trial 99 finished with value: 14.861917291368757 and parameters: {'hidden_dim_1': 64, 'hidden_dim_2': 32, 'hidden_dim_3': 112, 'dropout_rate': 0.057096620676505554, 'learning_rate': 0.0007768621094352815}. Best is trial 91 with value: 14.186381884983607.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'hidden_dim_1': 64, 'hidden_dim_2': 64, 'hidden_dim_3': 80, 'dropout_rate': 0.05155521210111333, 'learning_rate': 0.0009057370211032963}\n",
      "Best Validation RMSE: 14.186381884983607\n",
      "Best model saved to 'best_sdae_model_optuna_second.pth'\n"
     ]
    }
   ],
   "source": [
    "# rmse loss function\n",
    "# this function calculates rmse (root mean square error) between the predicted and true values\n",
    "# we use this for regression tasks, like predicting the remaining useful life (rul)\n",
    "def rmse_loss(predictions, targets):\n",
    "    return torch.sqrt(nn.MSELoss()(predictions, targets))  # mse loss is calculated first, then we take the square root\n",
    "\n",
    "# train function for training the model with noisy inputs\n",
    "# this function will be used during optuna's hyperparameter optimization\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    model.to(device)  # move the model to the selected device (GPU or CPU)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # set model to training mode\n",
    "        train_loss = 0.0  # we'll accumulate the training loss here\n",
    "        \n",
    "        # loop through the training batches\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)  # move data to device\n",
    "            batch_x_noisy = add_noise(batch_x)  # add noise to the input data for the autoencoder\n",
    "\n",
    "            optimizer.zero_grad()  # reset gradients from the previous step\n",
    "            decoded, prediction = model(batch_x_noisy)  # forward pass through the model\n",
    "\n",
    "            # loss calculation: we have two parts - reconstruction loss and prediction loss\n",
    "            loss = criterion(decoded, batch_x.view(batch_x.size(0), -1)) + criterion(prediction, batch_y)\n",
    "            \n",
    "            loss.backward()  # backpropagate the gradients\n",
    "            optimizer.step()  # update the model weights\n",
    "            train_loss += loss.item()  # accumulate the training loss\n",
    "\n",
    "        # validation phase to evaluate performance on the validation set\n",
    "        model.eval()  # set the model to evaluation mode (disables dropout, etc.)\n",
    "        val_loss = 0.0  # we'll accumulate the validation loss here\n",
    "        \n",
    "        with torch.no_grad():  # no need to compute gradients during validation\n",
    "            for batch_x, batch_y in val_loader:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)  # move data to device\n",
    "                decoded, prediction = model(batch_x)  # forward pass through the model\n",
    "\n",
    "                # calculate the loss for both the reconstruction and prediction parts\n",
    "                loss = criterion(decoded, batch_x.view(batch_x.size(0), -1)) + criterion(prediction, batch_y)\n",
    "                val_loss += loss.item()  # accumulate the validation loss\n",
    "\n",
    "        val_loss /= len(val_loader)  # average the validation loss over all batches\n",
    "    return val_loss  # return the validation loss to Optuna\n",
    "\n",
    "# objective function for optuna's optimization loop\n",
    "# this is what optuna uses to evaluate different hyperparameter combinations\n",
    "def objective(trial):\n",
    "    # define the hyperparameter search space\n",
    "    hidden_dims = [trial.suggest_int('hidden_dim_1', 64, 256, step=32),\n",
    "                   trial.suggest_int('hidden_dim_2', 32, 128, step=32),\n",
    "                   trial.suggest_int('hidden_dim_3', 16, 128, step=32)]\n",
    "    \n",
    "    # suggest a dropout rate between 0 and 0.3 for regularization\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.3)\n",
    "    \n",
    "    # suggest a learning rate using a log-uniform distribution\n",
    "    # this explores learning rates from 1e-5 to 1e-3\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
    "\n",
    "    # create the model using the suggested hyperparameters\n",
    "    model = SDAE(input_dim=30 * 14, hidden_dims=hidden_dims, dropout_rate=dropout_rate)\n",
    "\n",
    "    # use rmse loss and adam optimizer\n",
    "    criterion = rmse_loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # select the device (GPU or CPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # train the model and get the validation loss\n",
    "    val_loss = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20, device=device)\n",
    "\n",
    "    # return the validation loss to Optuna so it can decide whether this trial is good or not\n",
    "    return val_loss\n",
    "\n",
    "# create an Optuna study to minimize the validation loss\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# optimize for 100 trials (this will try different hyperparameter combinations)\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# print the best hyperparameters and the validation loss of the best trial\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n",
    "print(\"Best Validation RMSE:\", study.best_value)\n",
    "\n",
    "# once the best trial is found, extract the best hyperparameters\n",
    "best_trial = study.best_trial\n",
    "best_hidden_dims = [best_trial.params['hidden_dim_1'], best_trial.params['hidden_dim_2'], best_trial.params['hidden_dim_3']]\n",
    "best_dropout_rate = best_trial.params['dropout_rate']\n",
    "best_lr = best_trial.params['learning_rate']\n",
    "\n",
    "# create a new model with the best hyperparameters\n",
    "best_model = SDAE(input_dim=30 * 14, hidden_dims=best_hidden_dims, dropout_rate=best_dropout_rate)\n",
    "\n",
    "# create the optimizer and loss function for the final model\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=best_lr)\n",
    "criterion = rmse_loss\n",
    "\n",
    "# train the final model on the full training data with the best hyperparameters\n",
    "train_model(best_model, train_loader, val_loader, criterion, optimizer, num_epochs=20, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# save the best model to a file so we can load it later\n",
    "torch.save(best_model.state_dict(), 'best_sdae_model_optuna_second.pth')\n",
    "print(\"Best model saved to 'best_sdae_model_optuna_second.pth'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f737ec6e-9c5d-404d-a04b-5b0857c9533a",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f9f3f792-f255-4945-a5f0-643d6c4c7ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[108.270035 123.95801   46.380363  89.536026 101.55478  105.04238\n",
      "  88.46287   98.11394  117.86893   71.83512 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_155328/3303680736.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load('best_sdae_model_optuna_second.pth', map_location='cpu'))  # Use 'cuda' if running on GPU\n"
     ]
    }
   ],
   "source": [
    "# test data (processed test data and true rul values)\n",
    "X_test = processed_test_data  # processed test data\n",
    "y_test = true_rul  # true remaining useful life values\n",
    "\n",
    "# convert the test data and labels to pytorch tensors\n",
    "X_test_tensor = torch.FloatTensor(X_test)  # convert test data to float tensor\n",
    "y_test_tensor = torch.FloatTensor(y_test)  # convert true rul values to float tensor\n",
    "\n",
    "# create a DataLoader for the test data (used for batch processing)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)  # combine the features and labels into a dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)  # create the DataLoader for test data (no shuffling)\n",
    "\n",
    "# define the best hyperparameters found from optuna\n",
    "best_hidden_dims = [64, 64, 80] \n",
    "best_dropout_rate = 0.05155521210111333 \n",
    "\n",
    "# instantiate the model with the best hyperparameters\n",
    "best_model = SDAE(input_dim=30 * 14, hidden_dims=best_hidden_dims, dropout_rate=best_dropout_rate)\n",
    "\n",
    "# load the best model weights saved after training with optuna\n",
    "best_model.load_state_dict(torch.load('best_sdae_model_optuna_second.pth', map_location='cpu'))  # use 'cuda' if GPU use\n",
    "\n",
    "# define a function to get predictions from the model\n",
    "def get_predictions(model, test_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # use GPU if available, otherwise use CPU\n",
    "    model.to(device)  # move the model to the selected device (GPU/CPU)\n",
    "    model.eval()  # set the model to evaluation mode (disables dropout layers, etc.)\n",
    "    \n",
    "    all_predictions = []  # this will hold the predictions from all batches\n",
    "    \n",
    "    with torch.no_grad():  # turn off gradient computation since we are just doing inference\n",
    "        for batch_x, _ in test_loader:  # loop through the batches in the test_loader\n",
    "            batch_x = batch_x.to(device)  # move input batch to the same device as the model\n",
    "            _, predictions = model(batch_x)  # forward pass through the model to get predictions\n",
    "            all_predictions.append(predictions.cpu().numpy())  # store predictions (move them to CPU and convert to numpy)\n",
    "\n",
    "    # concatenate all predictions into a single array (flatten list of arrays)\n",
    "    all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "    \n",
    "    return all_predictions  # return the final array of predictions\n",
    "\n",
    "# get the model's predictions on the test set\n",
    "predictions = get_predictions(best_model, test_loader)\n",
    "\n",
    "# print or inspect the predictions\n",
    "print(predictions[:10])  # print the first 10 predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d98c8453-6dd0-4833-a087-a2748282670b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 10.44703010559082,\n",
       " 'MSE': 205.7282444988759,\n",
       " 'RMSE': 14.343229918636734,\n",
       " 'MAPE': 16.14549992434262}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def evaluate_rul_metrics(true, predicted):\n",
    "    \n",
    "    true = np.array(true)\n",
    "    predicted = np.array(predicted)\n",
    "    \n",
    "    mae = float(mean_absolute_error(true, predicted))\n",
    "    mse = float(mean_squared_error(true, predicted))\n",
    "    rmse = float(np.sqrt(mse))\n",
    "    mape = float(np.mean(np.abs((true - predicted) / true)) * 100)\n",
    "    \n",
    "    return {\n",
    "        \"MAE\": mae,\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAPE\": mape\n",
    "    }\n",
    "    \n",
    "metrics = evaluate_rul_metrics(true_rul, predictions)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79d1650-9cca-4a5e-b2a4-b79bd175744b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
