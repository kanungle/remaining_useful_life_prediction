2024-11-21 15:39:21,007 INFO    MainThread:26724 [wandb_setup.py:_flush():79] Current SDK version is 0.18.6
2024-11-21 15:39:21,007 INFO    MainThread:26724 [wandb_setup.py:_flush():79] Configure stats pid to 26724
2024-11-21 15:39:21,007 INFO    MainThread:26724 [wandb_setup.py:_flush():79] Loading settings from C:\Users\e_nkanungo\.config\wandb\settings
2024-11-21 15:39:21,007 INFO    MainThread:26724 [wandb_setup.py:_flush():79] Loading settings from c:\Users\e_nkanungo\Desktop\MADS_Capstone\RUL_Prediction\wandb\settings
2024-11-21 15:39:21,007 INFO    MainThread:26724 [wandb_setup.py:_flush():79] Loading settings from environment variables: {}
2024-11-21 15:39:21,007 INFO    MainThread:26724 [wandb_setup.py:_flush():79] Applying setup settings: {'mode': None, '_disable_service': None}
2024-11-21 15:39:21,007 INFO    MainThread:26724 [wandb_setup.py:_flush():79] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2024-11-21 15:39:21,007 INFO    MainThread:26724 [wandb_setup.py:_flush():79] Applying login settings: {}
2024-11-21 15:39:21,008 INFO    MainThread:26724 [wandb_init.py:_log_setup():533] Logging user logs to c:\Users\e_nkanungo\Desktop\MADS_Capstone\RUL_Prediction\wandb\run-20241121_153921-kahqnn08\logs\debug.log
2024-11-21 15:39:21,008 INFO    MainThread:26724 [wandb_init.py:_log_setup():534] Logging internal logs to c:\Users\e_nkanungo\Desktop\MADS_Capstone\RUL_Prediction\wandb\run-20241121_153921-kahqnn08\logs\debug-internal.log
2024-11-21 15:39:21,008 INFO    MainThread:26724 [wandb_init.py:_jupyter_setup():479] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x000001C8F5D71BD0>
2024-11-21 15:39:21,008 INFO    MainThread:26724 [wandb_init.py:init():619] calling init triggers
2024-11-21 15:39:21,008 INFO    MainThread:26724 [wandb_init.py:init():626] wandb.init called with sweep_config: {}
config: {}
2024-11-21 15:39:21,008 INFO    MainThread:26724 [wandb_init.py:init():669] starting backend
2024-11-21 15:39:21,008 INFO    MainThread:26724 [wandb_init.py:init():673] sending inform_init request
2024-11-21 15:39:21,011 INFO    MainThread:26724 [backend.py:_multiprocessing_setup():104] multiprocessing start_methods=spawn, using: spawn
2024-11-21 15:39:21,012 INFO    MainThread:26724 [wandb_init.py:init():686] backend started and connected
2024-11-21 15:39:21,020 INFO    MainThread:26724 [wandb_run.py:_label_probe_notebook():1341] probe notebook
2024-11-21 15:39:21,039 INFO    MainThread:26724 [wandb_run.py:_label_probe_notebook():1351] Unable to probe notebook: 'charmap' codec can't decode byte 0x81 in position 4688: character maps to <undefined>
2024-11-21 15:39:21,039 INFO    MainThread:26724 [wandb_init.py:init():781] updated telemetry
2024-11-21 15:39:21,588 INFO    MainThread:26724 [wandb_init.py:init():814] communicating run to backend with 90.0 second timeout
2024-11-21 15:39:23,070 INFO    MainThread:26724 [wandb_init.py:init():867] starting run threads in backend
2024-11-21 15:39:23,355 INFO    MainThread:26724 [wandb_run.py:_console_start():2451] atexit reg
2024-11-21 15:39:23,355 INFO    MainThread:26724 [wandb_run.py:_redirect():2299] redirect: wrap_raw
2024-11-21 15:39:23,356 INFO    MainThread:26724 [wandb_run.py:_redirect():2364] Wrapping output streams.
2024-11-21 15:39:23,356 INFO    MainThread:26724 [wandb_run.py:_redirect():2389] Redirects installed.
2024-11-21 15:39:23,360 INFO    MainThread:26724 [wandb_init.py:init():911] run started, returning control to user process
2024-11-21 15:39:23,364 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov21_15-39-14_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-21 15:39:23,367 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-21 15:39:23,367 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-21 15:39:24,582 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:39:24,582 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:40:48,264 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:40:48,375 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:40:48,376 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:40:48,392 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:40:48,395 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:40:48,395 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:40:48,416 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:40:48,493 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:40:48,493 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:41:35,748 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:41:41,048 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:41:41,048 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:41:41,080 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:41:41,083 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:41:41,083 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:41:41,113 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:41:41,140 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:41:41,140 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:42:30,500 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:42:35,900 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:42:35,900 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:42:35,944 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:42:35,946 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:42:35,947 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:42:35,997 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:42:36,040 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:42:36,040 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:42:43,669 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:42:43,782 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:42:43,782 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:42:43,810 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:42:43,813 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:42:43,813 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:42:43,844 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:42:43,853 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:42:43,853 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:42:43,911 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:42:43,918 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:42:43,918 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:42:43,958 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:42:43,962 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:42:43,962 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:42:43,983 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:42:44,665 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:42:44,665 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:42:44,677 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:42:44,962 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:42:44,962 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:42:45,015 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:42:45,018 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:42:45,018 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:42:45,044 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:42:45,047 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:42:45,047 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:42:45,067 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:42:45,111 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:42:45,111 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:42:45,129 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:42:45,894 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov21_15-42-45_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-21 15:42:45,898 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-21 15:42:45,898 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-21 15:42:46,649 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:42:46,649 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:43:30,666 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:43:30,769 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:43:30,770 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:43:30,793 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:43:30,796 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:43:30,796 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:43:30,810 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:43:30,817 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:43:30,817 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:43:30,829 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:43:30,840 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:43:30,840 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:43:30,856 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:43:30,859 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:43:30,859 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:43:30,874 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:43:31,609 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:43:31,609 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:43:31,621 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:43:31,906 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:43:31,906 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:43:31,959 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:43:31,962 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:43:31,962 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:43:32,025 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:43:32,028 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:43:32,028 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:43:32,057 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:43:32,066 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:43:32,066 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:43:32,085 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:43:32,798 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov21_15-43-32_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-21 15:43:32,802 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-21 15:43:32,803 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-21 15:43:33,612 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:43:33,612 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:45:16,916 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:45:16,920 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:45:16,920 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:45:19,574 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:45:19,578 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:45:19,578 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:45:19,911 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:45:19,914 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:45:19,915 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:45:20,006 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:45:20,010 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:45:20,010 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:45:25,160 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:45:25,165 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:45:25,165 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:45:25,912 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:45:25,917 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:45:25,917 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:45:26,168 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:45:26,174 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:45:26,174 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:45:30,318 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:45:30,323 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:45:30,323 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:45:31,540 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:45:31,544 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:45:31,544 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:45:31,716 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:45:31,720 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:45:31,720 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:45:31,820 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:45:31,824 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:45:31,824 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:45:35,529 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:45:35,665 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:45:35,665 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:45:35,685 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:45:35,687 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:45:35,687 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:45:35,721 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:45:35,729 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:45:35,729 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:45:35,760 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:45:35,766 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:45:35,766 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:45:35,792 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:45:35,797 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:45:35,797 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:45:35,854 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:45:36,451 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:45:36,451 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:45:36,518 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:45:36,782 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:45:36,782 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:45:36,801 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:45:36,803 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:45:36,803 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:45:36,823 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:45:36,825 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:45:36,825 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:45:36,843 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:45:36,849 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:45:36,849 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:45:36,880 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:45:37,016 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:45:37,016 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:46:11,126 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:46:11,216 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:46:11,217 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:46:11,236 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:46:11,238 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:46:11,238 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:46:11,257 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:46:11,266 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:46:11,266 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:46:11,277 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:46:11,285 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:46:11,285 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:46:11,298 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:46:11,301 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:46:11,301 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:46:11,327 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:46:11,891 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:46:11,891 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:46:11,903 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:46:12,138 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:46:12,138 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:46:12,152 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:46:12,155 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:46:12,155 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:46:12,167 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:46:12,169 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:46:12,169 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:46:12,184 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:46:12,189 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:46:12,189 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:46:12,204 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:46:12,280 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:46:12,280 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:46:24,449 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:46:24,532 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:46:24,532 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:46:24,547 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:46:24,548 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:46:24,548 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:46:24,588 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:46:24,597 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:46:24,598 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:46:24,617 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:46:24,623 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:46:24,623 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:46:24,664 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:46:24,668 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:46:24,668 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:46:24,680 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:46:25,241 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:46:25,241 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:46:25,261 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:46:25,877 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:46:25,877 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:46:25,900 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:46:25,903 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:46:25,903 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:46:25,918 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:46:25,919 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:46:25,919 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:46:25,933 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:46:25,939 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:46:25,939 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 15:46:25,964 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 15:46:26,070 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 15:46:26,070 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:06:04,642 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:06:04,815 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:06:04,815 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:06:04,839 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:06:04,842 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:06:04,842 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:06:04,862 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:06:04,886 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:06:04,886 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:06:04,898 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:06:04,902 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:06:04,902 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:06:04,925 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:06:04,929 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:06:04,929 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:06:04,964 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:06:05,539 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:06:05,539 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:06:05,564 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:06:05,798 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:06:05,798 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:06:05,809 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:06:05,812 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:06:05,812 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:06:05,827 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:06:05,830 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:06:05,830 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:06:05,842 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:06:05,849 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:06:05,849 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:06:05,865 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:06:05,939 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:06:05,939 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:14:21,018 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:14:21,067 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:14:21,067 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:14:21,122 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:14:21,139 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:14:21,142 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:14:21,208 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:14:21,221 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:14:21,229 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:14:21,284 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:14:21,299 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:14:21,299 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:14:21,357 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:14:21,377 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:14:21,377 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:14:21,427 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:14:21,441 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:14:21,441 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:14:21,503 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:14:21,522 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:14:21,523 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:14:21,576 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:14:21,591 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:14:21,592 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:14:21,649 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:14:21,669 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:14:21,670 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:14:53,297 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:14:53,305 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:14:53,305 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:15:19,874 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:15:21,095 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:15:21,095 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:16:00,326 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:16:00,331 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:16:00,331 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:16:00,362 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:16:00,368 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:16:00,368 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 16:16:00,586 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 16:16:00,606 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 16:16:00,606 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 19:49:33,710 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 19:49:33,740 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 19:49:33,742 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 19:49:33,770 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 19:49:33,889 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 19:49:33,895 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 19:49:33,905 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 19:49:33,912 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 19:49:33,912 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 19:49:35,431 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 19:49:35,435 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 19:49:35,435 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 19:49:35,468 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 19:49:35,476 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 19:49:35,477 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 19:49:35,496 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 19:49:35,504 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 19:49:35,505 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 19:49:35,655 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 19:49:35,662 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 19:49:35,663 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 19:49:36,430 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 19:49:36,438 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 19:49:36,439 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 19:49:39,233 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 19:49:39,672 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 19:49:39,672 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 19:49:39,729 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 19:49:39,735 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 19:49:39,735 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 19:49:39,814 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 19:49:39,866 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 19:49:39,866 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 19:49:39,890 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 19:49:39,921 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 19:49:39,922 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 19:49:39,982 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 19:49:40,001 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 19:49:40,001 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 19:49:40,027 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 19:49:40,208 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 19:49:40,208 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:32:47,245 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:32:47,250 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:32:47,250 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:32:47,817 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:32:47,824 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:32:47,824 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:32:48,009 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:32:48,015 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:32:48,015 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:32:48,309 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:32:48,314 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:32:48,314 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:32:48,550 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:32:48,556 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:32:48,556 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:32:51,837 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:32:51,846 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:32:51,846 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:32:52,112 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:32:52,116 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:32:52,116 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:32:52,220 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:32:52,225 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:32:52,225 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:32:52,609 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:32:52,614 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:32:52,614 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:32:52,844 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:32:52,850 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:32:52,850 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:32:52,934 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:32:52,938 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:32:52,938 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:33:02,353 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:33:02,448 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:33:02,448 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:33:02,472 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:33:02,473 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:33:02,473 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:33:02,492 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:33:02,504 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:33:02,504 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:33:02,519 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:33:02,532 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:33:02,532 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:33:02,553 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:33:02,568 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:33:02,568 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:33:02,592 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:33:02,728 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:33:02,729 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:33:53,522 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:33:53,615 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:33:53,615 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:33:53,633 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:33:53,635 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:33:53,635 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:33:53,658 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:33:53,663 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:33:53,663 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:33:53,699 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:33:53,712 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:33:53,712 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:33:53,778 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:33:53,787 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:33:53,787 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:33:53,817 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:33:54,644 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:33:54,644 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:33:54,672 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:33:55,906 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:33:55,906 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:33:55,931 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:33:55,934 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:33:55,934 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:33:55,949 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:33:55,951 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:33:55,951 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:33:55,978 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:33:55,991 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:33:55,992 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:33:56,012 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:33:57,160 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov21_22-33-57_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-21 22:33:57,167 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-21 22:33:57,167 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-21 22:33:57,977 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:33:57,977 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:34:17,737 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:34:17,831 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:34:17,831 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:34:17,846 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:34:17,849 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:34:17,849 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:34:17,866 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:34:17,871 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:34:17,871 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:34:17,895 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:34:17,909 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:34:17,909 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:34:17,954 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:34:18,743 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:34:18,744 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:34:18,773 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:34:18,824 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:34:18,824 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:34:18,864 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:34:18,955 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:34:18,955 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:34:39,550 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:34:39,634 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:34:39,634 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:34:39,650 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:34:39,652 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:34:39,652 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:34:39,694 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:34:39,700 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:34:39,700 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:34:39,757 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:34:39,767 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:34:39,767 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:34:39,781 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:34:40,617 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:34:40,617 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:34:40,649 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:34:40,679 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:34:40,680 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:34:40,712 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:34:41,008 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:34:41,008 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:34:41,097 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:34:41,100 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:34:41,100 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:34:41,159 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:34:41,160 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:34:41,160 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:34:41,186 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:34:41,191 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:34:41,191 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:34:41,210 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:34:41,949 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov21_22-34-41_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-21 22:34:41,954 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-21 22:34:41,954 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-21 22:34:42,743 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:34:42,744 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:35:21,970 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:35:22,105 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:35:22,106 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:35:22,125 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:35:22,128 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:35:22,128 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:35:22,148 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:35:22,155 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:35:22,155 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:35:22,178 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:35:22,189 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:35:22,189 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:35:22,207 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:35:22,962 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:35:22,962 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:35:22,973 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:35:22,999 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:35:23,000 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:35:23,017 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:35:23,289 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:35:23,289 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:35:23,307 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:35:23,309 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:35:23,309 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:35:23,323 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:35:23,325 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:35:23,325 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:35:23,342 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:35:23,348 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:35:23,349 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 22:35:23,392 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 22:35:24,146 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov21_22-35-24_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-21 22:35:24,150 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-21 22:35:24,150 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-21 22:35:25,076 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 22:35:25,076 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:05:59,804 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:05:59,810 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:05:59,811 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:05:59,844 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:05:59,849 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:05:59,850 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:06:00,064 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:06:00,072 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:06:00,073 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:06:01,983 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:06:01,997 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:06:01,997 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:06:02,046 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:06:02,052 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:06:02,052 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:06:03,948 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:06:03,954 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:06:03,954 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:06:03,985 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:06:03,990 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:06:03,990 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:07:14,689 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:07:15,048 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:07:15,048 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:07:15,065 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:07:15,068 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:07:15,068 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:07:15,098 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:07:15,142 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:07:15,142 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:07:15,163 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:07:15,174 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:07:15,174 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:07:15,218 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:07:15,903 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:07:15,903 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:07:15,913 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:07:15,938 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:07:15,938 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:07:15,952 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:07:16,205 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:07:16,205 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:07:16,228 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:07:16,230 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:07:16,230 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:07:16,248 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:07:16,251 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:07:16,251 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:07:16,264 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:07:16,270 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:07:16,270 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:07:16,289 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:07:17,273 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov21_23-07-17_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-21 23:07:17,276 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-21 23:07:17,276 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-21 23:07:18,045 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:07:18,046 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:08:33,135 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:08:33,207 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:08:33,208 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:08:33,232 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:08:33,233 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:08:33,233 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:08:33,252 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:08:33,259 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:08:33,259 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:08:33,274 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:08:33,284 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:08:33,284 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:08:33,302 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:08:33,984 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:08:33,984 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:08:33,995 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:08:34,018 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:08:34,018 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:08:34,033 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:08:34,319 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:08:34,319 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:08:34,335 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:08:34,336 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:08:34,336 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:08:34,350 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:08:34,352 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:08:34,352 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:08:34,365 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:08:34,370 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:08:34,370 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:08:34,383 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:08:35,196 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov21_23-08-35_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-21 23:08:35,200 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-21 23:08:35,200 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-21 23:08:35,994 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:08:35,994 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:11:26,702 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:11:26,811 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:11:26,812 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:11:26,831 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:11:26,834 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:11:26,835 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:11:26,857 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:11:26,863 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:11:26,863 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:11:26,880 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:11:26,889 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:11:26,889 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:11:26,905 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:11:27,569 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:11:27,569 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:11:27,579 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:11:27,600 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:11:27,600 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:11:27,610 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:11:27,855 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:11:27,855 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:11:27,870 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:11:27,871 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:11:27,871 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:11:27,888 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:11:27,889 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:11:27,889 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:11:27,903 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:11:27,909 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:11:27,909 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:11:27,937 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:11:28,648 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov21_23-11-28_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-21 23:11:28,653 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-21 23:11:28,654 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-21 23:11:29,395 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:11:29,395 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:21:05,496 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:21:05,582 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:21:05,582 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:21:05,604 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:21:05,607 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:21:05,607 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:21:05,629 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:21:05,638 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:21:05,638 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:21:05,665 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:21:05,677 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:21:05,678 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:21:05,706 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:21:06,438 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:21:06,438 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:21:06,451 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:21:06,473 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:21:06,473 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:21:06,483 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:21:06,737 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:21:06,737 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:21:06,757 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:21:06,760 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:21:06,761 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:21:06,775 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:21:06,777 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:21:06,777 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:21:06,791 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:21:06,797 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:21:06,797 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:21:06,814 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:21:06,869 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:21:06,870 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:21:21,673 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:21:21,679 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:21:21,679 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:21:21,710 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:21:21,716 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:21:21,716 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:21:53,793 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:21:53,800 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:21:53,800 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:21:53,827 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:21:53,834 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:21:53,834 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:21:56,099 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:21:56,104 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:21:56,104 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:22:01,513 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:22:01,614 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:22:01,614 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:22:01,630 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:22:01,633 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:22:01,633 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:22:01,647 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:22:01,673 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:22:01,673 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:22:01,682 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:22:01,693 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:22:01,693 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:22:01,710 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:22:02,391 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:22:02,392 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:22:02,401 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:22:02,432 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:22:02,432 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:22:02,483 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:22:02,756 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:22:02,756 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:22:02,772 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:22:02,775 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:22:02,775 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:22:02,793 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:22:02,795 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:22:02,795 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:22:02,814 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:22:02,820 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:22:02,820 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:22:02,837 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:22:04,313 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov21_23-22-04_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-21 23:22:04,317 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-21 23:22:04,318 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-21 23:22:05,232 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:22:05,232 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:24:52,031 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:24:52,038 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:24:52,038 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:24:52,071 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:24:52,076 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:24:52,076 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:24:52,467 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:24:52,472 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:24:52,472 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:24:52,732 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:24:52,738 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:24:52,738 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:24:52,871 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:24:52,876 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:24:52,876 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:24:53,112 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:24:53,120 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:24:53,120 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:24:53,407 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:24:53,411 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:24:53,411 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:24:53,689 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:24:53,694 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:24:53,694 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:24:53,781 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:24:53,786 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:24:53,786 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:24:55,019 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:24:55,160 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:24:55,160 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:25:10,509 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:25:10,616 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:25:10,616 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:25:10,630 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:25:10,633 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:25:10,633 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:25:10,649 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:25:10,656 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:25:10,656 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:25:10,681 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:25:10,689 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:25:10,689 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:25:10,703 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:25:11,367 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:25:11,367 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:25:11,377 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:25:11,399 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:25:11,399 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:25:11,410 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:25:11,659 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:25:11,659 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:25:11,678 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:25:11,679 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:25:11,679 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:25:11,693 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:25:11,696 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:25:11,696 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:25:11,720 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:25:11,728 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:25:11,728 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:25:11,752 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:25:11,898 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:25:11,898 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:26:54,513 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:26:54,521 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:26:54,521 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:26:54,543 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:26:54,552 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:26:54,552 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-21 23:27:05,702 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-21 23:27:06,498 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov21_23-27-06_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-21 23:27:06,502 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-21 23:27:06,502 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-21 23:27:07,344 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-21 23:27:07,344 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:39:24,559 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:39:24,942 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:39:24,942 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:39:24,957 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:39:24,959 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:39:24,959 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:39:24,977 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:39:25,010 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:39:25,010 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:39:25,023 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:39:25,034 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:39:25,034 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:39:25,057 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:39:25,862 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:39:25,862 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:39:25,885 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:39:25,925 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:39:25,925 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:39:25,983 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:39:26,280 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:39:26,281 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:39:26,305 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:39:26,308 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:39:26,308 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:39:26,327 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:39:26,329 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:39:26,329 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:39:26,344 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:39:26,354 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:39:26,354 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:39:26,368 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:39:26,431 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:39:26,432 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:39:32,847 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:39:32,854 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:39:32,855 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:39:32,890 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:39:32,895 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:39:32,896 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:39:33,295 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:39:33,300 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:39:33,300 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:40:13,442 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:40:13,539 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:40:13,541 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:40:13,560 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:40:13,561 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:40:13,561 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:40:13,576 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:40:13,583 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:40:13,583 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:40:13,597 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:40:13,608 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:40:13,609 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:40:13,623 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:40:14,419 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:40:14,419 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:40:14,444 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:40:14,471 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:40:14,471 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:40:14,517 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:40:15,822 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:40:15,822 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:40:15,842 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:40:15,844 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:40:15,844 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:40:15,860 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:40:15,862 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:40:15,862 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:40:15,876 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:40:15,880 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:40:15,881 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:40:15,895 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:40:16,745 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_04-40-16_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 04:40:16,749 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 04:40:16,749 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 04:40:17,528 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:40:17,528 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:41:47,242 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:41:47,247 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:41:47,248 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:41:47,271 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:41:47,309 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:41:47,309 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:41:47,320 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:41:47,340 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:41:47,340 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:41:47,502 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:41:47,506 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:41:47,510 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:42:03,757 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:42:03,855 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:42:03,856 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:42:03,880 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:42:03,883 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:42:03,883 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:42:03,896 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:42:03,905 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:42:03,905 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:42:03,958 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:42:03,970 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:42:03,971 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:42:04,005 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:42:04,764 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:42:04,764 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:42:04,778 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:42:04,809 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:42:04,809 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:42:04,827 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:42:05,095 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:42:05,095 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:42:05,115 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:42:05,118 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:42:05,118 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:42:05,159 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:42:05,161 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:42:05,161 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:42:05,221 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:42:05,229 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:42:05,229 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:42:05,318 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:42:06,045 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_04-42-05_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 04:42:06,048 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 04:42:06,048 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 04:42:06,858 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:42:06,858 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:42:46,952 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:42:46,989 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:42:47,004 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:42:47,059 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:42:47,078 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:42:47,079 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:42:47,128 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:42:47,139 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:42:47,141 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:42:47,197 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:42:47,215 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:42:47,216 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:42:47,265 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:42:47,277 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:42:47,278 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:42:47,391 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:42:47,403 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:42:47,404 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:42:47,462 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:42:47,476 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:42:47,476 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:42:47,533 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:42:47,547 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:42:47,547 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:42:47,602 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:42:47,615 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:42:47,620 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:42:47,676 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:42:47,689 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:42:47,689 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:42:47,743 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:42:47,760 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:42:47,760 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:10,215 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:10,301 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:10,301 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:10,323 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:10,326 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:10,326 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:10,346 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:10,353 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:10,353 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:10,367 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:10,381 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:10,381 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:10,414 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:11,178 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:11,178 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:11,188 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:11,216 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:11,216 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:11,233 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:11,492 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:11,492 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:11,510 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:11,512 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:11,512 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:11,530 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:11,533 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:11,533 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:11,557 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:11,566 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:11,566 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:11,588 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:12,305 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_04-43-12_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 04:43:12,308 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 04:43:12,308 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 04:43:13,134 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:13,134 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:46,030 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:46,035 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:46,035 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:46,064 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:46,096 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:46,096 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:46,134 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:46,137 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:46,139 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:47,467 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:47,475 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:47,478 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:50,546 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:50,650 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:50,651 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:50,674 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:50,677 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:50,677 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:50,729 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:50,736 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:50,736 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:50,746 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:50,759 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:50,759 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:50,775 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:51,499 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:51,499 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:51,518 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:51,547 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:51,547 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:51,562 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:52,257 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:52,257 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:52,280 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:52,282 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:52,282 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:52,335 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:52,338 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:52,338 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:52,386 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:52,406 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:52,406 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:43:52,472 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:43:53,167 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_04-43-53_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 04:43:53,172 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 04:43:53,173 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 04:43:53,966 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:43:53,967 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:46:32,187 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:46:32,212 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:46:32,212 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:46:32,297 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:46:32,315 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:46:32,315 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:46:32,382 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:46:32,398 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:46:32,398 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:46:32,469 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:46:32,505 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:46:32,505 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:46:32,554 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:46:32,574 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:46:32,574 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:46:32,626 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:46:32,640 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:46:32,640 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:46:32,696 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:46:32,711 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:46:32,711 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:46:32,774 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:46:32,787 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:46:32,787 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:46:32,847 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:46:32,860 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:46:32,867 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:46:32,920 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:46:32,934 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:46:32,935 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:46:32,987 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:46:33,002 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:46:33,004 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:46:54,296 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:46:54,683 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:46:54,683 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:46:54,711 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:46:54,714 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:46:54,714 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:46:54,741 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:46:54,766 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:46:54,767 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:46:54,783 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:46:54,793 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:46:54,793 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:46:54,813 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:46:55,504 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:46:55,504 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:46:55,516 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:46:55,537 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:46:55,537 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:46:55,569 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:46:55,840 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:46:55,840 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:46:55,855 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:46:55,858 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:46:55,858 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:46:55,871 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:46:55,873 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:46:55,873 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:46:55,886 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:46:55,905 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:46:55,905 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:46:55,930 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:46:56,095 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:46:56,095 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:47:16,979 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:47:16,988 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:47:16,988 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:47:17,022 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:47:17,026 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:47:17,026 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:47:17,287 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:47:17,294 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:47:17,294 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:47:17,380 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:47:17,408 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:47:17,408 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:47:22,533 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:47:22,620 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:47:22,620 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:47:22,637 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:47:22,638 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:47:22,638 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:47:22,665 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:47:22,671 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:47:22,671 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:47:22,682 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:47:22,692 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:47:22,692 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:47:22,728 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:47:23,453 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:47:23,453 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:47:23,464 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:47:23,486 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:47:23,486 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:47:23,496 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:47:23,751 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:47:23,751 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:47:23,766 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:47:23,768 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:47:23,768 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:47:23,781 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:47:23,782 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:47:23,782 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:47:23,796 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:47:23,817 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:47:23,817 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:47:23,862 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:47:24,634 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_04-47-24_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 04:47:24,637 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 04:47:24,637 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 04:47:25,426 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:47:25,426 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:53:00,606 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:53:00,688 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:53:00,688 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:53:00,707 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:53:00,709 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:53:00,709 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:53:00,725 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:53:00,731 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:53:00,731 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:53:00,743 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:53:00,753 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:53:00,753 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:53:00,770 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:53:01,509 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:53:01,509 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:53:01,519 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:53:01,543 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:53:01,543 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:53:01,588 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:53:01,871 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:53:01,871 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:53:01,905 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:53:01,908 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:53:01,909 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:53:01,935 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:53:01,937 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:53:01,937 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:53:01,960 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:53:01,980 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:53:01,980 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:53:02,012 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:53:03,203 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_04-53-03_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 04:53:03,205 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 04:53:03,205 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 04:53:03,924 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:53:03,924 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:53:24,499 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:53:24,506 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:53:24,507 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:53:24,530 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:53:24,535 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:53:24,536 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:53:27,154 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:53:27,252 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:53:27,252 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:53:27,269 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:53:27,272 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:53:27,272 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:53:27,294 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:53:27,299 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:53:27,299 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:53:27,311 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:53:27,321 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:53:27,321 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:53:27,345 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:53:28,107 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:53:28,107 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:53:28,118 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:53:28,141 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:53:28,141 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:53:28,153 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:53:28,407 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:53:28,407 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:53:28,434 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:53:28,437 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:53:28,439 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:53:28,538 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:53:28,540 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:53:28,540 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:53:28,570 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:53:28,590 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:53:28,590 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:53:28,630 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:53:29,338 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_04-53-29_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 04:53:29,342 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 04:53:29,343 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 04:53:30,097 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:53:30,098 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:55:28,184 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:55:28,233 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:55:28,233 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:55:28,284 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:55:28,301 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:55:28,301 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:55:28,368 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:55:28,387 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:55:28,387 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:55:28,458 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:55:28,486 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:55:28,487 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:55:28,582 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:55:28,606 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:55:28,606 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:55:28,703 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:55:28,723 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:55:28,723 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:55:28,781 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:55:28,794 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:55:28,794 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:55:28,853 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:55:28,865 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:55:28,865 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:55:28,921 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:55:28,934 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:55:28,938 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:55:28,990 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:55:29,003 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:55:29,003 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:55:29,055 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:55:29,078 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:55:29,078 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:56:33,371 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:56:33,377 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:56:33,377 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:56:33,402 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:56:33,407 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:56:33,407 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:56:33,671 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:56:33,676 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:56:33,676 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:56:51,733 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:56:51,823 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:56:51,824 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:56:51,852 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:56:51,855 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:56:51,855 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:56:51,923 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:56:51,949 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:56:51,949 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:56:51,994 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:56:52,003 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:56:52,003 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:56:52,018 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:56:52,745 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:56:52,745 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:56:52,755 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:56:52,809 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:56:52,809 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:56:52,819 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:56:53,076 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:56:53,076 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:56:53,094 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:56:53,096 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:56:53,096 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:56:53,108 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:56:53,110 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:56:53,111 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:56:53,123 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:56:53,124 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:56:53,125 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:56:53,137 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:56:53,154 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:56:53,154 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 04:56:53,189 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 04:56:54,037 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_04-56-53_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 04:56:54,041 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 04:56:54,041 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 04:56:54,796 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 04:56:54,796 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:00:55,762 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:00:55,784 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:00:55,789 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:00:55,862 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:00:55,880 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:00:55,881 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:00:55,930 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:00:55,944 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:00:55,944 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:00:55,996 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:00:56,014 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:00:56,014 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:00:56,063 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:00:56,081 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:00:56,081 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:00:56,130 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:00:56,144 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:00:56,144 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:00:56,200 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:00:56,215 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:00:56,216 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:00:56,280 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:00:56,294 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:00:56,294 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:00:56,352 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:00:56,366 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:00:56,371 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:00:56,422 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:00:56,434 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:00:56,435 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:00:56,491 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:00:56,508 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:00:56,508 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:01:19,523 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:01:19,628 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:01:19,628 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:01:19,666 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:01:19,670 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:01:19,670 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:01:19,741 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:01:19,746 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:01:19,746 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:01:19,762 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:01:19,773 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:01:19,774 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:01:19,792 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:01:20,483 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:01:20,483 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:01:20,494 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:01:20,517 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:01:20,517 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:01:20,532 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:01:20,789 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:01:20,790 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:01:20,808 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:01:20,810 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:01:20,810 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:01:20,822 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:01:20,824 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:01:20,824 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:01:20,838 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:01:20,857 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:01:20,857 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:01:20,872 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:01:23,392 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:01:23,392 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:01:23,422 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:01:23,426 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:01:23,426 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:01:23,453 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:01:24,547 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:01:24,547 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:01:24,585 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:01:24,588 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:01:24,588 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:01:24,606 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:01:24,633 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:01:24,633 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:01:24,650 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:01:24,677 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:01:24,677 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:05,584 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:05,594 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:05,594 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:05,671 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:05,692 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:05,692 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:05,711 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:05,718 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:05,718 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:05,751 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:05,756 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:05,756 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:05,929 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:05,937 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:05,937 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:05,978 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:05,983 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:05,983 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:21,382 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:21,393 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:21,393 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:21,436 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:21,441 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:21,441 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:21,515 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:21,522 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:21,522 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:21,556 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:21,561 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:21,561 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:21,694 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:21,704 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:21,704 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:21,739 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:21,744 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:21,744 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:23,913 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:24,006 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:24,007 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:24,027 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:24,031 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:24,031 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:24,051 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:24,058 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:24,058 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:24,070 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:24,079 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:24,079 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:24,103 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:24,906 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:24,906 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:24,916 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:24,946 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:24,946 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:24,956 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:25,203 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:25,203 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:25,219 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:25,221 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:25,221 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:25,242 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:25,244 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:25,246 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:25,293 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:25,317 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:25,318 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:25,400 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:27,948 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:27,948 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:27,987 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:27,990 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:27,990 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:28,048 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:28,629 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:28,629 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:28,640 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:28,642 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:28,642 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:28,660 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:28,668 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:28,668 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:28,688 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:28,717 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:28,717 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:36,373 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:36,446 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:36,446 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:36,466 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:36,469 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:36,469 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:36,483 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:36,488 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:36,488 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:36,498 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:36,510 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:36,510 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:36,528 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:37,242 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:37,242 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:37,257 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:37,284 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:37,285 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:37,297 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:37,594 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:37,594 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:37,610 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:37,613 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:37,613 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:37,626 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:37,627 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:37,627 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:37,639 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:37,658 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:37,658 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:37,688 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:39,893 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:39,893 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:39,918 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:39,922 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:39,922 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:39,940 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:40,540 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:40,540 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:40,556 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:40,557 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:40,557 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:40,570 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:40,577 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:40,577 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:04:40,590 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:04:40,615 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:04:40,615 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:10,864 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:10,880 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:10,887 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:11,017 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:11,035 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:11,035 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:11,090 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:11,104 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:11,104 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:11,160 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:11,178 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:11,178 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:11,245 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:11,261 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:11,265 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:11,318 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:11,332 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:11,332 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:11,392 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:11,406 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:11,410 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:11,461 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:11,473 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:11,474 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:11,530 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:11,548 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:11,548 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:11,599 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:11,612 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:11,617 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:11,697 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:11,720 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:11,720 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:23,619 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:23,732 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:23,733 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:23,752 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:23,754 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:23,755 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:23,785 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:23,809 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:23,809 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:23,832 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:24,599 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:24,599 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:24,610 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:24,633 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:24,633 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:24,651 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:24,932 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:24,932 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:24,967 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:24,971 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:24,972 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:24,990 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:24,991 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:24,991 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:25,011 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:25,033 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:25,033 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:25,066 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:27,341 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:27,341 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:27,368 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:28,083 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:28,083 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:28,093 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:28,094 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:28,094 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:28,108 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:28,115 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:28,115 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:09:28,129 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:09:28,154 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:09:28,154 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:11:43,165 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:11:43,258 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:11:43,258 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:11:43,275 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:11:43,277 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:11:43,278 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:11:43,299 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:11:43,308 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:11:43,308 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:11:43,337 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:11:44,043 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:11:44,043 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:11:44,055 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:11:44,078 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:11:44,078 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:11:44,088 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:11:44,366 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:11:44,366 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:11:44,386 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:11:44,389 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:11:44,389 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:11:44,405 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:11:44,407 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:11:44,407 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:11:44,424 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:11:44,444 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:11:44,445 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:11:44,489 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:11:45,359 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_05-11-45_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 05:11:45,363 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 05:11:45,363 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 05:11:46,214 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:11:46,214 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:17:57,543 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:17:57,552 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:17:57,552 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:17:57,569 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:17:57,574 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:17:57,574 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:18:07,831 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:18:07,914 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:18:07,914 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:18:07,934 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:18:07,938 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:18:07,938 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:18:07,978 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:18:07,985 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:18:07,986 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:18:08,025 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:18:08,753 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:18:08,753 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:18:08,770 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:18:08,796 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:18:08,796 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:18:08,813 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:18:09,103 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:18:09,103 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:18:09,138 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:18:09,140 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:18:09,140 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:18:09,161 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:18:09,164 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:18:09,164 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:18:09,184 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:18:09,209 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:18:09,209 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:18:09,235 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:18:10,387 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_05-18-10_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 05:18:10,389 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 05:18:10,389 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 05:18:12,467 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_05-18-11_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 05:18:12,471 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 05:18:12,471 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 05:18:13,482 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:18:13,483 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:25:49,272 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:25:49,365 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:25:49,365 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:25:49,382 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:25:49,384 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:25:49,384 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:25:49,409 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:25:49,416 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:25:49,416 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:25:49,430 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:25:50,166 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:25:50,167 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:25:50,180 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:25:50,218 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:25:50,218 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:25:50,239 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:25:50,572 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:25:50,573 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:25:50,604 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:25:50,608 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:25:50,608 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:25:50,634 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:25:50,636 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:25:50,637 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:25:50,663 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:25:50,688 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:25:50,688 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 05:25:50,762 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 05:25:51,591 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_05-25-51_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 05:25:51,596 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 05:25:51,596 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 05:25:52,111 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 05:25:52,111 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:42:34,268 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:42:34,936 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:42:34,937 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:42:35,018 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:42:35,047 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:42:35,047 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:42:35,065 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:42:35,213 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:42:35,213 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:42:35,238 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:42:36,327 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:42:36,328 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:42:36,341 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:42:36,375 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:42:36,376 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:42:36,390 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:42:36,871 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:42:36,872 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:42:36,894 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:42:36,897 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:42:36,897 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:42:36,926 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:42:36,929 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:42:36,929 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:42:37,030 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:42:37,082 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:42:37,082 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:42:37,106 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:42:38,219 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_17-42-38_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 17:42:38,229 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 17:42:38,230 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 17:42:38,748 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:42:38,748 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:42:58,060 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:42:58,813 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_17-42-58_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 17:42:58,816 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 17:42:58,816 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 17:42:59,117 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:42:59,117 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:43:52,224 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:43:52,308 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:43:52,308 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:43:52,330 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:43:52,333 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:43:52,333 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:43:52,352 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:43:52,363 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:43:52,363 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:43:52,377 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:43:53,129 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:43:53,129 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:43:53,146 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:43:53,191 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:43:53,192 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:43:53,210 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:43:53,537 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:43:53,537 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:43:53,567 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:43:53,569 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:43:53,569 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:43:53,588 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:43:53,590 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:43:53,590 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:43:53,604 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:43:53,625 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:43:53,625 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:43:53,653 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:43:54,361 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_17-43-54_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 17:43:54,365 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 17:43:54,365 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 17:43:54,720 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:43:54,720 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:44:15,361 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:44:15,481 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:44:15,481 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:44:15,501 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:44:15,504 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:44:15,504 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:44:15,522 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:44:15,531 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:44:15,531 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:44:15,546 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:44:16,290 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:44:16,290 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:44:16,303 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:44:16,335 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:44:16,335 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:44:16,348 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:44:16,635 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:44:16,635 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:44:16,653 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:44:16,655 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:44:16,655 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:44:16,689 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:44:16,692 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:44:16,692 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:44:16,711 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:44:16,737 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:44:16,737 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:44:16,760 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:44:17,549 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_17-44-17_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 17:44:17,553 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 17:44:17,554 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 17:44:18,791 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_17-44-18_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 17:44:18,795 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 17:44:18,796 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 17:44:19,792 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_17-44-19_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 17:44:19,795 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 17:44:19,795 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 17:44:22,664 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_17-44-22_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 17:44:22,668 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 17:44:22,668 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 17:44:23,762 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_17-44-23_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 17:44:23,766 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 17:44:23,767 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 17:44:24,727 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_17-44-24_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 17:44:24,732 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 17:44:24,732 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 17:44:25,727 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_17-44-25_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 17:44:25,730 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 17:44:25,730 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 17:44:26,135 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:44:26,135 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:46:09,755 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:46:09,838 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:46:09,838 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:46:09,855 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:46:09,857 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:46:09,858 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:46:09,877 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:46:09,886 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:46:09,886 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:46:09,901 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:46:10,648 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:46:10,648 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:46:10,671 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:46:10,695 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:46:10,695 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:46:10,755 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:46:11,088 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:46:11,088 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:46:11,126 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:46:11,128 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:46:11,129 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:46:11,143 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:46:11,145 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:46:11,145 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:46:11,163 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:46:11,184 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:46:11,184 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:46:11,200 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:46:11,927 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_17-46-11_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 17:46:11,931 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 17:46:11,932 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 17:46:13,278 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_17-46-13_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 17:46:13,280 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 17:46:13,280 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 17:46:14,229 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_17-46-14_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 17:46:14,231 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 17:46:14,231 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 17:46:15,262 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_17-46-15_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 17:46:15,265 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 17:46:15,265 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 17:46:16,271 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_17-46-16_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 17:46:16,274 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 17:46:16,274 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 17:46:17,239 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_17-46-17_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 17:46:17,241 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 17:46:17,241 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 17:46:18,279 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_17-46-18_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 17:46:18,281 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 17:46:18,281 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 17:46:18,685 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:46:18,686 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:54:19,677 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:54:19,685 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:54:19,685 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:54:19,729 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:54:19,734 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:54:19,735 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:54:19,788 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:54:19,794 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:54:19,794 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:54:20,839 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:54:20,847 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:54:20,847 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:54:20,874 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:54:20,879 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:54:20,880 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:54:24,902 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:54:25,008 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:54:25,008 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:54:25,026 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:54:25,029 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:54:25,029 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:54:25,055 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:54:25,061 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:54:25,061 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:54:25,111 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:54:25,837 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:54:25,837 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:54:25,848 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:54:25,872 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:54:25,872 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:54:25,888 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:54:26,155 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:54:26,156 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:54:26,178 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:54:26,180 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:54:26,180 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:54:26,200 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:54:26,202 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:54:26,202 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:54:26,236 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:54:26,260 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:54:26,260 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:54:26,290 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:54:27,131 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_17-54-27_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 17:54:27,135 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 17:54:27,135 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 17:54:27,477 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:54:27,477 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:55:43,423 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:55:43,430 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:55:43,430 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:55:43,451 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:55:43,458 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:55:43,458 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:55:46,062 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:55:46,136 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:55:46,136 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:55:46,166 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:55:46,168 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:55:46,168 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:55:46,180 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:55:46,187 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:55:46,187 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:55:46,202 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:55:46,895 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:55:46,895 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:55:46,906 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:55:46,928 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:55:46,928 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:55:46,939 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:55:47,185 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:55:47,185 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:55:47,213 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:55:47,216 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:55:47,217 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:55:47,242 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:55:47,244 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:55:47,244 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:55:47,298 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:55:47,323 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:55:47,323 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:55:47,356 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:55:47,454 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:55:47,455 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:56:31,325 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:56:31,409 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:56:31,409 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:56:31,434 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:56:31,437 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:56:31,437 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:56:31,457 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:56:31,461 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:56:31,462 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:56:31,487 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:56:32,209 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:56:32,209 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:56:32,219 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:56:32,243 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:56:32,243 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:56:32,254 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:56:32,550 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:56:32,550 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:56:32,581 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:56:32,584 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:56:32,585 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:56:32,610 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:56:32,613 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:56:32,613 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:56:32,660 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:56:32,690 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:56:32,690 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:56:32,725 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:56:32,834 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:56:32,834 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:56:38,412 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:56:38,417 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:56:38,418 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:56:38,439 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:56:38,446 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:56:38,447 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:57:47,024 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:57:47,096 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:57:47,097 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:57:47,118 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:57:47,120 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:57:47,120 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:57:47,138 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:57:47,144 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:57:47,144 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:57:47,158 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:57:47,821 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:57:47,822 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:57:47,834 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:57:47,855 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:57:47,855 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:57:47,866 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:57:48,142 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:57:48,143 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:57:48,158 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:57:48,161 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:57:48,161 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:57:48,174 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:57:48,176 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:57:48,176 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:57:48,189 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:57:48,208 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:57:48,208 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 17:57:48,238 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 17:57:49,010 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_17-57-48_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 17:57:49,013 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 17:57:49,013 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 17:57:49,345 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 17:57:49,345 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:02:41,118 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:02:41,229 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:02:41,229 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:02:41,278 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:02:41,280 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:02:41,280 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:02:41,310 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:02:41,315 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:02:41,316 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:02:41,335 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:02:42,115 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:02:42,115 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:02:42,127 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:02:42,149 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:02:42,149 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:02:42,165 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:02:42,471 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:02:42,471 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:02:42,495 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:02:42,498 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:02:42,498 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:02:42,514 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:02:42,517 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:02:42,518 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:02:42,583 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:02:42,607 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:02:42,607 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:02:42,646 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:02:43,787 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_18-02-43_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 18:02:43,792 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 18:02:43,792 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 18:02:44,537 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:02:44,537 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:04:14,540 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:04:14,547 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:04:14,547 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:04:14,837 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:04:14,843 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:04:14,843 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:04:14,971 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:04:14,976 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:04:14,976 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:04:15,133 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:04:15,142 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:04:15,142 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:04:15,374 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:04:15,380 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:04:15,380 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:04:15,591 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:04:15,600 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:04:15,600 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:04:15,698 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:04:15,705 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:04:15,705 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:04:19,010 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:04:19,096 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:04:19,096 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:04:19,114 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:04:19,117 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:04:19,117 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:04:19,142 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:04:19,147 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:04:19,148 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:04:19,164 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:04:19,914 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:04:19,914 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:04:19,926 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:04:19,951 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:04:19,952 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:04:19,964 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:04:20,292 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:04:20,292 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:04:20,324 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:04:20,326 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:04:20,327 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:04:20,345 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:04:20,347 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:04:20,348 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:04:20,377 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:04:20,404 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:04:20,404 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:04:20,450 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:04:21,598 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_18-04-21_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 18:04:21,602 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 18:04:21,602 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 18:04:21,914 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:04:21,914 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:05:27,047 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:05:27,131 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:05:27,131 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:05:27,147 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:05:27,150 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:05:27,151 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:05:27,173 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:05:27,179 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:05:27,179 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:05:27,193 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:05:27,979 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:05:27,979 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:05:27,993 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:05:28,017 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:05:28,017 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:05:28,029 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:05:28,332 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:05:28,333 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:05:28,379 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:05:28,382 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:05:28,383 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:05:28,414 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:05:28,416 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:05:28,416 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:05:28,443 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:05:28,464 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:05:28,464 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:05:28,487 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:05:29,239 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_18-05-29_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 18:05:29,243 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 18:05:29,243 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 18:05:29,622 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:05:29,622 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:12,101 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:12,187 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:12,187 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:12,204 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:12,206 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:12,206 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:12,226 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:12,232 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:12,232 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:12,246 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:13,001 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:13,001 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:13,015 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:13,045 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:13,045 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:13,065 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:13,395 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:13,396 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:13,436 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:13,439 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:13,439 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:13,490 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:13,492 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:13,493 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:13,521 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:13,526 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:13,526 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:13,561 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:14,262 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_18-06-14_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 18:06:14,265 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 18:06:14,265 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 18:06:14,600 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:14,601 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:34,969 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:35,051 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:35,051 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:35,072 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:35,075 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:35,075 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:35,095 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:35,106 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:35,106 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:35,131 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:35,902 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:35,902 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:35,944 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:35,970 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:35,970 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:35,984 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:36,309 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:36,309 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:36,330 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:36,333 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:36,333 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:36,373 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:36,374 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:36,374 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:36,419 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:36,424 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:36,425 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:36,582 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:37,378 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_18-06-37_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 18:06:37,381 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 18:06:37,381 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 18:06:38,201 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:38,202 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:54,677 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:54,761 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:54,761 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:54,776 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:54,779 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:54,779 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:54,797 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:54,804 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:54,804 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:54,818 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:55,585 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:55,585 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:55,600 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:55,622 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:55,622 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:55,636 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:55,969 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:55,970 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:56,059 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:56,062 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:56,062 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:56,077 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:56,080 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:56,080 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:56,095 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:56,116 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:56,116 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:06:56,136 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:06:56,888 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_18-06-56_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 18:06:56,890 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 18:06:56,890 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 18:06:57,716 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:06:57,716 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:07:18,815 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:07:18,921 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:07:18,922 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:07:18,936 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:07:18,939 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:07:18,939 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:07:18,956 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:07:18,962 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:07:18,962 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:07:18,985 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:07:19,712 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:07:19,712 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:07:19,724 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:07:19,748 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:07:19,748 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:07:19,762 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:07:20,016 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:07:20,016 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:07:20,045 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:07:20,047 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:07:20,047 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:07:20,064 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:07:20,066 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:07:20,066 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:07:20,083 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:07:20,106 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:07:20,106 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:07:20,128 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:07:21,299 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_18-07-20_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 18:07:21,302 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 18:07:21,302 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 18:07:23,436 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_18-07-22_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 18:07:23,440 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 18:07:23,441 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 18:07:24,505 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:07:24,506 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:08:05,962 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:08:05,969 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:08:05,971 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:08:05,991 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:08:05,996 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:08:05,997 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:08:12,854 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:08:12,927 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:08:12,928 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:08:12,959 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:08:12,960 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:08:12,961 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:08:12,973 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:08:12,979 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:08:12,979 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:08:12,994 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:08:13,746 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:08:13,746 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:08:13,758 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:08:13,783 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:08:13,783 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:08:13,798 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:08:14,148 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:08:14,149 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:08:14,168 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:08:14,171 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:08:14,171 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:08:14,192 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:08:14,193 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:08:14,193 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:08:14,220 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:08:14,240 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:08:14,240 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:08:14,280 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:08:15,038 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_18-08-14_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 18:08:15,041 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 18:08:15,041 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 18:08:15,896 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:08:15,896 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:08:38,006 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:08:38,089 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:08:38,089 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:08:38,131 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:08:38,133 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:08:38,133 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:08:38,162 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:08:38,170 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:08:38,170 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:08:38,221 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:08:38,978 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:08:38,978 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:08:38,992 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:08:39,018 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:08:39,018 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:08:39,057 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:08:39,391 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:08:39,391 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:08:39,479 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:08:39,481 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:08:39,481 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:08:39,506 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:08:39,509 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:08:39,509 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:08:39,561 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:08:39,581 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:08:39,581 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:08:39,692 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:08:40,795 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_18-08-40_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 18:08:40,797 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 18:08:40,797 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 18:08:41,157 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:08:41,157 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:09:23,941 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:09:24,036 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:09:24,036 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:09:24,062 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:09:24,063 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:09:24,063 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:09:24,081 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:09:24,092 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:09:24,092 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:09:24,115 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:09:24,896 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:09:24,897 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:09:24,909 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:09:24,934 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:09:24,934 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:09:24,956 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:09:25,258 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:09:25,258 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:09:25,308 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:09:25,310 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:09:25,310 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:09:25,334 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:09:25,336 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:09:25,337 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:09:25,354 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:09:25,375 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:09:25,375 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:09:25,395 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:09:26,494 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_18-09-26_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 18:09:26,496 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 18:09:26,496 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 18:09:26,852 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:09:26,853 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:09:41,068 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:09:41,161 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:09:41,162 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:09:41,193 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:09:41,195 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:09:41,195 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:09:41,211 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:09:41,215 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:09:41,215 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:09:41,262 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:09:42,015 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:09:42,015 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:09:42,033 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:09:42,059 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:09:42,059 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:09:42,076 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:09:42,919 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:09:42,919 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:09:42,944 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:09:42,947 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:09:42,947 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:09:42,989 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:09:42,992 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:09:42,992 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:09:43,026 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:09:43,048 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:09:43,048 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:09:43,113 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:09:44,171 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_18-09-43_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 18:09:44,174 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 18:09:44,174 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 18:09:46,285 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_18-09-45_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 18:09:46,288 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 18:09:46,288 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 18:09:47,403 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:09:47,403 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:10:34,622 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:10:34,717 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:10:34,717 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:10:34,746 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:10:34,749 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:10:34,749 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:10:34,768 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:10:34,774 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:10:34,774 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:10:34,802 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:10:35,666 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:10:35,666 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:10:35,687 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:10:35,724 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:10:35,726 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:10:35,768 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:10:36,094 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:10:36,094 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:10:36,130 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:10:36,134 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:10:36,134 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:10:36,153 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:10:36,155 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:10:36,155 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:10:36,189 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:10:36,210 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:10:36,210 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:10:36,279 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:10:37,335 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_18-10-36_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 18:10:37,338 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 18:10:37,338 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 18:10:37,710 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:10:37,710 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:16:50,645 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:16:50,763 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:16:50,763 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:16:50,798 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:16:50,801 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:16:50,801 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:16:50,877 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:16:50,885 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:16:50,886 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:16:50,972 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:16:51,852 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:16:51,852 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:16:51,866 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:16:51,912 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:16:51,912 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:16:51,944 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:16:52,286 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:16:52,287 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:16:52,320 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:16:52,325 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:16:52,325 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:16:52,467 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:16:52,471 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:16:52,471 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:16:52,498 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:16:52,520 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:16:52,520 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:16:52,559 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:16:53,855 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_18-16-53_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 18:16:53,859 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 18:16:53,859 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 18:16:54,159 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:16:54,159 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:17:12,072 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:17:12,080 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:17:12,080 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:17:12,125 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:17:12,130 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:17:12,132 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:17:12,764 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:17:12,768 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:17:12,769 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:17:13,212 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:17:13,222 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:17:13,222 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:17:20,154 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:17:20,248 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:17:20,249 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:17:20,270 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:17:20,273 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:17:20,273 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:17:20,312 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:17:20,319 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:17:20,319 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:17:20,376 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:17:21,193 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:17:21,194 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:17:21,205 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:17:21,241 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:17:21,241 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:17:21,252 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:17:21,574 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:17:21,574 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:17:21,601 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:17:21,603 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:17:21,604 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:17:21,628 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:17:21,629 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:17:21,629 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:17:21,644 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:17:21,664 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:17:21,664 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:17:21,681 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:17:22,768 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_18-17-22_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 18:17:22,771 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 18:17:22,771 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 18:17:23,132 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:17:23,132 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:21:49,866 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:21:49,948 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:21:49,948 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:21:49,980 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:21:49,982 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:21:49,983 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:21:50,021 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:21:50,028 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:21:50,028 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:21:50,067 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:21:50,909 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:21:50,909 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:21:50,922 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:21:50,952 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:21:50,952 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:21:50,965 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:21:51,288 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:21:51,288 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:21:51,312 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:21:51,314 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:21:51,314 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:21:51,329 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:21:51,331 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:21:51,331 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:21:51,346 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:21:51,368 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:21:51,368 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 18:21:51,384 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 18:21:52,534 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_18-21-52_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 18:21:52,537 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 18:21:52,537 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 18:21:52,905 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 18:21:52,905 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:09:28,777 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:09:28,784 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:09:28,784 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:09:28,812 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:09:28,818 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:09:28,818 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:09:30,609 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:09:30,615 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:09:30,615 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:09:30,632 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:09:30,638 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:09:30,639 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:09:34,274 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:09:34,477 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:09:34,477 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:09:34,514 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:09:34,517 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:09:34,517 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:09:34,566 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:09:34,602 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:09:34,602 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:09:34,622 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:09:35,483 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:09:35,483 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:09:35,499 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:09:35,526 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:09:35,526 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:09:35,545 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:09:35,822 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:09:35,823 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:09:35,849 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:09:35,852 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:09:35,852 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:09:35,885 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:09:35,888 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:09:35,888 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:09:35,918 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:09:35,939 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:09:35,939 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:09:35,965 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:09:36,862 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-09-36_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:09:36,866 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:09:36,867 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:09:37,321 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:09:37,322 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:11:29,817 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:11:29,828 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:11:29,828 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:11:32,059 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:11:32,068 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:11:32,068 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:11:35,522 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:11:35,649 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:11:35,650 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:11:35,672 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:11:35,675 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:11:35,675 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:11:35,707 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:11:35,715 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:11:35,715 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:11:35,731 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:11:36,536 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:11:36,536 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:11:36,550 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:11:36,576 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:11:36,577 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:11:36,608 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:11:37,010 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:11:37,010 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:11:37,041 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:11:37,044 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:11:37,044 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:11:37,064 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:11:37,067 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:11:37,067 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:11:37,127 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:11:37,154 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:11:37,155 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:11:37,250 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:11:38,014 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-11-37_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:11:38,020 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:11:38,020 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:11:38,460 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:11:38,460 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:13:58,311 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:13:58,412 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:13:58,412 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:13:58,433 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:13:58,437 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:13:58,437 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:13:58,486 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:13:58,516 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:13:58,516 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:13:58,550 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:13:59,292 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:13:59,292 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:13:59,309 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:13:59,350 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:13:59,350 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:13:59,364 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:13:59,679 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:13:59,679 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:13:59,725 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:13:59,728 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:13:59,728 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:13:59,752 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:13:59,755 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:13:59,755 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:13:59,770 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:13:59,794 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:13:59,796 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:13:59,827 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:14:00,806 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-14-00_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:14:00,809 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:14:00,809 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:14:01,165 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:14:01,165 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:14:49,040 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:14:49,047 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:14:49,047 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:14:49,175 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:14:49,181 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:14:49,182 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:14:49,215 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:14:49,221 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:14:49,222 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:14:49,239 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:14:49,245 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:14:49,246 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:14:49,279 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:14:49,285 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:14:49,285 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:14:51,471 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:14:52,214 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-14-52_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:14:52,218 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:14:52,218 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:14:52,611 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:14:52,611 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:15:09,474 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:15:09,583 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:15:09,584 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:15:09,625 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:15:09,627 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:15:09,627 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:15:09,664 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:15:09,671 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:15:09,671 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:15:09,694 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:15:10,403 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:15:10,403 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:15:10,418 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:15:10,449 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:15:10,449 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:15:10,465 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:15:10,740 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:15:10,741 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:15:10,766 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:15:10,769 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:15:10,769 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:15:10,810 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:15:10,812 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:15:10,813 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:15:10,851 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:15:10,879 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:15:10,880 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:15:10,943 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:15:11,640 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-15-11_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:15:11,644 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:15:11,644 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:15:12,043 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:15:12,043 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:16:42,937 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:16:42,944 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:16:42,944 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:16:42,984 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:16:42,989 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:16:42,989 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:16:45,286 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:16:46,550 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-16-46_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:16:46,555 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:16:46,556 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:16:46,987 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:16:46,987 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:17:32,898 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:17:32,907 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:17:32,907 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:17:32,983 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:17:33,014 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:17:33,015 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:17:33,036 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:17:33,042 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:17:33,042 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:17:33,324 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:17:33,341 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:17:33,342 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:17:34,981 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:17:34,989 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:17:34,989 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:17:35,438 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:17:35,445 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:17:35,445 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:17:35,548 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:17:35,557 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:17:35,557 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:17:35,754 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:17:35,760 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:17:35,761 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:17:35,947 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:17:35,952 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:17:35,953 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:17:38,894 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:17:38,983 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:17:38,983 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:17:39,027 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:17:39,029 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:17:39,029 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:17:39,046 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:17:39,055 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:17:39,055 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:17:39,089 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:17:39,933 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:17:39,933 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:17:39,946 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:17:39,973 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:17:39,973 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:17:39,988 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:17:40,312 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:17:40,313 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:17:40,343 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:17:40,346 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:17:40,346 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:17:40,366 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:17:40,367 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:17:40,368 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:17:40,385 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:17:40,408 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:17:40,408 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:17:40,440 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:17:41,170 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-17-41_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:17:41,174 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:17:41,174 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:17:41,564 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:17:41,565 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:18:52,322 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:18:52,416 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:18:52,416 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:18:52,438 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:18:52,440 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:18:52,440 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:18:52,519 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:18:52,526 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:18:52,526 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:18:52,619 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:18:53,438 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:18:53,439 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:18:53,451 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:18:53,484 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:18:53,484 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:18:53,500 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:18:53,811 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:18:53,811 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:18:53,844 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:18:53,847 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:18:53,847 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:18:53,872 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:18:53,874 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:18:53,875 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:18:53,918 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:18:53,947 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:18:53,947 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:18:54,065 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:18:55,308 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:18:55,308 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:19:09,067 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:19:09,150 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:19:09,150 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:19:09,188 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:19:09,190 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:19:09,190 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:19:09,215 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:19:09,224 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:19:09,224 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:19:09,242 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:19:10,052 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:19:10,052 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:19:10,083 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:19:10,127 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:19:10,127 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:19:10,174 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:19:10,508 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:19:10,508 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:19:10,545 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:19:10,547 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:19:10,547 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:19:10,564 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:19:10,565 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:19:10,565 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:19:10,605 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:19:10,626 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:19:10,626 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:19:10,669 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:19:11,525 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:19:11,525 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:19:52,549 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:19:52,554 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:19:52,554 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:19:55,754 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:19:55,850 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:19:55,850 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:19:55,870 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:19:55,872 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:19:55,872 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:19:55,901 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:19:55,909 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:19:55,910 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:19:55,979 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:19:57,688 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:19:57,688 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:19:57,705 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:19:57,805 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:19:57,805 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:19:57,826 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:19:58,109 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:19:58,109 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:19:58,123 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:19:58,127 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:19:58,127 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:19:58,139 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:19:58,142 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:19:58,142 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:19:58,156 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:19:58,186 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:19:58,186 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:19:58,213 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:19:59,480 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-19-58_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:19:59,484 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:19:59,484 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:19:59,821 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:19:59,821 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:21:07,912 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:21:07,918 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:21:07,918 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:21:10,963 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:21:11,068 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:21:11,068 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:21:11,091 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:21:11,092 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:21:11,092 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:21:11,176 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:21:11,184 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:21:11,184 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:21:11,264 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:21:12,065 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:21:12,065 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:21:12,101 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:21:12,135 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:21:12,135 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:21:12,174 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:21:12,515 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:21:12,515 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:21:12,536 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:21:12,538 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:21:12,539 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:21:12,558 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:21:12,563 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:21:12,564 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:21:12,739 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:21:12,760 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:21:12,761 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:21:12,780 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:21:13,478 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-21-13_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:21:13,482 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:21:13,482 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:21:13,846 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:21:13,846 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:22:31,523 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:22:31,535 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:22:31,536 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:22:31,563 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:22:31,590 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:22:31,590 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:22:39,003 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:22:39,099 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:22:39,099 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:22:39,131 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:22:39,133 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:22:39,133 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:22:39,151 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:22:39,157 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:22:39,158 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:22:39,176 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:22:40,029 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:22:40,029 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:22:40,042 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:22:40,076 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:22:40,076 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:22:40,090 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:22:40,403 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:22:40,403 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:22:40,432 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:22:40,436 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:22:40,436 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:22:40,458 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:22:40,460 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:22:40,460 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:22:40,481 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:22:40,505 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:22:40,505 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:22:40,529 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:22:41,385 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-22-41_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:22:41,390 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:22:41,390 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:22:41,815 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:22:41,815 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:24:16,997 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:24:17,092 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:24:17,092 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:24:17,112 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:24:17,116 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:24:17,116 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:24:17,138 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:24:17,143 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:24:17,143 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:24:17,159 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:24:17,975 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:24:17,975 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:24:17,986 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:24:18,014 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:24:18,014 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:24:18,029 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:24:18,316 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:24:18,316 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:24:18,349 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:24:18,352 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:24:18,352 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:24:18,381 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:24:18,383 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:24:18,384 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:24:18,417 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:24:18,440 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:24:18,440 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:24:18,473 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:24:19,822 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-24-19_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:24:19,827 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:24:19,827 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:24:20,184 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:24:20,184 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:28:18,992 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:28:19,008 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:28:19,008 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:28:19,112 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:28:19,116 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:28:19,117 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:28:19,137 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:28:19,143 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:28:19,143 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:28:19,177 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:28:19,183 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:28:19,183 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:28:20,010 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:28:20,034 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:28:20,034 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:28:20,102 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:28:20,109 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:28:20,110 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:28:20,193 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:28:20,198 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:28:20,199 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:28:22,031 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:28:22,825 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-28-22_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:28:22,829 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:28:22,829 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:28:23,171 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:28:23,171 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:30:14,836 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:30:14,985 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:30:14,985 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:30:15,010 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:30:15,012 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:30:15,012 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:30:15,029 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:30:15,055 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:30:15,055 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:30:15,071 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:30:15,859 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:30:15,859 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:30:15,874 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:30:15,901 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:30:15,901 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:30:15,919 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:30:16,223 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:30:16,223 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:30:16,263 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:30:16,266 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:30:16,266 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:30:16,308 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:30:16,309 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:30:16,309 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:30:16,373 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:30:16,400 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:30:16,400 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:30:16,490 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:30:17,379 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:30:17,380 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:32:23,924 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:32:24,066 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:32:24,067 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:32:24,106 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:32:24,109 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:32:24,109 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:32:24,143 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:32:24,148 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:32:24,148 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:32:24,190 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:32:24,976 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:32:24,976 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:32:24,988 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:32:25,013 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:32:25,014 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:32:25,032 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:32:25,370 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:32:25,370 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:32:25,394 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:32:25,397 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:32:25,397 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:32:25,420 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:32:25,421 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:32:25,421 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:32:25,471 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:32:25,501 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:32:25,501 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:32:25,624 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:32:26,469 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:32:26,469 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:32:48,876 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:32:48,962 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:32:48,962 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:32:48,998 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:32:49,001 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:32:49,001 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:32:49,057 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:32:49,063 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:32:49,063 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:32:49,105 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:32:49,861 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:32:49,861 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:32:49,879 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:32:49,906 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:32:49,906 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:32:49,935 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:32:50,259 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:32:50,259 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:32:50,281 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:32:50,284 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:32:50,284 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:32:50,302 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:32:50,305 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:32:50,305 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:32:50,332 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:32:50,355 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:32:50,355 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:32:50,436 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:32:51,247 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-32-51_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:32:51,250 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:32:51,250 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:32:51,625 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:32:51,626 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:34:44,545 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:34:44,665 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:34:44,665 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:34:44,688 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:34:44,690 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:34:44,691 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:34:44,727 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:34:44,733 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:34:44,733 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:34:44,764 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:34:45,557 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:34:45,557 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:34:45,573 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:34:45,621 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:34:45,621 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:34:45,659 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:34:45,982 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:34:45,982 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:34:46,015 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:34:46,018 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:34:46,018 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:34:46,035 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:34:46,037 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:34:46,037 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:34:46,055 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:34:46,076 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:34:46,076 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:34:46,091 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:34:46,825 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-34-46_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:34:46,830 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:34:46,830 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:34:47,200 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:34:47,200 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:35:11,619 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:35:11,715 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:35:11,715 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:35:11,736 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:35:11,738 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:35:11,738 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:35:11,763 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:35:11,768 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:35:11,769 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:35:11,789 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:35:12,607 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:35:12,607 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:35:12,618 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:35:12,658 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:35:12,658 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:35:12,680 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:35:13,005 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:35:13,005 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:35:13,032 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:35:13,034 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:35:13,034 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:35:13,049 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:35:13,051 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:35:13,051 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:35:13,069 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:35:13,093 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:35:13,093 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:35:13,125 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:35:13,859 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-35-13_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:35:13,864 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:35:13,864 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:35:14,083 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:35:14,083 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:38:40,906 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:38:40,936 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:38:40,936 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:38:41,039 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:38:41,065 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:38:41,065 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:38:41,115 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:38:41,129 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:38:41,130 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:38:41,219 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:38:41,247 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:38:41,248 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:38:41,317 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:38:41,335 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:38:41,336 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:38:41,386 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:38:41,401 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:38:41,401 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:38:41,457 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:38:41,471 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:38:41,471 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:38:41,982 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:38:41,995 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:38:41,995 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:38:42,053 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:38:42,068 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:38:42,068 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:38:42,124 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:38:42,137 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:38:42,137 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:38:42,201 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:38:42,218 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:38:42,220 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:40:02,868 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:40:03,004 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:40:03,004 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:40:03,066 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:40:03,068 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:40:03,068 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:40:03,092 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:40:03,099 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:40:03,099 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:40:03,117 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:40:13,942 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:40:13,942 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:40:14,003 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:40:14,530 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:40:14,530 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:40:14,564 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:40:15,737 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:40:15,737 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:40:15,755 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:40:15,758 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:40:15,758 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:40:15,787 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:40:15,790 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:40:15,790 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:40:15,823 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:40:15,985 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:40:15,985 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:40:16,029 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:40:26,022 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-40-16_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:40:26,027 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:40:26,027 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:40:48,571 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-40-35_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:40:48,575 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:40:48,575 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:41:11,495 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-41-03_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:41:11,499 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:41:11,499 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:41:28,617 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-41-19_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:41:28,620 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:41:28,620 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:41:50,262 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-41-38_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:41:50,267 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:41:50,267 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:42:12,694 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-42-03_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:42:12,697 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:42:12,697 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:42:34,720 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-42-22_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:42:34,725 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:42:34,725 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:42:48,749 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:42:48,749 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:42:49,078 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:42:49,182 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:42:49,182 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:42:49,211 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:42:49,214 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:42:49,214 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:42:49,245 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:42:49,253 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:42:49,253 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:42:49,289 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:42:50,921 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:42:50,922 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:43:30,114 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:43:30,243 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:43:30,243 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:43:30,293 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:43:30,296 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:43:30,296 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:43:30,321 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:43:30,326 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:43:30,326 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:43:30,363 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:43:33,049 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:43:33,049 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:43:33,087 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:43:33,222 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:43:33,223 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:43:33,257 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:43:33,658 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:43:33,659 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:43:33,683 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:43:33,686 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:43:33,686 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:43:33,781 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:43:33,782 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:43:33,782 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:43:33,825 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:43:33,865 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:43:33,865 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:43:33,885 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:43:36,054 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-43-34_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:43:36,057 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:43:36,057 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:43:36,163 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:43:36,163 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:44:02,686 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:44:02,783 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:44:02,783 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:44:02,812 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:44:02,814 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:44:02,815 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:44:02,832 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:44:02,839 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:44:02,839 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:44:02,865 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:44:08,007 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:44:08,008 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:44:08,044 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:44:08,402 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:44:08,403 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:44:08,444 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:44:09,011 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:44:09,011 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:44:09,027 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:44:09,030 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:44:09,030 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:44:09,049 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:44:09,051 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:44:09,051 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:44:09,069 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:44:09,152 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:44:09,152 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:44:09,174 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:44:14,208 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-44-09_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:44:14,211 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:44:14,211 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:44:21,888 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:44:21,888 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:46:32,363 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:46:32,779 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:46:32,780 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:46:32,803 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:46:32,806 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:46:32,807 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:46:32,839 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:46:32,863 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:46:32,863 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:46:32,880 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:46:37,980 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:46:37,980 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:46:38,063 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:46:38,354 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:46:38,354 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:46:38,372 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:46:38,981 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:46:38,982 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:46:38,999 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:46:39,002 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:46:39,002 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:46:39,019 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:46:39,023 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:46:39,023 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:46:39,039 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:46:39,124 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:46:39,124 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:46:39,140 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:46:44,252 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-46-39_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:46:44,256 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:46:44,256 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:46:53,511 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:46:53,513 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:46:58,260 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:46:58,368 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:46:58,369 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:46:58,398 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:46:58,401 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:46:58,401 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:46:58,421 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:46:58,428 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:46:58,428 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:46:58,449 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:47:03,369 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:47:03,369 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:47:03,429 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:47:03,729 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:47:03,729 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:47:03,748 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:47:04,362 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:47:04,363 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:47:04,382 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:47:04,385 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:47:04,385 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:47:04,408 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:47:04,410 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:47:04,411 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:47:04,435 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:47:04,518 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:47:04,519 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:47:04,553 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:47:09,521 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-47-05_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:47:09,524 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:47:09,524 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:47:15,759 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:47:15,759 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:48:30,918 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:48:31,014 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:48:31,014 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:48:31,046 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:48:31,050 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:48:31,050 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:48:31,078 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:48:31,086 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:48:31,086 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:48:31,114 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:48:34,625 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:48:34,625 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:48:34,643 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:48:34,681 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:48:34,681 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:48:34,716 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:48:34,968 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:48:34,968 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:48:35,009 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:48:35,011 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:48:35,011 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:48:35,049 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:48:35,051 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:48:35,051 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:48:35,079 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:48:35,097 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:48:35,097 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:48:35,122 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:48:35,210 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:48:35,210 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:53:41,737 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:53:41,760 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:53:41,761 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:53:41,850 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:53:41,871 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:53:41,871 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:53:41,926 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:53:41,943 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:53:41,943 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:53:41,994 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:53:42,013 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:53:42,013 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:53:42,064 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:53:42,083 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:53:42,083 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:53:42,132 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:53:42,147 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:53:42,153 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:53:42,203 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:53:42,218 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:53:42,218 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:53:42,282 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:53:42,305 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:53:42,312 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:53:42,391 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:53:42,410 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:53:42,410 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:53:42,462 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:53:42,476 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:53:42,477 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:53:42,536 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:53:42,570 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:53:42,570 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:53:42,624 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:53:42,643 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:53:42,644 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:53:53,205 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:53:53,310 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:53:53,310 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:53:53,345 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:53:53,348 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:53:53,348 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:53:53,383 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:53:53,392 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:53:53,392 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:53:53,446 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:53:58,710 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:53:58,710 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:53:58,750 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:53:59,065 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:53:59,065 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:53:59,079 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:53:59,651 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:53:59,651 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:53:59,671 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:53:59,673 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:53:59,673 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:53:59,690 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:53:59,692 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:53:59,692 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:53:59,706 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:53:59,781 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:53:59,781 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:53:59,821 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:54:05,205 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-54-00_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:54:05,208 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:54:05,208 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:54:15,345 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-54-08_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:54:15,349 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:54:15,349 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:54:25,833 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-54-21_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:54:25,838 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:54:25,838 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:54:33,409 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-54-29_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:54:33,414 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:54:33,414 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:54:43,630 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-54-37_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:54:43,633 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:54:43,633 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:54:53,421 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-54-49_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:54:53,423 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:54:53,423 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:55:03,062 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-54-57_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:55:03,065 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:55:03,066 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:55:11,951 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-55-08_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:55:11,954 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:55:11,954 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:55:18,952 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-55-14_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:55:18,956 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:55:18,956 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:55:27,752 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_19-55-22_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 19:55:27,756 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 19:55:27,756 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 19:55:31,560 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:55:31,561 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:55:31,595 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:55:32,236 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:55:32,237 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:55:32,250 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:55:32,251 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:55:32,251 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:55:32,303 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:55:32,315 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:55:32,315 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 19:55:32,374 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 19:55:32,401 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 19:55:32,401 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:00:40,939 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:00:41,045 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:00:41,045 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:00:41,072 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:00:41,075 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:00:41,076 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:00:41,112 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:00:41,118 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:00:41,118 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:00:41,138 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:00:46,566 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:00:46,566 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:00:46,606 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:00:46,935 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:00:46,936 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:00:46,962 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:00:47,603 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:00:47,603 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:00:47,620 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:00:47,622 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:00:47,623 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:00:47,638 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:00:47,639 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:00:47,639 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:00:47,657 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:00:47,738 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:00:47,739 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:00:47,763 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:00:53,227 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_20-00-48_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 20:00:53,230 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 20:00:53,230 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 20:00:56,373 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:00:56,373 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:01:05,834 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:01:05,939 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:01:05,939 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:01:05,967 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:01:05,971 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:01:05,971 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:01:06,007 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:01:06,014 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:01:06,014 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:01:06,054 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:01:10,714 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:01:10,714 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:01:10,746 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:01:11,014 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:01:11,015 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:01:11,032 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:01:11,648 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:01:11,648 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:01:11,671 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:01:11,674 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:01:11,674 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:01:11,692 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:01:11,696 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:01:11,696 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:01:11,713 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:01:11,819 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:01:11,819 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:01:11,876 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:01:17,298 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_20-01-12_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 20:01:17,300 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 20:01:17,300 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 20:01:27,911 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_20-01-20_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 20:01:27,914 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 20:01:27,915 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 20:01:39,042 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_20-01-34_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 20:01:39,046 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 20:01:39,046 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 20:01:44,269 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:01:44,269 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:05:18,358 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:05:18,964 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:05:18,972 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:05:19,063 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:05:19,078 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:05:19,082 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:05:19,132 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:05:19,148 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:05:19,148 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:05:19,203 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:05:19,222 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:05:19,222 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:05:19,271 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:05:19,290 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:05:19,290 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:05:19,341 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:05:19,360 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:05:19,360 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:05:19,413 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:05:19,426 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:05:19,426 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:05:19,486 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:05:19,501 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:05:19,509 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:05:19,609 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:05:19,633 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:05:19,633 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:05:19,731 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:05:19,746 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:05:19,747 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:05:19,812 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:05:19,828 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:05:19,828 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:05:19,898 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:05:19,920 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:05:19,921 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:05:26,076 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:05:26,326 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:05:26,326 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:06:28,449 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:06:28,614 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:06:28,614 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:06:28,658 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:06:28,662 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:06:28,663 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:06:28,688 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:06:28,705 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:06:28,705 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:06:28,731 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:06:28,843 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:06:28,843 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:07:05,442 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:07:05,448 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:07:05,448 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:07:05,586 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:07:05,590 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:07:05,591 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:07:05,753 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:07:05,758 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:07:05,759 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:07:05,940 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:07:05,947 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:07:05,948 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:07:09,112 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:07:09,263 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:07:09,263 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:07:09,328 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:07:09,332 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:07:09,332 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:07:09,347 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:07:09,355 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:07:09,355 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:07:09,376 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:07:09,654 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:07:09,654 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:07:22,229 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:07:22,341 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:07:22,341 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:07:22,360 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:07:22,363 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:07:22,363 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:07:22,388 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:07:22,394 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:07:22,394 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:07:22,416 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:07:22,606 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:07:22,606 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:08:03,755 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:08:03,852 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:08:03,852 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:08:03,873 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:08:03,876 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:08:03,876 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:08:03,904 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:08:03,910 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:08:03,910 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:08:03,937 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:08:04,316 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:08:04,317 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:08:14,264 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:08:14,379 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:08:14,379 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:08:14,434 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:08:14,436 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:08:14,436 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:08:14,458 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:08:14,466 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:08:14,466 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:08:14,487 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:08:14,680 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:08:14,680 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:08:42,664 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:08:42,669 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:08:42,670 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:08:50,085 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:08:50,169 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:08:50,171 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:08:50,191 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:08:50,194 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:08:50,194 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:08:50,219 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:08:50,224 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:08:50,224 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:08:50,249 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:08:50,459 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:08:50,459 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:08:55,672 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:08:55,681 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:08:55,681 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:08:55,727 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:08:55,735 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:08:55,735 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:08:58,063 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:08:58,147 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:08:58,147 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:08:58,166 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:08:58,169 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:08:58,169 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:08:58,199 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:08:58,210 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:08:58,210 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:08:58,255 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:08:59,997 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:08:59,997 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:00,066 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:00,139 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:00,139 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:00,202 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:00,561 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:00,561 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:00,583 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:00,586 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:00,586 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:00,606 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:00,608 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:00,608 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:00,622 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:00,812 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:00,813 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:00,837 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:02,182 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_20-09-01_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 20:09:02,186 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 20:09:02,186 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 20:09:02,289 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:02,289 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:23,041 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:23,202 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:23,202 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:23,249 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:23,250 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:23,250 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:23,270 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:23,279 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:23,279 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:23,294 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:24,145 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:24,145 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:24,174 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:24,205 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:24,205 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:24,316 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:24,707 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:24,707 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:24,736 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:24,739 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:24,739 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:24,778 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:24,780 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:24,780 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:24,834 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:25,056 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:25,056 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:25,083 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:25,772 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_20-09-25_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 20:09:25,775 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 20:09:25,775 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 20:09:25,955 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:25,955 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:45,694 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:45,789 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:45,789 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:45,819 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:45,822 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:45,822 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:45,839 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:45,845 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:45,845 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:45,896 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:48,822 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:48,823 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:48,854 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:48,884 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:48,884 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:48,917 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:49,172 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:49,172 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:49,187 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:49,189 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:49,189 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:49,204 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:49,205 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:49,205 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:49,227 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:49,428 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:49,428 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:09:49,443 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:09:50,198 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_20-09-50_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 20:09:50,204 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 20:09:50,204 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 20:09:50,320 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:09:50,320 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:10:21,559 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:10:21,686 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:10:21,687 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:10:21,729 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:10:21,733 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:10:21,733 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:10:21,759 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:10:21,765 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:10:21,766 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:10:21,781 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:10:29,580 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:10:29,580 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:10:29,639 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:10:29,673 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:10:29,673 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:10:29,701 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:10:29,962 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:10:29,962 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:10:29,976 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:10:29,978 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:10:29,978 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:10:29,997 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:10:29,998 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:10:29,998 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:10:30,017 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:10:30,248 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:10:30,248 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:10:30,269 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:10:31,053 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_20-10-31_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 20:10:31,057 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 20:10:31,057 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 20:10:31,178 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:10:31,178 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:10:51,960 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:10:52,781 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_20-10-52_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 20:10:52,785 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 20:10:52,785 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 20:10:52,938 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:10:52,938 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:16:18,006 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:16:20,032 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:16:20,032 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:16:27,098 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:16:29,017 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:16:29,017 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:17:25,659 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:17:25,666 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:17:25,666 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:17:31,202 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:17:52,462 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:17:52,462 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:20:22,216 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:20:22,357 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:20:22,358 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:20:22,374 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:20:22,377 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:20:22,377 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:20:22,398 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:20:22,450 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:20:22,450 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:20:22,473 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:20:26,898 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:20:26,898 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:20:26,917 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:20:27,115 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:20:27,115 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:20:27,141 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:20:27,626 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:20:27,626 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:20:27,641 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:20:27,643 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:20:27,643 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:20:27,658 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:20:27,659 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:20:27,659 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:20:27,680 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:20:27,764 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:20:27,764 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:20:27,796 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:20:34,174 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:20:34,174 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:09,762 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:09,859 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:09,860 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:09,886 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:09,888 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:09,888 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:09,915 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:09,926 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:09,927 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:09,969 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:11,671 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:11,671 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:11,697 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:11,749 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:11,749 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:11,765 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:12,060 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:12,060 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:12,074 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:12,076 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:12,076 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:12,091 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:12,093 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:12,093 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:12,109 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:12,134 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:12,134 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:12,152 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:13,455 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_20-32-12_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 20:32:13,459 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 20:32:13,459 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 20:32:13,581 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:13,581 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:19,865 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:19,973 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:19,973 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:20,013 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:20,016 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:20,017 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:20,047 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:20,053 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:20,054 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:20,102 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:21,477 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:21,477 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:21,525 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:21,564 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:21,564 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:21,626 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:22,052 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:22,052 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:22,072 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:22,076 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:22,076 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:22,096 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:22,099 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:22,099 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:22,116 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:22,138 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:22,138 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:22,163 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:22,923 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_20-32-22_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 20:32:22,930 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 20:32:22,930 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 20:32:23,115 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:23,115 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:30,079 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:30,173 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:30,173 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:30,194 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:30,197 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:30,197 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:30,225 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:30,231 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:30,231 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:30,256 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:31,098 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:31,098 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:31,126 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:31,156 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:31,157 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:31,217 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:31,480 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:31,480 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:31,494 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:31,496 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:31,496 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:31,509 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:31,511 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:31,511 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:31,525 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:31,542 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:31,542 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:31,557 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:32,260 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_20-32-32_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 20:32:32,264 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 20:32:32,265 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 20:32:32,550 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:32,550 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:40,355 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:40,546 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:40,547 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:40,580 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:40,582 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:40,582 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:40,604 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:40,609 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:40,609 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:40,626 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:41,636 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:41,636 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:41,674 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:41,705 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:41,705 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:41,736 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:41,994 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:41,994 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:42,011 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:42,013 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:42,013 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:42,029 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:42,031 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:42,031 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:42,045 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:42,069 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:42,070 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:32:42,116 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:32:42,820 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_20-32-42_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 20:32:42,823 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 20:32:42,823 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 20:32:42,953 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:32:42,954 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:34:45,948 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:34:45,954 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:34:45,954 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:34:47,942 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:34:47,947 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:34:47,948 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:34:53,453 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:34:53,458 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:34:53,458 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:34:59,031 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:34:59,125 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:34:59,126 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:34:59,156 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:34:59,158 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:34:59,158 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:34:59,187 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:34:59,193 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:34:59,194 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:34:59,225 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:35:02,605 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:35:02,606 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:35:02,650 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:35:02,902 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:35:02,902 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:35:02,943 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:35:03,638 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:35:03,638 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:35:03,689 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:35:03,693 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:35:03,693 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:35:03,721 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:35:03,724 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:35:03,724 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:35:03,771 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:35:03,878 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:35:03,878 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:35:03,934 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:35:09,418 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_20-35-04_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 20:35:09,422 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 20:35:09,423 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 20:35:17,069 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:35:17,069 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:36:19,963 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:36:19,968 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:36:19,968 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:36:47,153 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:36:47,247 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:36:47,248 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:36:47,279 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:36:47,282 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:36:47,282 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:36:47,303 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:36:47,309 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:36:47,309 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:36:47,349 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:36:51,866 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:36:51,866 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:36:51,884 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:36:52,119 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:36:52,120 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:36:52,136 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:36:52,824 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:36:52,824 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:36:52,846 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:36:52,850 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:36:52,850 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:36:52,867 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:36:52,869 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:36:52,869 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:36:52,891 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:36:52,955 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:36:52,956 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:36:52,975 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:36:54,645 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:36:54,646 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:38:15,294 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:38:15,425 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:38:15,425 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:38:15,465 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:38:15,467 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:38:15,467 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:38:15,503 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:38:15,508 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:38:15,508 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:38:15,527 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:38:19,915 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:38:19,915 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:38:19,943 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:38:20,097 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:38:20,097 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:39:54,203 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:39:54,209 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:39:54,209 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:39:54,237 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:39:54,243 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:39:54,244 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:39:54,335 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:39:54,346 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:39:54,346 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:39:54,403 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:39:54,410 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:39:54,410 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:39:54,605 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:39:54,611 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:39:54,611 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:39:54,758 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:39:54,766 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:39:54,766 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:39:55,472 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:39:55,479 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:39:55,479 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:39:55,671 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:39:55,679 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:39:55,679 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:39:55,788 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:39:55,795 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:39:55,795 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:39:55,975 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:39:55,983 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:39:55,983 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:39:56,449 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:39:56,454 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:39:56,454 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:39:56,582 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:39:56,589 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:39:56,589 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:39:58,990 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:39:58,998 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:39:58,998 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:39:59,024 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:39:59,031 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:39:59,031 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:39:59,110 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:39:59,114 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:39:59,115 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:39:59,450 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:39:59,455 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:39:59,455 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:39:59,690 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:39:59,697 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:39:59,697 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:39:59,960 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:39:59,969 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:39:59,969 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:00,127 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:00,137 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:00,137 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:00,329 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:00,335 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:00,336 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:00,451 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:00,457 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:00,457 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:00,589 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:00,595 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:00,595 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:12,542 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:12,550 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:12,550 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:12,584 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:12,612 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:12,613 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:13,102 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:13,108 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:13,108 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:13,269 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:13,275 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:13,276 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:14,755 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:14,763 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:14,763 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:14,907 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:14,914 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:14,914 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:16,852 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:18,489 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:18,489 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:28,059 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:28,142 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:28,142 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:28,160 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:28,163 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:28,163 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:28,177 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:28,193 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:28,194 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:28,215 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:28,437 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:28,437 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:28,465 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:28,472 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:28,472 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:28,504 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:28,662 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:28,662 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:28,676 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:28,680 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:28,680 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:28,694 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:28,697 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:28,697 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:28,711 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:28,726 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:28,727 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:28,755 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:30,452 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:30,452 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:49,077 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:49,172 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:49,173 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:49,206 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:49,208 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:49,208 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:49,231 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:49,238 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:49,238 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:49,268 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:49,477 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:49,477 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:49,530 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:49,534 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:49,534 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:49,624 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:49,779 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:49,779 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:49,799 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:49,801 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:49,801 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:49,817 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:49,820 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:49,820 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:49,852 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:49,868 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:49,868 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:49,890 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:50,872 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_20-40-50_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 20:40:50,876 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 20:40:50,876 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 20:40:51,080 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:51,080 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:51,501 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:51,584 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:51,584 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:51,617 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:51,621 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:51,621 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:51,634 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:51,642 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:51,642 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:51,670 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:51,907 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:51,907 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:51,940 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:51,945 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:51,946 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:51,974 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:52,120 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:52,120 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:52,134 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:52,136 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:52,137 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:52,152 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:52,155 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:52,155 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:52,169 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:52,189 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:52,190 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:40:52,243 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:40:52,983 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_20-40-52_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 20:40:52,993 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 20:40:52,993 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 20:40:53,140 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:40:53,140 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:42:54,891 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:42:54,906 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:42:54,906 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:42:54,958 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:42:54,962 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:42:54,963 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:42:57,891 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:42:57,898 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:42:57,898 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:42:57,954 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:42:57,960 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:42:57,960 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:42:58,040 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:42:58,044 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:42:58,045 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:00,620 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:00,626 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:00,626 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:00,969 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:00,975 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:00,975 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:01,177 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:01,182 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:01,182 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:01,489 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:01,497 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:01,498 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:02,060 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:02,065 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:02,066 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:02,229 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:02,239 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:02,239 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:04,241 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:04,495 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:04,495 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:24,666 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:24,748 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:24,749 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:24,766 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:24,769 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:24,769 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:24,786 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:24,792 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:24,792 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:24,826 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:25,046 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:25,046 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:25,081 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:25,086 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:25,086 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:25,127 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:25,307 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:25,307 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:25,327 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:25,330 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:25,330 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:25,347 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:25,349 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:25,349 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:25,376 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:25,390 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:25,391 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:25,411 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:26,105 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_20-43-26_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 20:43:26,110 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 20:43:26,110 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 20:43:26,307 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:26,307 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:44,361 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:44,444 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:44,444 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:44,488 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:44,492 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:44,492 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:44,552 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:44,558 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:44,559 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:44,586 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:44,796 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:44,796 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:44,829 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:44,834 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:44,834 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:44,857 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:44,999 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:45,000 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:45,020 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:45,024 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:45,024 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:45,053 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:45,054 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:45,055 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:45,120 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:45,134 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:45,136 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:45,196 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:45,910 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_20-43-45_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 20:43:45,914 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 20:43:45,914 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 20:43:46,035 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:46,035 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:57,597 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:57,702 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:57,702 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:57,724 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:57,727 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:57,727 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:57,759 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:57,784 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:57,784 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:57,822 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:58,076 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:58,076 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:58,110 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:58,117 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:58,117 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:58,140 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:58,293 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:58,293 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:58,311 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:58,313 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:58,313 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:58,336 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:58,338 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:58,338 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:58,367 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:58,391 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:58,391 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:43:58,426 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:43:59,727 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_20-43-59_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 20:43:59,732 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 20:43:59,732 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 20:43:59,871 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:43:59,873 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:44:40,329 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:44:40,430 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:44:40,430 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:44:40,452 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:44:40,455 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:44:40,455 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:44:40,496 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:44:40,504 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:44:40,504 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:44:40,541 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:44:40,789 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:44:40,790 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:44:40,846 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:44:40,851 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:44:40,851 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:44:40,876 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:44:41,002 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:44:41,002 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:44:41,020 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:44:41,023 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:44:41,023 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:44:41,051 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:44:41,053 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:44:41,053 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:44:41,102 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:44:41,118 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:44:41,118 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:44:41,171 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:44:41,888 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_20-44-41_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 20:44:41,894 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 20:44:41,894 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 20:44:42,035 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:44:42,035 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:45:42,313 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:45:42,337 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:45:42,337 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:45:42,433 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:45:42,453 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:45:42,453 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:45:42,510 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:45:42,524 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:45:42,525 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:45:42,609 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:45:42,628 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:45:42,629 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:45:42,685 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:45:43,612 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:45:43,612 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:45:43,682 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:45:43,705 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:45:43,707 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:45:43,768 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:45:43,784 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:45:43,785 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:45:43,858 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:45:43,872 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:45:43,872 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:45:43,936 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:45:43,952 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:45:43,952 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:45:44,013 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:45:44,027 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:45:44,027 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:45:44,115 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:45:44,131 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:45:44,132 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:45:44,199 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:45:44,214 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:45:44,215 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:45:44,275 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:45:44,298 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:45:44,299 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:45:57,037 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:45:57,134 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:45:57,134 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:45:57,175 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:45:57,177 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:45:57,177 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:45:57,202 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:45:57,210 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:45:57,210 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:45:57,264 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:46:02,219 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:46:02,219 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:46:02,240 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:46:02,596 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:46:02,596 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:46:02,614 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:46:03,123 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:46:03,123 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:46:03,138 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:46:03,142 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:46:03,142 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:46:03,156 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:46:03,159 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:46:03,159 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:46:03,183 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:46:03,276 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:46:03,276 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:46:03,339 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:46:08,550 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_20-46-04_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 20:46:08,553 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 20:46:08,553 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 20:46:10,830 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:46:10,831 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:46:51,860 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:46:51,868 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:46:51,868 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:47:02,562 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:47:02,575 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:47:02,575 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:47:30,427 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:47:30,434 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:47:30,435 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:47:31,353 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:47:31,358 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:47:31,358 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:47:32,848 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:47:32,945 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:47:32,945 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:47:32,985 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:47:32,988 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:47:32,988 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:47:33,012 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:47:33,017 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:47:33,017 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:47:33,047 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:47:36,774 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:47:36,774 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:47:36,800 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:47:36,943 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:47:36,943 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:47:36,962 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:47:37,329 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:47:37,329 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:47:37,343 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:47:37,345 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:47:37,345 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:47:37,361 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:47:37,362 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:47:37,362 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:47:37,376 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:47:37,410 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:47:37,411 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:47:37,444 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:47:39,723 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_20-47-38_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 20:47:39,729 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 20:47:39,729 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 20:47:39,845 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:47:39,845 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:47:49,140 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:47:49,279 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:47:49,279 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:47:49,343 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:47:49,346 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:47:49,347 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:47:49,377 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:47:49,382 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:47:49,382 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:47:49,412 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:47:51,950 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:47:51,950 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:47:51,984 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:47:52,037 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:47:52,037 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:47:52,053 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:47:52,397 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:47:52,397 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:47:52,413 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:47:52,416 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:47:52,416 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:47:52,430 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:47:52,431 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:47:52,431 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:47:52,446 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:47:52,472 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:47:52,472 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:47:52,492 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:47:53,801 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_20-47-53_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 20:47:53,804 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 20:47:53,804 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 20:47:53,913 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:47:53,913 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:49:27,652 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:49:27,737 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:49:27,738 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:49:27,759 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:49:27,762 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:49:27,762 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:49:27,802 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:49:27,810 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:49:27,810 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:49:27,843 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:49:33,380 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:49:33,380 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:49:33,404 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:49:33,701 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:49:33,701 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:49:33,721 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:49:34,349 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:49:34,349 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:49:34,381 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:49:34,384 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:49:34,384 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:49:34,403 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:49:34,405 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:49:34,405 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:49:34,437 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:49:34,508 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:49:34,508 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:49:34,539 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:49:37,114 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:49:37,114 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:50:45,526 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:50:45,554 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:50:45,554 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:50:45,678 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:50:45,702 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:50:45,703 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:50:45,783 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:50:45,798 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:50:45,799 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:50:45,859 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:50:45,896 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:50:45,896 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:50:45,951 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:50:45,971 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:50:45,971 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:50:46,034 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:50:46,055 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:50:46,058 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:50:46,111 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:50:46,135 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:50:46,136 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:50:47,036 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:50:47,054 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:50:47,054 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:50:47,138 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:50:47,155 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:50:47,155 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:50:47,245 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:50:47,261 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:50:47,261 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:50:47,324 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:50:47,339 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:50:47,339 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:50:47,403 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:50:47,419 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:50:47,420 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:50:47,481 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:50:47,502 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:50:47,502 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:51:13,838 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:51:13,922 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:51:13,922 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:51:13,957 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:51:13,961 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:51:13,961 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:51:13,979 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:51:13,985 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:51:13,986 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:51:14,026 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:51:19,977 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:51:19,977 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:51:19,999 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:51:20,280 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:51:20,280 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:51:20,296 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:51:20,966 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:51:20,967 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:51:20,992 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:51:20,996 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:51:20,996 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:51:21,022 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:51:21,025 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:51:21,025 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:51:21,047 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:51:21,134 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:51:21,134 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:51:21,159 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:51:27,239 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_20-51-21_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 20:51:27,244 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 20:51:27,244 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 20:51:34,427 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:51:34,427 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:52:00,143 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:52:00,149 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:52:00,149 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:52:15,760 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:52:15,856 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:52:15,857 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:52:15,880 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:52:15,884 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:52:15,884 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:52:15,944 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:52:15,953 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:52:15,953 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:52:16,039 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:52:21,601 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:52:21,601 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:52:21,621 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:52:21,958 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:52:21,959 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:52:22,013 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:52:23,001 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:52:23,001 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:58:42,969 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:58:42,973 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:58:42,973 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:58:47,851 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:58:47,873 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:58:47,873 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:58:47,886 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:58:47,949 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:58:47,952 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:58:47,974 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:58:47,979 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:58:47,979 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:58:48,419 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:58:48,530 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:58:48,530 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:58:58,225 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:58:58,322 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:58:58,323 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:58:58,353 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:58:58,359 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:58:58,360 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:58:58,391 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:58:58,415 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:58:58,415 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:58:58,447 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:59:02,718 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:59:02,719 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:59:02,875 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:59:08,622 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:59:08,622 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:59:08,655 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:59:09,047 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:59:09,048 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:59:09,102 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:59:10,344 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:59:10,345 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:59:10,366 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:59:10,370 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:59:10,370 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:59:10,423 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:59:10,427 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:59:10,427 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:59:53,732 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:59:53,824 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:59:53,824 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:59:53,854 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:59:53,860 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:59:53,860 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:59:53,886 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:59:53,923 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:59:53,923 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 20:59:53,994 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 20:59:54,165 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 20:59:54,165 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:00:17,088 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:00:17,101 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:00:17,103 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:00:17,144 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:00:17,150 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:00:17,152 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:00:17,885 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:00:17,891 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:00:17,891 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:00:18,069 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:00:18,076 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:00:18,082 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:00:21,741 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:00:21,871 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:00:21,872 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:00:21,910 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:00:21,914 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:00:21,914 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:00:21,942 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:00:21,952 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:00:21,953 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:00:21,976 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:00:28,563 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:00:28,563 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:00:28,590 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:00:28,911 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:00:28,911 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:00:28,931 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:00:29,893 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:00:29,893 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:00:29,919 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:00:29,924 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:00:29,924 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:00:29,947 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:00:29,950 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:00:29,950 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:00:29,990 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:00:30,112 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:00:30,112 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:00:30,142 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:00:36,459 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_21-00-31_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 21:00:36,470 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 21:00:36,470 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 21:00:45,052 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:00:45,052 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:01:30,517 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:01:30,639 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:01:30,639 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:01:30,713 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:01:30,718 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:01:30,718 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:01:30,742 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:01:30,749 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:01:30,749 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:01:30,774 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:01:35,897 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:01:35,897 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:01:35,933 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:01:36,257 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:01:36,257 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:01:36,382 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:01:37,426 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:01:37,426 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:01:37,449 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:01:37,453 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:01:37,453 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:01:37,471 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:01:37,474 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:01:37,474 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:01:37,500 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:01:37,574 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:01:37,574 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:01:37,616 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:01:40,792 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:01:40,792 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:01:45,698 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:01:45,792 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:01:45,792 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:01:45,838 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:01:45,843 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:01:45,843 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:01:45,889 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:01:45,899 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:01:45,899 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:01:45,981 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:01:49,086 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:01:49,086 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:01:49,110 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:01:49,208 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:01:49,209 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:01:49,225 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:01:50,028 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:01:50,028 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:01:50,046 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:01:50,048 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:01:50,049 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:01:50,069 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:01:50,073 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:01:50,073 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:01:50,087 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:01:50,153 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:01:50,154 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:01:50,185 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:01:53,090 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_21-01-51_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 21:01:53,100 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 21:01:53,101 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 21:01:53,441 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:01:53,441 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:01:53,799 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:01:53,911 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:01:53,911 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:01:53,982 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:01:53,986 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:01:53,986 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:01:54,006 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:01:54,014 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:01:54,015 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:01:54,038 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:01:55,347 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:01:55,347 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:02:40,776 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:02:40,786 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:02:40,790 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:02:40,943 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:02:40,953 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:02:40,953 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:02:41,098 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:02:41,108 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:02:41,113 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:02:41,301 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:02:41,312 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:02:41,317 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:02:41,552 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:02:41,563 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:02:41,568 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:02:44,844 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:02:45,010 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:02:45,012 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:02:45,039 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:02:45,043 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:02:45,043 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:02:45,068 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:02:45,077 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:02:45,077 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:02:45,114 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:02:48,014 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:02:48,014 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:02:48,060 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:02:48,204 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:02:48,204 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:02:48,246 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:02:48,994 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:02:48,995 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:02:49,013 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:02:49,017 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:02:49,017 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:02:49,032 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:02:49,034 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:02:49,034 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:02:49,052 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:02:49,113 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:02:49,113 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:02:49,142 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:02:53,031 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_21-02-51_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 21:02:53,044 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 21:02:53,044 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 21:02:53,337 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:02:53,338 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:05:42,163 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:05:42,174 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:05:42,174 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:05:42,219 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:05:42,226 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:05:42,229 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:05:42,569 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:05:42,579 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:05:42,582 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:05:42,788 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:05:42,799 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:05:42,799 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:05:43,020 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:05:43,029 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:05:43,033 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:05:43,650 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:05:43,661 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:05:43,670 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:05:43,887 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:05:43,895 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:05:43,895 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:05:44,015 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:05:44,036 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:05:44,037 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:06:19,080 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:06:19,092 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:06:19,093 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:06:50,711 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:06:50,725 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:06:50,730 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:06:50,769 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:06:50,775 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:06:50,778 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:06:52,206 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:06:52,214 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:06:52,215 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:06:52,408 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:06:52,415 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:06:52,415 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:06:52,584 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:06:52,593 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:06:52,597 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:09,179 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:09,188 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:09,194 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:09,230 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:09,238 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:09,240 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:09,281 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:09,289 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:09,290 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:09,549 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:09,557 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:09,563 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:09,790 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:09,798 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:09,803 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:10,001 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:10,009 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:10,014 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:10,435 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:10,443 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:10,450 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:10,829 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:10,840 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:10,840 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:11,213 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:11,234 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:11,234 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:19,814 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:19,823 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:19,823 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:20,138 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:20,146 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:20,146 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:20,324 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:20,333 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:20,338 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:23,813 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:23,825 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:23,825 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:23,870 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:23,878 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:23,880 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:24,048 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:24,055 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:24,058 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:30,544 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:30,552 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:30,558 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:30,595 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:30,603 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:30,608 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:30,679 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:30,689 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:30,690 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:31,851 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:31,864 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:31,872 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:31,908 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:31,916 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:31,919 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:33,590 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:33,600 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:33,604 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:33,822 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:33,830 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:33,832 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:33,978 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:33,992 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:34,002 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:35,319 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:35,328 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:35,334 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:35,594 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:35,602 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:35,606 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:35,748 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:35,780 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:35,781 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:35,976 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:35,985 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:35,987 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:44,074 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:44,229 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:44,230 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:44,266 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:44,272 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:44,272 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:44,311 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:44,326 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:44,326 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:07:44,397 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:07:44,404 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:07:44,406 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:08:09,298 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:08:09,311 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:08:09,317 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:08:09,519 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:08:09,529 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:08:09,534 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:08:13,406 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:08:13,557 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:08:13,558 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:08:13,620 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:08:13,625 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:08:13,625 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:08:13,673 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:08:13,684 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:08:13,685 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:08:13,724 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:08:13,728 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:08:13,729 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:08:19,734 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:08:19,825 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:08:19,825 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:08:19,849 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:08:19,853 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:08:19,853 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:08:19,876 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:08:19,885 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:08:19,885 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:08:19,905 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:08:29,438 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:08:29,438 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:08:29,514 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:08:29,762 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:08:29,762 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:08:29,782 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:08:30,744 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:08:30,744 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:08:30,769 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:08:30,772 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:08:30,773 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:08:30,801 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:08:30,807 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:08:30,807 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:08:30,851 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:08:30,956 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:08:30,956 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:08:30,985 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:08:31,987 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_21-08-31_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 21:08:31,998 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 21:08:31,999 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 21:08:32,295 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:08:32,295 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:03,039 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:03,051 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:03,051 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:05,094 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:05,101 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:05,101 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:05,344 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:05,353 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:05,356 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:05,486 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:05,496 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:05,496 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:09,677 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:09,796 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:09,797 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:09,876 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:09,881 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:09,881 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:10,022 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:10,031 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:10,032 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:10,115 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:12,976 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:12,976 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:13,057 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:13,513 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:13,513 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:19,231 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:19,237 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:19,243 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:20,551 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:20,560 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:20,567 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:20,613 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:20,620 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:20,620 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:21,308 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:21,316 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:21,320 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:21,440 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:21,449 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:21,450 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:22,524 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:22,531 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:22,534 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:23,917 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:23,925 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:23,930 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:24,167 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:24,174 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:24,179 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:25,138 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:25,147 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:25,152 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:25,200 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:25,207 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:25,210 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:26,134 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:26,144 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:26,150 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:26,434 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:26,440 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:26,444 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:26,562 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:26,570 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:26,575 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:26,891 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:26,928 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:26,929 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:30,240 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:30,385 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:30,385 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:30,498 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:30,501 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:30,501 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:30,559 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:30,566 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:30,566 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:30,648 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:33,988 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:33,988 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:34,042 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:42,291 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:42,291 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:42,338 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:42,581 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:42,582 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:14:42,601 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:14:45,214 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:14:45,216 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:15:06,455 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:15:06,468 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:15:06,475 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:15:06,552 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:15:06,564 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:15:06,567 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:15:06,692 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:15:06,700 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:15:06,704 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:15:07,214 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:15:07,221 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:15:07,237 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:15:08,272 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:15:08,283 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:15:08,284 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:15:08,425 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:15:08,434 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:15:08,438 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:15:08,562 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:15:08,570 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:15:08,574 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:15:11,982 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:15:11,991 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:15:11,998 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:15:12,033 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:15:12,041 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:15:12,044 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:15:12,185 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:15:12,193 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:15:12,193 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:15:12,699 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:15:12,709 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:15:12,711 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:15:13,758 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:15:13,767 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:15:13,770 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:15:13,910 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:15:13,917 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:15:13,920 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:15:14,053 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:15:14,062 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:15:14,074 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:15:16,246 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:15:16,375 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:15:16,376 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:15:16,424 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:15:16,429 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:15:16,429 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:15:16,460 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:15:16,477 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:15:16,477 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:15:16,514 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:15:19,412 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:15:19,412 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:17:01,147 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:17:01,156 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:17:01,156 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:17:01,189 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:17:01,195 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:17:01,197 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:17:01,306 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:17:01,323 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:17:01,327 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:17:01,508 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:17:01,518 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:17:01,520 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:17:02,469 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:17:02,476 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:17:02,476 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:17:22,396 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:17:22,505 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:17:22,505 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:17:22,552 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:17:22,557 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:17:22,557 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:17:22,579 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:17:22,586 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:17:22,587 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:17:22,624 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:17:27,256 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:17:27,257 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:17:38,499 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:17:38,506 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:17:38,512 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:17:38,538 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:17:38,545 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:17:38,552 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:17:38,720 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:17:38,730 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:17:38,731 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:17:59,132 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:17:59,230 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:17:59,231 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:17:59,253 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:17:59,259 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:17:59,260 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:17:59,280 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:17:59,288 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:17:59,289 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:17:59,307 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:18:05,220 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:18:05,220 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:18:05,261 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:18:12,369 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:18:12,369 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:18:12,406 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:18:12,565 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:18:12,566 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:18:12,590 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:18:13,722 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:18:13,722 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:18:13,802 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:18:13,806 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:18:13,806 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:18:13,828 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:18:13,831 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:18:13,831 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:18:13,856 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:18:13,943 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:18:13,943 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:18:13,970 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:18:15,046 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_21-18-14_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 21:18:15,059 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 21:18:15,060 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 21:18:15,368 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:18:15,370 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:21:45,887 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:21:45,899 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:21:45,906 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:21:45,943 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:21:45,949 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:21:45,953 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:21:48,272 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:21:48,281 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:21:48,287 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:21:48,327 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:21:48,335 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:21:48,338 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:21:48,400 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:21:48,407 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:21:48,408 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:21:48,631 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:21:48,638 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:21:48,638 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:21:49,587 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:21:49,594 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:21:49,596 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:22:18,627 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:22:18,768 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:22:18,768 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:22:18,815 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:22:18,819 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:22:18,819 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:22:18,848 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:22:18,859 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:22:18,859 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:22:18,910 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:22:22,937 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:22:22,938 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:22:22,995 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:22:31,537 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:22:31,537 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:22:31,578 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:22:31,787 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:22:31,788 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:22:31,808 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:22:32,900 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:22:32,900 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:22:32,944 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:22:32,950 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:22:32,950 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:22:32,995 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:22:32,999 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:22:33,000 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:22:33,058 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:22:33,159 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:22:33,159 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:22:33,194 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:22:36,732 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:22:36,732 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:22:58,227 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:22:58,235 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:22:58,244 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:22:58,322 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:22:58,331 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:22:58,339 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:22:58,365 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:22:58,372 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:22:58,385 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:22:58,436 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:22:58,443 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:22:58,456 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:22:59,445 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:22:59,476 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:22:59,478 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:22:59,599 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:22:59,606 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:22:59,612 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:22:59,636 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:22:59,645 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:22:59,649 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:22:59,713 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:22:59,722 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:22:59,725 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:23:03,649 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:23:03,778 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:23:03,780 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:23:03,821 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:23:03,827 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:23:03,827 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:23:03,856 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:23:03,868 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:23:03,868 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:23:03,923 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:23:08,367 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:23:08,367 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:23:08,427 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:23:17,149 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:23:17,149 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:23:17,173 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:23:17,425 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:23:17,425 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:23:17,448 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:23:18,566 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:23:18,566 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:23:18,595 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:23:18,598 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:23:18,599 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:23:18,616 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:23:18,618 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:23:18,618 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:23:18,678 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:23:18,788 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:23:18,789 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:23:18,814 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:23:21,079 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_21-23-20_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 21:23:21,093 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 21:23:21,093 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 21:23:21,389 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:23:21,389 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:24:18,024 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:24:18,033 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:24:18,039 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:24:18,070 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:24:18,076 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:24:18,077 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:24:21,096 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:24:21,105 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:24:21,110 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:24:21,141 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:24:21,160 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:24:21,160 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:24:21,354 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:24:21,364 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:24:21,365 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:24:21,415 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:24:21,426 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:24:21,445 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:25:06,753 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:25:06,905 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:25:06,906 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:25:06,949 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:25:06,952 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:25:06,952 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:25:06,998 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:25:07,010 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:25:07,011 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:25:07,127 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:25:11,720 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:25:11,720 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:25:11,825 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:25:11,828 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:25:11,828 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:25:11,882 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:25:11,899 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:25:11,899 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:25:11,959 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:25:12,750 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:25:12,751 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:25:12,796 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:25:12,802 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:25:12,802 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:25:12,836 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:25:12,840 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:25:12,841 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:25:12,953 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:25:12,999 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:25:13,000 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:25:13,047 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:25:13,958 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_21-25-13_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 21:25:13,969 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 21:25:13,969 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 21:25:14,285 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:25:14,285 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:25:56,404 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:25:56,589 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:25:56,589 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:25:56,630 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:25:56,635 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:25:56,635 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:25:56,669 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:25:56,677 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:25:56,677 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:25:56,707 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:26:00,425 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:26:00,426 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:26:00,465 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:26:00,467 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:26:00,467 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:26:00,490 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:26:00,507 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:26:00,507 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:26:00,524 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:26:01,473 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:26:01,473 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:26:01,499 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:26:01,504 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:26:01,504 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:26:01,529 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:26:01,531 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:26:01,533 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:26:01,553 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:26:01,590 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:26:01,590 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:26:01,637 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:26:02,721 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_21-26-02_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 21:26:02,737 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 21:26:02,737 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 21:26:03,108 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:26:03,108 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:27:40,992 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:27:41,213 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:27:41,213 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:30:03,454 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:30:03,479 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:30:03,479 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:30:03,804 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:30:03,829 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:30:03,831 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:30:03,980 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:30:04,007 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:30:04,016 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:30:04,242 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:30:04,278 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:30:04,292 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:30:04,448 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:30:04,502 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:30:04,514 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:30:04,650 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:30:04,678 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:30:04,680 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:30:04,882 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:30:04,906 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:30:04,908 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:30:05,129 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:30:05,152 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:30:05,161 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:30:05,309 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:30:05,332 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:30:05,334 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:30:05,512 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:30:05,537 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:30:05,547 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:30:05,676 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:30:05,698 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:30:05,701 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:30:05,839 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:30:05,863 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:30:05,865 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:30:05,999 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:30:06,023 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:30:06,025 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:30:06,160 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:30:06,183 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:30:06,185 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:30:06,344 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:30:06,369 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:30:06,379 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:30:06,506 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:30:06,529 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:30:06,539 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:30:06,715 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:30:06,740 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:30:06,748 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:30:27,558 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:30:27,691 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:30:27,691 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:30:27,727 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:30:27,733 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:30:27,734 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:30:27,771 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:30:27,814 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:30:27,814 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:30:27,894 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:38:27,830 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:38:27,830 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:41:38,702 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:41:38,803 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:41:38,803 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:41:38,841 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:41:38,847 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:41:38,847 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:41:38,868 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:41:38,877 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:41:38,877 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:41:38,947 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:41:43,193 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:41:43,193 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:41:54,758 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:41:54,914 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:41:54,914 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:41:54,941 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:41:54,945 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:41:54,945 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:41:54,971 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:41:54,979 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:41:54,979 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:41:55,015 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:41:58,708 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:41:58,708 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:09,170 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:09,294 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:09,294 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:09,345 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:09,349 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:09,350 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:09,373 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:09,381 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:09,381 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:09,422 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:13,786 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:13,786 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:13,877 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:17,188 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:17,188 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:17,222 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:17,225 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:17,225 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:17,262 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:17,277 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:17,278 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:17,330 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:17,923 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:17,923 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:17,947 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:17,951 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:17,951 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:17,972 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:17,975 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:17,975 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:18,013 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:18,049 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:18,050 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:18,090 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:19,135 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_21-43-19_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 21:43:19,146 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 21:43:19,146 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 21:43:19,492 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:19,492 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:33,435 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:33,446 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:33,447 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:34,520 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:34,527 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:34,529 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:34,729 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:34,737 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:34,738 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:36,948 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:36,955 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:36,970 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:39,728 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:39,742 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:39,747 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:39,953 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:39,960 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:39,964 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:40,094 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:40,101 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:40,105 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:40,313 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:40,320 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:40,324 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:45,258 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:45,265 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:45,270 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:47,765 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:47,905 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:47,905 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:47,958 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:47,962 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:47,962 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:47,981 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:47,987 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:47,988 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:48,009 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:51,976 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:51,976 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:52,023 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:55,166 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:55,166 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:55,207 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:55,208 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:55,210 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:55,228 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:55,245 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:55,245 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:55,268 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:55,827 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:55,828 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:55,852 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:55,856 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:55,856 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:55,908 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:55,913 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:55,913 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:55,942 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:55,978 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:55,978 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:43:56,013 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:43:56,906 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_21-43-56_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 21:43:56,918 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 21:43:56,918 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 21:43:57,216 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:43:57,216 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:44:29,063 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:44:29,198 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:44:29,199 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:44:29,223 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:44:29,229 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:44:29,229 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:44:29,254 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:44:29,278 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:44:29,278 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:44:29,297 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:44:33,150 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:44:33,150 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:44:33,180 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:44:36,745 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:44:36,745 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:44:36,778 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:44:36,780 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:44:36,780 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:44:36,834 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:44:36,996 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:44:36,996 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:44:37,014 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:44:38,227 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:44:38,227 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:44:38,248 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:44:38,253 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:44:38,254 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:44:38,281 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:44:38,287 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:44:38,287 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:44:38,333 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:44:38,418 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:44:38,418 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:44:38,445 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:44:43,732 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:44:43,733 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:44:50,877 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:44:50,957 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:44:50,957 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:44:50,989 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:44:50,993 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:44:50,993 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:44:51,011 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:44:51,017 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:44:51,017 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:44:51,048 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:44:54,935 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:44:54,935 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:44:54,954 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:44:55,090 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:44:55,091 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:44:55,117 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:44:55,986 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:44:55,986 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:44:56,030 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:44:56,034 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:44:56,035 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:44:56,064 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:44:56,067 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:44:56,067 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:44:56,152 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:44:56,259 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:44:56,260 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:44:56,338 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:45:02,211 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_21-44-57_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 21:45:02,219 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 21:45:02,219 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 21:45:16,025 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_21-45-08_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 21:45:16,035 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 21:45:16,035 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 21:45:30,909 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_21-45-26_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 21:45:30,917 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 21:45:30,917 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 21:45:42,004 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_21-45-37_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 21:45:42,012 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 21:45:42,012 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 21:45:51,760 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:45:51,760 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:47:30,391 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:47:30,398 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:47:30,404 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:47:30,430 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:47:30,436 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:47:30,437 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:47:30,528 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:47:30,536 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:47:30,539 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:47:30,702 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:47:30,708 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:47:30,713 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:47:31,759 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:47:31,769 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:47:31,776 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:47:31,923 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:47:31,931 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:47:31,937 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:47:32,090 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:47:32,097 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:47:32,103 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:47:32,428 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:47:32,437 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:47:32,442 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:47:32,661 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:47:32,668 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:47:32,673 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:47:32,833 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:47:32,842 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:47:32,852 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:47:33,125 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:47:33,131 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:47:33,137 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:47:33,310 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:47:33,317 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:47:33,323 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:47:33,433 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:47:33,440 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:47:33,447 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:47:33,600 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:47:33,607 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:47:33,612 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:47:35,179 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:47:35,186 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:47:35,190 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:48:41,002 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:48:41,078 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:48:41,079 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:48:41,107 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:48:41,111 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:48:41,111 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:48:41,132 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:48:41,139 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:48:41,140 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:48:41,178 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:48:45,329 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:48:45,329 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:48:45,346 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:48:45,485 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:48:45,485 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:48:45,502 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:48:46,343 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:48:46,343 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:48:46,363 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:48:46,365 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:48:46,365 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:48:46,383 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:48:46,386 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:48:46,386 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:48:46,402 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:48:46,518 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:48:46,519 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:48:46,583 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:48:46,762 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:48:46,764 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:49:01,604 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:49:01,613 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:49:01,614 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:49:13,231 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:49:13,330 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:49:13,330 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:49:13,354 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:49:13,358 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:49:13,358 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:49:13,379 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:49:13,387 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:49:13,387 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:49:13,418 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:49:17,569 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:49:17,569 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:49:17,607 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:49:17,756 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:49:17,756 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:49:17,774 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:49:18,752 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:49:18,752 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:49:18,779 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:49:18,783 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:49:18,783 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:49:18,806 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:49:18,808 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:49:18,808 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:49:18,832 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:49:18,919 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:49:18,919 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:49:18,957 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:49:24,374 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_21-49-19_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 21:49:24,384 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 21:49:24,385 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 21:49:37,666 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_21-49-30_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 21:49:37,676 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 21:49:37,677 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 21:49:52,668 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_21-49-48_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 21:49:52,676 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 21:49:52,676 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 21:49:56,303 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:49:56,303 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:50:01,482 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:50:01,493 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:50:01,501 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:50:01,544 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:50:01,551 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:50:01,554 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:50:06,493 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:50:06,571 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:50:06,572 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:50:06,601 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:50:06,606 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:50:06,607 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:50:06,645 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:50:06,656 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:50:06,657 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:50:06,715 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:50:11,018 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:50:11,018 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:50:11,056 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:50:11,188 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:50:11,188 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:50:11,207 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:50:12,074 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:50:12,074 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:50:12,099 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:50:12,103 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:50:12,103 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:50:12,124 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:50:12,127 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:50:12,127 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:50:12,149 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:50:12,246 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:50:12,246 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:50:12,294 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:50:17,691 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_21-50-13_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 21:50:17,700 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 21:50:17,700 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 21:50:30,605 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_21-50-23_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 21:50:30,613 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 21:50:30,613 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 21:50:44,646 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_21-50-40_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 21:50:44,653 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 21:50:44,653 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 21:50:54,315 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_21-50-49_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 21:50:54,322 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 21:50:54,323 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 21:51:06,502 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:51:06,503 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:57:14,109 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:57:14,122 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:57:14,130 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:57:14,154 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:57:14,160 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:57:14,163 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:57:14,914 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:57:14,921 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:57:14,924 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:57:37,100 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:57:37,107 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:57:37,118 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:57:37,191 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:57:37,197 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:57:37,200 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:57:37,286 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:57:37,295 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:57:37,305 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:57:37,394 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:57:37,402 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:57:37,405 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:57:37,530 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:57:37,542 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:57:37,552 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:57:37,650 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:57:37,656 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:57:37,659 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:57:45,202 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:57:45,212 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:57:45,223 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:57:45,338 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:57:45,348 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:57:45,361 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:57:46,251 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:57:46,291 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:57:46,313 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:57:46,465 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:57:46,477 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:57:46,482 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:57:59,617 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:57:59,627 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:57:59,632 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:01,103 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:01,116 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:01,120 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:01,426 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:01,435 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:01,436 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:01,835 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:01,849 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:01,855 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:02,099 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:02,108 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:02,112 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:02,439 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:02,450 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:02,454 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:02,578 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:02,586 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:02,590 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:02,781 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:02,790 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:02,794 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:02,939 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:02,952 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:02,956 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:03,061 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:03,069 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:03,072 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:25,713 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:25,828 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:25,829 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:25,870 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:25,875 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:25,875 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:25,905 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:25,926 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:25,926 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:25,946 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:30,482 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:30,482 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:30,519 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:30,657 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:30,657 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:30,674 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:31,551 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:31,551 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:31,572 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:31,576 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:31,576 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:31,596 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:31,599 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:31,599 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:31,616 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:31,690 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:31,690 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:31,716 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:37,286 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_21-58-32_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 21:58:37,296 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 21:58:37,296 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 21:58:50,009 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:50,009 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:55,987 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:56,003 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:56,011 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:56,057 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:56,064 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:56,068 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:56,213 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:56,220 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:56,224 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:57,574 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:57,585 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:57,590 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:57,682 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:57,692 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:57,712 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:58:57,865 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:58:57,872 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:58:57,874 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:59:07,520 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:59:07,531 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:59:07,531 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:59:07,589 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:59:07,596 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:59:07,598 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:59:07,648 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:59:07,654 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:59:07,657 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:59:15,596 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:59:15,694 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:59:15,694 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:59:15,724 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:59:15,727 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:59:15,727 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:59:15,752 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:59:15,758 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:59:15,758 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:59:15,787 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:59:19,936 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:59:19,936 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:59:19,993 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:59:20,192 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:59:20,192 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:59:20,214 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:59:21,173 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:59:21,173 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:59:21,193 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:59:21,195 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:59:21,196 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:59:21,215 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:59:21,217 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:59:21,218 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:59:21,237 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:59:21,311 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:59:21,311 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 21:59:21,337 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 21:59:26,784 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_21-59-22_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 21:59:26,792 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 21:59:26,792 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 21:59:39,155 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_21-59-32_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 21:59:39,163 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 21:59:39,163 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 21:59:52,243 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 21:59:52,243 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:00:39,073 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:00:39,085 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:00:39,090 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:02:08,208 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:02:08,299 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:02:08,300 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:02:08,326 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:02:08,331 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:02:08,331 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:02:08,361 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:02:08,388 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:02:08,388 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:02:08,409 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:02:12,861 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:02:12,861 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:02:12,878 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:02:13,032 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:02:13,032 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:02:13,050 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:02:13,915 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:02:13,915 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:02:13,936 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:02:13,939 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:02:13,939 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:02:13,961 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:02:13,963 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:02:13,963 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:02:13,982 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:02:14,057 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:02:14,058 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:02:14,085 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:02:19,310 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_22-02-14_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 22:02:19,323 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 22:02:19,323 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 22:02:24,045 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:02:24,045 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:05:06,337 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:05:06,440 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:05:06,440 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:05:06,469 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:05:06,473 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:05:06,473 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:05:06,512 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:05:06,521 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:05:06,521 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:05:06,550 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:05:11,151 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:05:11,151 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:05:11,170 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:05:11,309 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:05:11,309 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:05:11,325 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:05:12,224 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:05:12,224 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:05:12,247 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:05:12,250 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:05:12,250 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:05:12,271 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:05:12,273 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:05:12,273 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:05:12,298 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:05:12,380 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:05:12,380 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:05:12,408 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:05:17,628 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_22-05-13_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 22:05:17,636 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 22:05:17,636 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 22:05:22,184 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:05:22,184 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:07:40,391 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:07:40,415 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:07:40,419 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:07:40,705 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:07:40,729 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:07:40,732 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:07:40,901 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:07:40,925 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:07:40,934 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:07:41,064 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:07:41,090 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:07:41,093 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:07:41,229 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:07:41,251 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:07:41,260 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:07:41,384 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:07:41,406 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:07:41,408 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:07:41,602 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:07:41,689 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:07:41,690 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:07:41,909 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:07:41,932 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:07:41,941 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:07:42,073 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:07:42,098 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:07:42,100 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:07:42,278 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:07:42,305 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:07:42,307 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:07:42,439 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:07:42,464 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:07:42,466 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:07:42,601 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:07:42,625 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:07:42,627 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:07:42,759 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:07:42,782 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:07:42,785 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:07:42,942 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:07:42,968 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:07:42,970 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:07:43,108 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:07:43,136 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:07:43,137 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:07:43,274 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:07:43,299 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:07:43,302 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:07:44,297 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:07:44,323 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:07:44,328 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:08:27,185 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:08:27,277 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:08:27,277 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:08:27,303 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:08:27,307 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:08:27,307 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:08:27,373 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:08:27,386 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:08:27,386 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:08:27,423 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:08:31,575 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:08:31,575 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:08:31,613 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:08:31,749 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:08:31,750 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:08:31,768 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:08:32,627 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:08:32,628 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:08:32,655 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:08:32,657 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:08:32,657 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:08:32,676 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:08:32,679 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:08:32,679 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:08:32,697 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:08:32,773 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:08:32,773 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:08:32,799 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:08:38,239 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_22-08-33_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 22:08:38,249 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 22:08:38,249 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 22:08:50,809 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_22-08-43_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 22:08:50,817 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 22:08:50,817 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 22:09:04,411 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_22-09-00_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 22:09:04,421 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 22:09:04,421 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 22:09:13,634 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_22-09-09_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 22:09:13,651 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 22:09:13,652 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 22:09:25,478 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_22-09-18_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 22:09:25,489 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 22:09:25,490 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 22:09:33,553 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:09:33,554 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:09:33,613 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:09:33,905 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:09:33,905 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:09:33,933 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:09:34,599 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:09:34,599 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:09:34,615 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:09:34,619 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:09:34,619 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:09:34,645 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:09:34,659 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:09:34,660 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:09:34,704 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:09:34,775 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:09:34,775 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:10:05,222 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:10:05,240 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:10:05,250 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:10:05,347 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:10:05,354 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:10:05,355 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:10:14,924 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:10:14,930 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:10:14,937 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:10:19,882 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:10:20,166 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:10:20,166 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:10,109 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:10,133 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:10,139 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:10,423 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:10,447 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:10,449 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:10,619 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:10,642 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:10,651 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:10,777 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:10,802 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:10,804 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:10,947 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:10,974 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:10,983 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:11,112 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:11,137 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:11,140 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:11,316 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:11,341 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:11,344 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:11,524 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:11,547 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:11,556 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:11,688 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:11,713 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:11,715 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:11,997 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:12,028 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:12,030 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:12,178 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:12,203 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:12,206 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:12,355 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:12,378 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:12,380 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:12,514 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:12,538 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:12,540 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:12,703 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:12,727 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:12,730 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:12,869 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:12,895 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:12,897 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:13,042 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:13,065 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:13,067 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:13,227 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:13,272 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:13,276 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:25,970 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:25,990 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:25,991 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:30,529 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:30,637 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:30,638 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:30,661 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:30,665 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:30,666 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:30,706 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:30,734 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:30,734 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:30,762 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:30,773 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:30,773 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:30,847 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:31,478 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:31,478 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:31,493 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:31,509 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:31,509 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:31,524 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:31,851 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:31,851 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:31,871 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:31,875 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:31,875 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:31,891 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:31,895 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:31,895 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:31,922 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:31,950 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:14:31,950 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:14:31,986 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:14:37,412 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_22-14-32_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 22:14:37,419 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 22:14:37,419 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 22:14:49,487 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_22-14-42_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 22:14:49,496 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 22:14:49,496 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 22:15:02,739 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_22-14-58_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 22:15:02,749 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 22:15:02,749 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 22:15:12,411 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_22-15-07_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 22:15:12,418 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 22:15:12,418 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 22:15:24,034 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_22-15-17_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 22:15:24,042 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 22:15:24,042 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 22:15:31,582 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:15:31,582 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:15:31,626 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:15:31,984 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:15:31,985 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:21:18,232 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:21:18,332 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:21:18,332 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:21:18,354 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:21:18,358 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:21:18,359 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:21:18,379 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:21:18,386 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:21:18,386 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:21:18,410 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:21:18,422 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:21:18,422 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:21:18,448 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:21:19,008 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:21:19,010 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:21:19,029 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:21:19,048 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:21:19,050 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:21:19,130 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:21:19,477 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:21:19,477 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:21:19,500 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:21:19,502 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:21:19,502 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:21:19,524 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:21:19,526 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:21:19,526 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:21:19,557 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:21:19,591 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:21:19,592 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:21:19,633 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:21:25,787 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_22-21-21_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 22:21:25,793 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 22:21:25,793 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 22:21:38,143 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_22-21-31_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 22:21:38,152 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 22:21:38,152 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 22:21:51,457 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_22-21-47_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 22:21:51,465 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 22:21:51,465 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 22:22:01,464 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_22-21-56_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 22:22:01,474 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 22:22:01,474 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 22:22:13,653 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb None None {'num_input_channels': 1, 'context_length': 512, 'patch_length': 64, 'expansion_factor': 2, 'num_layers': 2, 'dropout': 0.2, 'mode': 'common_channel', 'gated_attn': True, 'norm_mlp': 'LayerNorm', 'scaling': 'std', 'head_dropout': 0.2, 'patch_last': True, 'use_positional_encoding': False, 'positional_encoding_type': 'sincos', 'prediction_length': 96, 'prediction_channel_indices': None, 'self_attn': False, 'self_attn_heads': 1, 'init_std': 0.02, 'post_init': False, 'distribution_output': 'student_t', 'loss': 'mse', 'num_parallel_samples': 100, 'norm_eps': 1e-05, 'use_decoder': True, 'adaptive_patching_levels': 3, 'resolution_prefix_tuning': False, 'exogenous_channel_indices': None, 'decoder_num_layers': 2, 'decoder_adaptive_patching_levels': 0, 'decoder_raw_residual': False, 'decoder_mode': 'common_channel', 'fcm_gated_attn': True, 'fcm_context_length': 1, 'fcm_use_mixer': False, 'fcm_mix_layers': 2, 'fcm_prepend_past': True, 'fcm_prepend_past_offset': None, 'enable_forecast_channel_mixing': False, 'frequency_token_vocab_size': 5, 'd_model': 192, 'patch_stride': 64, 'decoder_d_model': 128, 'categorical_vocab_size_list': None, 'init_processing': True, 'prediction_filter_length': 24, 'init_linear': 'pytorch', 'init_embed': 'pytorch', 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float32', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['TinyTimeMixerForPrediction'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': None, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'ibm/TTM', '_attn_implementation_autoset': True, 'transformers_version': '4.46.1', 'model_type': 'tinytimemixer', 'num_patches': 8, 'output_dir': 'tmp_trainer', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': False, 'eval_strategy': 'no', 'prediction_loss_only': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': 'tmp_trainer\\runs\\Nov22_22-22-06_A-LPTP-AWRmmVlZ', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': None, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'tmp_trainer', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'adamw_torch', 'optim_args': None, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': ['tensorboard', 'wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': False, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'evaluation_strategy': None, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'dispatch_batches': None, 'split_batches': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False}
2024-11-22 22:22:13,661 INFO    MainThread:26724 [wandb_config.py:__setitem__():154] config set model/num_parameters = 805280 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x000001C8F65066D0>>
2024-11-22 22:22:13,661 INFO    MainThread:26724 [wandb_run.py:_config_callback():1389] config_cb model/num_parameters 805280 None
2024-11-22 22:22:21,562 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:22:21,562 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:22:21,761 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:22:22,050 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:22:22,050 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:22:47,870 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:22:47,882 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:22:47,889 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:22:47,936 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:22:47,942 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:22:47,945 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:22:48,019 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:22:48,027 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:22:48,029 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:22:49,001 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:22:49,012 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:22:49,020 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:22:49,069 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:22:49,075 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:22:49,078 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:22:55,377 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:22:55,456 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:22:55,456 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:22:55,478 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:22:55,483 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:22:55,483 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:22:55,503 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:22:55,512 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:22:55,512 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:22:55,531 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:22:55,539 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:22:55,540 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:22:55,581 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:22:56,217 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:22:56,218 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:22:56,246 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:22:56,264 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:22:56,264 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:22:56,304 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:22:56,727 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:22:56,728 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:22:56,747 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:22:56,751 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:22:56,751 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:22:56,771 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:22:56,773 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:22:56,774 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:22:56,799 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:22:56,832 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:22:56,832 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
2024-11-22 22:22:56,866 INFO    MainThread:26724 [wandb_init.py:_resume_backend():449] resuming backend
2024-11-22 22:22:57,150 INFO    MainThread:26724 [jupyter.py:save_ipynb():387] not saving jupyter notebook
2024-11-22 22:22:57,151 INFO    MainThread:26724 [wandb_init.py:_pause_backend():444] pausing backend
