{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd52439d",
   "metadata": {},
   "source": [
    "# Gradient Boosted Decision Tree to Predict RUL - Smoothed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82761921",
   "metadata": {},
   "source": [
    "This notebook is an extension of workbook \"GBDT-Raw.ipynb\" and is intended to analyze smoothed data. Additional notes and highlights are included herein. \n",
    "\n",
    "Ultimately, the results of the smoothed data did not generalize between train and test sets, and further analysis was abandoned. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33da68f",
   "metadata": {},
   "source": [
    "# 1.0 Dependencies and Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def4509c",
   "metadata": {},
   "source": [
    "This notebook was built with the libraries imported below and the following versions:\n",
    "\n",
    "Pandas 2.2.3 <br>\n",
    "Numpy 2.0.2 <br>\n",
    "Altair 5.4.1 <br>\n",
    "sklearn 1.5.0 <br>\n",
    "XGBoost 2.1.2 <br>\n",
    "matplotlib 3.9.0 <br>\n",
    "\n",
    "Different versions of these libraries may affect the functionality of this notebook.\n",
    "\n",
    "The purpose of this notebook is to create a gradiet-boosted random forest to predict remaining useful life of jet engines using <b>smoothed</b> data provided by NASA. The notebook includes definitions to build the model, fit it, and then explore and store the results. \n",
    "\n",
    "Results are stored via a CSV file. There is a function for looping through different parameters, and other functions for viewing, exploring, and saving the results. \n",
    "\n",
    "NOTE REGARDING SMOOTHED DATA ANALYSIS: This notebook was built with notebook \"GBDT-Raw.ipynb\" used as a template. \"GBDT-Raw.ipynb\" used unsmoothed data, while this one uses smoothed data to reduce undesired noise in the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fda3790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from numpy import array, hstack\n",
    "import pickle\n",
    "import xgboost as xg\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c5608d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTED VERSIONS OF DEPENDENT LIBRARIES:\n",
      "2.2.3\n",
      "2.0.2\n",
      "5.4.1\n",
      "1.5.0\n",
      "2.1.2\n",
      "3.9.0\n"
     ]
    }
   ],
   "source": [
    "print(\"IMPORTED VERSIONS OF DEPENDENT LIBRARIES:\")\n",
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "print(alt.__version__)\n",
    "print(sklearn.__version__)\n",
    "print(xg.__version__)\n",
    "print(matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298bf497",
   "metadata": {},
   "source": [
    "The cell below can be used to view active variables in the notebook. It can be referred back to as the user goes through the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a19a9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                         Type                          Data/Info\n",
      "------------------------------------------------------------------------\n",
      "GradientBoostingRegressor        ABCMeta                       <class 'sklearn.ensemble.<...>adientBoostingRegressor'>\n",
      "INDX                             Index                         Index([    0,     1,     <...>ype='int64', length=3000)\n",
      "MinMaxScaler                     type                          <class 'sklearn.preproces<...>sing._data.MinMaxScaler'>\n",
      "RUL_values_to_remove             ndarray                       30: 30 elems, type `int64`, 240 bytes\n",
      "StandardScaler                   type                          <class 'sklearn.preproces<...>ng._data.StandardScaler'>\n",
      "alt                              module                        <module 'altair' from 'C:<...>es\\\\altair\\\\__init__.py'>\n",
      "array                            builtin_function_or_method    <built-in function array>\n",
      "columns                          list                          n=15\n",
      "columns_to_drop                  ndarray                       10: 10 elems, type `int64`, 80 bytes\n",
      "data_length                      int                           200\n",
      "early_RUL                        int                           125\n",
      "engine                           int64                         100\n",
      "f                                BufferedReader                <_io.BufferedReader name=<...>ing/true_rul_values.pkl'>\n",
      "feature_dictionary_long          dict                          n=21\n",
      "feature_dictionary_short         dict                          n=21\n",
      "hstack                           _ArrayFunctionDispatcher      <function hstack at 0x0000015C5CC444C0>\n",
      "i                                int                           20\n",
      "interpolated_engines_to_remove   list                          n=30\n",
      "item                             str                           sensor_19\n",
      "key                              str                           sensor_21\n",
      "l                                int                           199\n",
      "matplotlib                       module                        <module 'matplotlib' from<...>matplotlib\\\\__init__.py'>\n",
      "mean_absolute_error              function                      <function mean_absolute_e<...>or at 0x0000015C6F8F1AF0>\n",
      "mean_squared_error               function                      <function mean_squared_er<...>or at 0x0000015C6F8F1E50>\n",
      "new                              ndarray                       200: 200 elems, type `float64`, 1600 bytes\n",
      "np                               module                        <module 'numpy' from 'C:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "pd                               module                        <module 'pandas' from 'C:<...>es\\\\pandas\\\\__init__.py'>\n",
      "pickle                           module                        <module 'pickle' from 'C:<...>naconda\\\\lib\\\\pickle.py'>\n",
      "plt                              module                        <module 'matplotlib.pyplo<...>\\\\matplotlib\\\\pyplot.py'>\n",
      "r2_score                         function                      <function r2_score at 0x0000015C6F8FE5E0>\n",
      "raw_train                        DataFrame                            unit_number  time_<...>[20631 rows x 16 columns]\n",
      "sensor                           str                           sensor_12\n",
      "sklearn                          module                        <module 'sklearn' from 'C<...>s\\\\sklearn\\\\__init__.py'>\n",
      "smooth_test                      DataFrame                            unit_number  time_<...>[11097 rows x 16 columns]\n",
      "smooth_train                     DataFrame                            unit_number  time_<...>[20631 rows x 16 columns]\n",
      "smooth_y_test                    ndarray                       70: 70 elems, type `int64`, 560 bytes\n",
      "smooth_y_train                   ndarray                       20631: 20631 elems, type `float64`, 165048 bytes (161.1796875 kb)\n",
      "temp                             DataFrame                            sensor_2  sensor_3<...>[20631 rows x 14 columns]\n",
      "u                                int64                         100\n",
      "unit                             int                           33\n",
      "x                                Series                        6412      1\\n6413      2\\<...>Length: 200, dtype: int64\n",
      "xg                               module                        <module 'xgboost' from 'C<...>s\\\\xgboost\\\\__init__.py'>\n",
      "y1                               Series                        6412    1.560422\\n6413   <...>ngth: 200, dtype: float64\n",
      "y2                               Series                        Series([], Name: sensor_12, dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61edef0a",
   "metadata": {},
   "source": [
    "## 1.1 Load and define smoothed train and test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d481f977",
   "metadata": {},
   "source": [
    "Since the format of data input into the GBDT does not match that of other algorithms (cheifly, the neural networks), additional data preprocessing is conducted below. It maintains the same dropped columns and 'early RUL' as provided in the preprocessing workbook. Scaling occurs later in Section 2.1 and is optional. No batching occurs, as data is required to be 2 dimensional input for the GBDT. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb58cde4",
   "metadata": {},
   "source": [
    "NOTE REGARDING SMOOTH DATA ANALYSIS: Smooth data is not processed from the raw NASA data like in \"GBDT-Raw.ipynb\". Instead, it is cleaned and smoothed ahead of time. A standard scaler is applied to it as well. \n",
    "\n",
    "Variables to keep active include early_RUL, and data variables for further processing: smooth_train, smooth_test, y_test.\n",
    "<ul>\n",
    "    <li><b>early_RUL</b> - sets the threshold of the maximum remaining useful life. This is intended to lessen the impact of data instance far from the end of useful life; see the data processing notebook for more. </li>\n",
    "    <li><b>raw_train, raw_test, y_test</b> - the raw, unprocessed data from the NASA data repository. The raw files are preprocessed in Section 1.1 of this notebook (and maintain the same variable names) to remove unneeded fields and to create the RUL column of the training set.</li>\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "efe7156b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20631\n"
     ]
    }
   ],
   "source": [
    "early_RUL = 125\n",
    "link = \"../data/processed_data_pickle_files_with_smoothing/\"\n",
    "\n",
    "with open(link + \"train_data_no_batches.pkl\", 'rb') as f:\n",
    "    smooth_train = pickle.load(f)\n",
    "    \n",
    "del link\n",
    "\n",
    "columns = ['unit_number', 'sensor_2', 'sensor_3', 'sensor_4',\n",
    "       'sensor_6', 'sensor_7', 'sensor_8', 'sensor_9', 'sensor_11',\n",
    "       'sensor_12', 'sensor_13', 'sensor_15', 'sensor_17', 'sensor_20',\n",
    "       'sensor_21']\n",
    "\n",
    "smooth_train.columns = columns\n",
    "smooth_train['unit_number'] = smooth_train['unit_number'].astype('int')\n",
    "\n",
    "smooth_train.insert(1, 'time_cycles', 1)\n",
    "\n",
    "for u in smooth_train[\"unit_number\"].unique():\n",
    "    l = len(smooth_train[smooth_train['unit_number'] == u]) + 1\n",
    "    smooth_train.loc[smooth_train['unit_number'] == u, 'time_cycles'] = list(range(1, l, 1))\n",
    "\n",
    "print(len(smooth_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022f5c66",
   "metadata": {},
   "source": [
    "The defined function and code below adds early RUL to the data and is borrowed from the notebook 'data_processing.ipynb'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4638836d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20631\n",
      "[125. 125. 125. ...   2.   1.   0.]\n"
     ]
    }
   ],
   "source": [
    "def process_targets(data_length, early_rul=None):\n",
    "    \n",
    "    # if no early RUL is provided, generate a descending sequence from data_length -1 to 0\n",
    "    if early_rul is None:\n",
    "        return np.arange(data_length - 1, -1, -1)\n",
    "    \n",
    "    else:\n",
    "        # calculate the duration for which early RUL is applicable\n",
    "        early_rul_duration = data_length - early_rul\n",
    "        \n",
    "        # if the early RUL duration is non-positive, use a linear degradation curve (same as when early_rul is none)\n",
    "        if early_rul_duration <= 0:\n",
    "            return np.arange(data_length - 1, -1, -1)\n",
    "        \n",
    "        else:\n",
    "            # create an array where the first early_rul_duration values are equal to early_rul\n",
    "            target_array = np.append(early_rul * np.ones(shape=(early_rul_duration,)),\n",
    "                                     np.arange(early_rul - 1, -1, -1))  # Add descending values from early_rul-1 to 0\n",
    "            return target_array\n",
    "        \n",
    "smooth_y_train = np.ndarray([])\n",
    "\n",
    "for engine in smooth_train.iloc[:,0].unique():\n",
    "    \n",
    "    data_length = len(smooth_train[smooth_train.iloc[:,0] == engine])\n",
    "    if engine == 1:\n",
    "        smooth_y_train = process_targets(data_length, early_rul = early_RUL)\n",
    "    else:\n",
    "        new = process_targets(data_length, early_rul = 125)\n",
    "        smooth_y_train = np.append(smooth_y_train, new)\n",
    "\n",
    "del process_targets\n",
    "        \n",
    "print(len(smooth_y_train))\n",
    "print(smooth_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577b67b0",
   "metadata": {},
   "source": [
    "Additional processing is required for the test data, since smoothing limited the test engine count to 70. This is presented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2e7ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"../data/processed_data_pickle_files_with_smoothing/\"\n",
    "\n",
    "with open(link + \"test_data_no_batches.pkl\", 'rb') as f:\n",
    "    smooth_test = pickle.load(f)\n",
    "    \n",
    "with open(link + \"true_rul_values.pkl\", 'rb') as f:\n",
    "    smooth_y_test = pickle.load(f)\n",
    "    \n",
    "del link\n",
    "\n",
    "columns = ['unit_number', 'sensor_2', 'sensor_3', 'sensor_4',\n",
    "       'sensor_6', 'sensor_7', 'sensor_8', 'sensor_9', 'sensor_11',\n",
    "       'sensor_12', 'sensor_13', 'sensor_15', 'sensor_17', 'sensor_20',\n",
    "       'sensor_21']\n",
    "\n",
    "smooth_test.columns = columns\n",
    "\n",
    "interpolated_engines_to_remove = [1, 2, 5, 9, 11, 14, 15, 22, 25, 26, \n",
    "                                  33, 39, 44, 47, 48, 50, 59, 65, 67, \n",
    "                                  69, 71, 75, 78, 83, 85, 87, 88, 95, 96, 99]\n",
    "\n",
    "RUL_values_to_remove = np.array(interpolated_engines_to_remove) - 1\n",
    "smooth_y_test = np.delete(smooth_y_test, RUL_values_to_remove)\n",
    "\n",
    "smooth_test['unit_number'] = smooth_test['unit_number'].astype('int')\n",
    "\n",
    "\n",
    "INDX = smooth_test[smooth_test['unit_number'].isin(interpolated_engines_to_remove)].index\n",
    "\n",
    "smooth_test.drop(INDX, inplace = True)\n",
    "\n",
    "smooth_test.insert(1, 'time_cycles', 1)\n",
    "\n",
    "for u in smooth_test[\"unit_number\"].unique():\n",
    "    l = len(smooth_test[smooth_test['unit_number'] == u]) + 1\n",
    "    smooth_test.loc[smooth_test['unit_number'] == u, 'time_cycles'] = list(range(1, l, 1))\n",
    "    \n",
    "smooth_test.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d56ac5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20631, 16)\n",
      "(20631,)\n",
      "(11097, 16)\n",
      "(70,)\n"
     ]
    }
   ],
   "source": [
    "print(smooth_train.shape)\n",
    "print(smooth_y_train.shape)\n",
    "print(smooth_test.shape)\n",
    "print(smooth_y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a55f9ca",
   "metadata": {},
   "source": [
    "## 1.2 Capturing Headings and Choosing Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba213ff9",
   "metadata": {},
   "source": [
    "This section is for reference and does not affect the raw data files used in the following sections. \n",
    "\n",
    "Hard coded descriptions of the different sensors are provided below, both abbreviated descriptions (to use as column headers if so desired) and longer descriptions that can be printed out. Dictionaries are created for each based on sensor number.\n",
    "\n",
    "Then, the sensors that were removed are shown, along with the sensors that were kept in the dataset. \n",
    "\n",
    "Only variables for the dictionaries are kept: feature_dictionary_short, feature_dictionary_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d131b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor_1 :  Total temperature at fan inlet, degrees rankine\n",
      "sensor_2 :  Total temperature at Low Pressure Compressor (LPC) outlet, degrees rankine\n",
      "sensor_3 :  Total temperature at High Pressure Compressor (HPC) outlet, degrees rankine\n",
      "sensor_4 :  Total temperature at Low Pressure Turbine (LPT) outlet, degrees rankine\n",
      "sensor_5 :  Pressure at fan inlet, psia\n",
      "sensor_6 :  Total pressure in bypass-duct, psia\n",
      "sensor_7 :  Total pressure at HPC outlet, psia\n",
      "sensor_8 :  Physical fan speed, rpm\n",
      "sensor_9 :  Physical core speed, rpm\n",
      "sensor_10 :  Engine pressure ratio (P50/P2) where P2 is Pressure at Fan Inlet and P50 is Pressure at LPT outlet, psia\n",
      "sensor_11 :  Static pressure at HPC outlet, psia\n",
      "sensor_12 :  Ratio of fuel flow to Ps30 where Ps30 is static pressure at HPC outlet, pps/psi\n",
      "sensor_13 :  Corrected fan speed, rpm\n",
      "sensor_14 :  Corrected core speed, rpm\n",
      "sensor_15 :  Bypass Ratio, unitless\n",
      "sensor_16 :  Burner fuel-air ratio, unitless\n",
      "sensor_17 :  Bleed Enthalpy, unitless\n",
      "sensor_18 :  Demanded fan speed, rpm\n",
      "sensor_19 :  Demanded corrected fan speed, rpm\n",
      "sensor_20 :  HPT coolant bleed, lbm/s\n",
      "sensor_21 :  LPT coolant bleed, lbm/s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_number</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_6</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>sensor_8</th>\n",
       "      <th>sensor_9</th>\n",
       "      <th>sensor_11</th>\n",
       "      <th>sensor_12</th>\n",
       "      <th>sensor_13</th>\n",
       "      <th>sensor_15</th>\n",
       "      <th>sensor_17</th>\n",
       "      <th>sensor_20</th>\n",
       "      <th>sensor_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.065889</td>\n",
       "      <td>-0.695171</td>\n",
       "      <td>-0.807599</td>\n",
       "      <td>0.426686</td>\n",
       "      <td>1.004786</td>\n",
       "      <td>-0.570566</td>\n",
       "      <td>-0.751606</td>\n",
       "      <td>-0.398120</td>\n",
       "      <td>1.288601</td>\n",
       "      <td>-0.822016</td>\n",
       "      <td>-1.038086</td>\n",
       "      <td>-1.154212</td>\n",
       "      <td>1.307804</td>\n",
       "      <td>0.969818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.100972</td>\n",
       "      <td>-0.665510</td>\n",
       "      <td>-0.865381</td>\n",
       "      <td>0.426686</td>\n",
       "      <td>1.005885</td>\n",
       "      <td>-0.578016</td>\n",
       "      <td>-0.752771</td>\n",
       "      <td>-0.556099</td>\n",
       "      <td>1.196665</td>\n",
       "      <td>-0.829922</td>\n",
       "      <td>-1.037966</td>\n",
       "      <td>-1.158125</td>\n",
       "      <td>1.276253</td>\n",
       "      <td>0.989448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.102540</td>\n",
       "      <td>-0.647767</td>\n",
       "      <td>-0.902253</td>\n",
       "      <td>0.426686</td>\n",
       "      <td>1.002206</td>\n",
       "      <td>-0.571604</td>\n",
       "      <td>-0.751847</td>\n",
       "      <td>-0.705007</td>\n",
       "      <td>1.159946</td>\n",
       "      <td>-0.829644</td>\n",
       "      <td>-1.044008</td>\n",
       "      <td>-1.148715</td>\n",
       "      <td>1.239163</td>\n",
       "      <td>1.011182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.097768</td>\n",
       "      <td>-0.642849</td>\n",
       "      <td>-0.936744</td>\n",
       "      <td>0.426686</td>\n",
       "      <td>1.001796</td>\n",
       "      <td>-0.561942</td>\n",
       "      <td>-0.748910</td>\n",
       "      <td>-0.835521</td>\n",
       "      <td>1.111974</td>\n",
       "      <td>-0.825451</td>\n",
       "      <td>-1.046743</td>\n",
       "      <td>-1.137596</td>\n",
       "      <td>1.206491</td>\n",
       "      <td>1.037151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.082796</td>\n",
       "      <td>-0.648783</td>\n",
       "      <td>-0.960949</td>\n",
       "      <td>0.426686</td>\n",
       "      <td>1.003173</td>\n",
       "      <td>-0.555888</td>\n",
       "      <td>-0.743812</td>\n",
       "      <td>-0.928732</td>\n",
       "      <td>1.059255</td>\n",
       "      <td>-0.820618</td>\n",
       "      <td>-1.040194</td>\n",
       "      <td>-1.127616</td>\n",
       "      <td>1.178001</td>\n",
       "      <td>1.057445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_number  time_cycles  sensor_2  sensor_3  sensor_4  sensor_6  sensor_7  \\\n",
       "0            1            1 -1.065889 -0.695171 -0.807599  0.426686  1.004786   \n",
       "1            1            2 -1.100972 -0.665510 -0.865381  0.426686  1.005885   \n",
       "2            1            3 -1.102540 -0.647767 -0.902253  0.426686  1.002206   \n",
       "3            1            4 -1.097768 -0.642849 -0.936744  0.426686  1.001796   \n",
       "4            1            5 -1.082796 -0.648783 -0.960949  0.426686  1.003173   \n",
       "\n",
       "   sensor_8  sensor_9  sensor_11  sensor_12  sensor_13  sensor_15  sensor_17  \\\n",
       "0 -0.570566 -0.751606  -0.398120   1.288601  -0.822016  -1.038086  -1.154212   \n",
       "1 -0.578016 -0.752771  -0.556099   1.196665  -0.829922  -1.037966  -1.158125   \n",
       "2 -0.571604 -0.751847  -0.705007   1.159946  -0.829644  -1.044008  -1.148715   \n",
       "3 -0.561942 -0.748910  -0.835521   1.111974  -0.825451  -1.046743  -1.137596   \n",
       "4 -0.555888 -0.743812  -0.928732   1.059255  -0.820618  -1.040194  -1.127616   \n",
       "\n",
       "   sensor_20  sensor_21  \n",
       "0   1.307804   0.969818  \n",
       "1   1.276253   0.989448  \n",
       "2   1.239163   1.011182  \n",
       "3   1.206491   1.037151  \n",
       "4   1.178001   1.057445  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_headers = [\"Temp, fan in\", \"Temp, LPC out\", \"Temp, HPC out\", \n",
    "                           \"Temp, LPT out\", \"Press, fan in\", \"Tot Press, bypass\", \"Tot Press, HPC out\",\n",
    "                           \"Speed, fan\", \"Speed, core\", \"Eng Press Ratio\", \"Stat Press, HPC out\", \n",
    "                           \"phi Fuel Flow Ratio\", \"Corr. Speed, Fan\", \"Corr. Speed, Core\", \"Bypass Ratio\", \n",
    "                           \"Burner Fuel/Air Ratio\", \"Bleed Enthalpy\", \"Dem Speed, fan\", \"(?) Dem Corr Speed, fan\", \n",
    "                           \"Coolant Bleed, HPT\", \"Coolant Bleed, LPT\" ]\n",
    "long_descriptions = [\"Total temperature at fan inlet, degrees rankine\", \n",
    "                     \"Total temperature at Low Pressure Compressor (LPC) outlet, degrees rankine\", \n",
    "                     \"Total temperature at High Pressure Compressor (HPC) outlet, degrees rankine\", \n",
    "                     \"Total temperature at Low Pressure Turbine (LPT) outlet, degrees rankine\", \n",
    "                     \"Pressure at fan inlet, psia\", \n",
    "                     \"Total pressure in bypass-duct, psia\", \n",
    "                     \"Total pressure at HPC outlet, psia\", \n",
    "                     \"Physical fan speed, rpm\", \n",
    "                     \"Physical core speed, rpm\", \n",
    "                     \"Engine pressure ratio (P50/P2) where P2 is Pressure at Fan Inlet and P50 is Pressure at LPT outlet, psia\", \n",
    "                     \"Static pressure at HPC outlet, psia\", \n",
    "                     \"Ratio of fuel flow to Ps30 where Ps30 is static pressure at HPC outlet, pps/psi\", \n",
    "                     \"Corrected fan speed, rpm\", \n",
    "                     \"Corrected core speed, rpm\", \n",
    "                     \"Bypass Ratio, unitless\", \n",
    "                     \"Burner fuel-air ratio, unitless\", \n",
    "                     \"Bleed Enthalpy, unitless\", \n",
    "                     \"Demanded fan speed, rpm\", \n",
    "                     \"Demanded corrected fan speed, rpm\", \n",
    "                     \"HPT coolant bleed, lbm/s\", \n",
    "                     \"LPT coolant bleed, lbm/s\"]\n",
    "    #Temps are in R; for temps in F, subtract 459.67\n",
    "    #Pressures are in psia\n",
    "    #Speed is in rpm\n",
    "    #\"phi Fuel Flow Ratio\" is ration of fuel flow to static pressure at HPC, in pps/psi\n",
    "    #Bypass ratio - proportion of air mass passing through bypass versus the engine core (compressors/burners/turbines)\n",
    "    #\"Bleed Enthalpy\" refers to bleed air (?), and the total enthalpy of it (Enthalpy = Internal Energy + (Pressure*Volume))\n",
    "    #Coolant Bleed is in pound mass per second (lbm/s)\n",
    "    \n",
    "sensor_names = ['sensor_{}'.format(i) for i in range(1, 22)]\n",
    "\n",
    "feature_dictionary_short = {}\n",
    "feature_dictionary_long = {}\n",
    "for i, sensor in enumerate(sensor_names):\n",
    "    feature_dictionary_short[sensor] = description_headers[i]\n",
    "    feature_dictionary_long[sensor] = long_descriptions[i]\n",
    "    \n",
    "for key in feature_dictionary_long.keys():\n",
    "    print(key, \": \", feature_dictionary_long[key])\n",
    "    \n",
    "del description_headers\n",
    "del long_descriptions\n",
    "del sensor_names\n",
    "\n",
    "smooth_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ad397cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENSORS REMOVED\n",
      "sensor_1 :  Total temperature at fan inlet, degrees rankine\n",
      "sensor_5 :  Pressure at fan inlet, psia\n",
      "sensor_10 :  Engine pressure ratio (P50/P2) where P2 is Pressure at Fan Inlet and P50 is Pressure at LPT outlet, psia\n",
      "sensor_14 :  Corrected core speed, rpm\n",
      "sensor_16 :  Burner fuel-air ratio, unitless\n",
      "sensor_18 :  Demanded fan speed, rpm\n",
      "sensor_19 :  Demanded corrected fan speed, rpm\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = []\n",
    "for key in feature_dictionary_long.keys():\n",
    "    if key not in smooth_train.iloc[:,2:].keys():\n",
    "        columns_to_drop.append(key)\n",
    "\n",
    "print('SENSORS REMOVED') \n",
    "for item in columns_to_drop:\n",
    "    print(item + \" : \", feature_dictionary_long[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb212e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENSORS KEPT AS FIELDS\n",
      "sensor_2 :  Total temperature at Low Pressure Compressor (LPC) outlet, degrees rankine\n",
      "sensor_3 :  Total temperature at High Pressure Compressor (HPC) outlet, degrees rankine\n",
      "sensor_4 :  Total temperature at Low Pressure Turbine (LPT) outlet, degrees rankine\n",
      "sensor_6 :  Total pressure in bypass-duct, psia\n",
      "sensor_7 :  Total pressure at HPC outlet, psia\n",
      "sensor_8 :  Physical fan speed, rpm\n",
      "sensor_9 :  Physical core speed, rpm\n",
      "sensor_11 :  Static pressure at HPC outlet, psia\n",
      "sensor_12 :  Ratio of fuel flow to Ps30 where Ps30 is static pressure at HPC outlet, pps/psi\n",
      "sensor_13 :  Corrected fan speed, rpm\n",
      "sensor_15 :  Bypass Ratio, unitless\n",
      "sensor_17 :  Bleed Enthalpy, unitless\n",
      "sensor_20 :  HPT coolant bleed, lbm/s\n",
      "sensor_21 :  LPT coolant bleed, lbm/s\n"
     ]
    }
   ],
   "source": [
    "print('SENSORS KEPT AS FIELDS') \n",
    "for key in feature_dictionary_long.keys():\n",
    "    if key in smooth_train.iloc[:,2:].keys():\n",
    "        print(key + \" : \", feature_dictionary_long[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477fb1ec",
   "metadata": {},
   "source": [
    "# 2.0 Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32928261",
   "metadata": {},
   "source": [
    "Definitions used in the model creation and tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6266ada",
   "metadata": {},
   "source": [
    "## 2.1 Function Definitions for Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54432f7c",
   "metadata": {},
   "source": [
    "Data can be scaled, but may not be neccessary with decision trees.\n",
    "\n",
    "Two options for a scaler exist - 'standard' and 'minmax', both built off the canned sklearn scalers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb27d7b",
   "metadata": {},
   "source": [
    "Since decision trees consider each instance separately (as a singular moment in time), extra consideration was given to how the different time series fields are changing over the time cycles. To do this, the below functions break apart the data set into the separate engines, add additional fields representing changes in each time series field, and then rebuild the dataset by concatenating the engines back into a single dataframe with the new fields (this is Step 4 in the main pipeline function defined below). \n",
    "\n",
    "For each existing field, one or two additional fields are possible to represent the observed changes in that field. The changes are measured using windows and are summarized as follows:\n",
    "\n",
    "<ul>\n",
    "  <li>Average Change ('avg'): average change between each consecutive time step within the designated window. The larger the time window, the larger the time frame the field considers for average change.</li><br>\n",
    "  <li>Absolute Change ('abs'): absolute change between the first and last rows in a window.</li><br>\n",
    "  <li>Acceleration of Change ('acc'): Measures if the rate of change of the field is increasing or decreasing, and to what extent. It does this by first taking the difference as defined below with input 'dif', and then taking the absolute differences (dependent on window size) of those differences.</li><br>\n",
    "    <li>Difference ('dif'): The difference between the current instance and the immediate preceding instance. Is the same as absolute change with a window size of 2. </li>\n",
    "</ul>\n",
    "This methodoly creates some fields with NaN values at the beginnning of each engine's time series. An option is available to drop the rows with NaN values with the default option being \"True\" (default is to drop NaN values). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ad890c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_window_field(data, size, typ, min_p, num):\n",
    "    if num == \"1\":\n",
    "        cols = list(data.columns)\n",
    "    elif num == \"2\":\n",
    "        cols = list(data.columns[0:14])\n",
    "    \n",
    "    for col in cols:\n",
    "        dif = data[col].diff()\n",
    "        name = \"w\" + num + \"_\" + typ + \"_\" + col\n",
    "        lamb_x = lambda x: x.iloc[-1] - x.iloc[0]\n",
    "        if typ == 'avg':\n",
    "            data[name] = dif.rolling(window = size, min_periods = min_p).mean()\n",
    "        elif typ == 'abs':\n",
    "            data[name] = data[col].rolling(window = size, min_periods = min_p).apply(lamb_x)\n",
    "        elif typ == 'acc':\n",
    "            data[name] = dif.rolling(window = size, min_periods = min_p).apply(lamb_x)\n",
    "        elif typ == 'dif':\n",
    "            data[name] = dif\n",
    "        else:\n",
    "            raise NameError(\"The window type was not properly specified.\")           \n",
    "    return data\n",
    "\n",
    "def add_window_fields(dat, p, num, show_prints = False):\n",
    "    #Initialize new dataframe, exclude identifier columns (unit and cycle)\n",
    "    n_tn = dat.copy().iloc[:0,2:]\n",
    "    \n",
    "    #Break apart existing dataframe by engine\n",
    "    for unit in dat['unit_number'].unique():\n",
    "            #Create new fields w/ function\n",
    "            chunk = dat[dat['unit_number'] == unit].iloc[:,2:]\n",
    "            if show_prints == True:\n",
    "                print(\"Unit \", unit)\n",
    "                display(chunk)    \n",
    "            chunk = add_window_field(chunk, \n",
    "                                     p[\"first_window\"], \n",
    "                                     p[\"first_window_type\"], \n",
    "                                     p[\"min_periods\"], \n",
    "                                     num)\n",
    "            if show_prints == True:\n",
    "                display(chunk)\n",
    "            #Append chunk to newly initialized dataframe\n",
    "            n_tn = pd.concat([n_tn, chunk], ignore_index = True)\n",
    "            \n",
    "    #First add back in identifier columns, then return new dataframe\n",
    "    n_tn = pd.concat([dat.iloc[:,:2], n_tn], axis = 1, ignore_index = False)\n",
    "    return n_tn\n",
    "\n",
    "def process_data(params, train, test, y_train):\n",
    "    \n",
    "    #STEP 1\n",
    "    #Throw an error if the designated windows are too big. \n",
    "    if params['first_window'] != None:\n",
    "        if params['first_window'] > 30:\n",
    "            raise ValueError('Window size cannot be greater than 30 to maintain functionality with the given test set.')\n",
    "    if params['second_window'] != None:\n",
    "        if params['second_window'] > 30:\n",
    "            raise ValueError('Window size cannot be greater than 30 to maintain functionality with the given test set.')\n",
    "    \n",
    "    #STEP 2\n",
    "    #Initialize required variables/datasets used in this function definition.\n",
    "    trn = train.iloc[:,2:]\n",
    "    tst = test.iloc[:,2:]\n",
    "    y_trn = y_train\n",
    "    cols = train.columns[2:]\n",
    "    before = len(trn)\n",
    "    \n",
    "#     print(\"STEP 2:\")\n",
    "#     display(tst.head(5))\n",
    "    \n",
    "    #STEP 3\n",
    "    #Scale the test and train sets fit on all the fields in the train set (regardless of unit).\n",
    "    #Don't forget to reattach the 'unit_number' and 'cycles'\n",
    "    if params['scaler'] == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif params['scaler'] == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif params['scaler'] == None:\n",
    "        scaler = None\n",
    "    else:\n",
    "        raise NameError(\"The designated scaler does not exist or is not available.\")\n",
    "    \n",
    "    if scaler != None:\n",
    "        trn = pd.DataFrame(scaler.fit_transform(trn), columns = cols)\n",
    "        tst = pd.DataFrame(scaler.transform(tst), columns = cols)\n",
    "\n",
    "    trn = pd.concat([train.iloc[:,:2], trn], axis = 1)\n",
    "    tst = pd.concat([test.iloc[:,:2], tst], axis = 1)\n",
    "    \n",
    "#     print(\"STEP 3:\")\n",
    "#     display(tst.head(5))\n",
    "    \n",
    "    #STEP 4 (OPTIONAL BOOLEAN - USES PREVIOUSLY DEFINED FUNCTIONS)\n",
    "    #Add new features to test and train sets, keep it confined to individual engines.\n",
    "    #Use if statement to determine if new columns are desired\n",
    "    if params[\"first_window\"] != None:\n",
    "        trn = add_window_fields(trn, params, \"1\")\n",
    "        tst = add_window_fields(tst, params, \"1\")\n",
    "    if params[\"second_window\"] != None:\n",
    "        trn = add_window_fields(trn, params, \"2\")\n",
    "        tst = add_window_fields(tst, params, \"2\")\n",
    "\n",
    "#     print(\"STEP 4:\")\n",
    "#     display(tst.head(5))\n",
    "    \n",
    "    #STEP 5 (OPTIONAL BOOLEAN)\n",
    "    #Drop na values from train and test sets, if desired. \n",
    "    if params['drop_nan_train'] == True:\n",
    "        trn[\"RUL\"] = y_trn\n",
    "        trn.dropna(inplace = True)\n",
    "        y_trn = trn[\"RUL\"]\n",
    "        trn.drop(['RUL'], axis = 1, inplace = True)\n",
    "        \n",
    "        tst.dropna(inplace = True)\n",
    "\n",
    "#     print(\"STEP 5:\")\n",
    "#     display(tst.head(5))\n",
    "    \n",
    "    #STEP 6\n",
    "    #Extract final row from each test set. \n",
    "    temp_df = tst.iloc[:0,:]\n",
    "    for unit in tst['unit_number'].unique():\n",
    "        tail = tst[tst['unit_number'] == unit].tail(1)\n",
    "        temp_df = pd.concat([temp_df, tail], ignore_index = True)\n",
    "    tst = temp_df\n",
    "    \n",
    "#     print(\"STEP 6:\")\n",
    "#     display(tst.head(5))\n",
    "    \n",
    "    #STEP 7\n",
    "    #Record number of dropped rows from train data and number of features, to include in record.\n",
    "    dropped = before - len(trn)\n",
    "    num_feat = len(trn.columns)\n",
    "    \n",
    "    #STEP 7\n",
    "    #Return each processed dataframe\n",
    "    return trn, tst, y_trn, {'num_features': num_feat - 2, 'train_samples_dropped': dropped}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba670c4",
   "metadata": {},
   "source": [
    "## 2.2 Model Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4febe2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_and_train_GBDT(params, train_data, train_target):\n",
    "    \n",
    "    \"\"\"\n",
    "    Intializes a gradient-boosted decision tree using sklearn Library. \n",
    "    Parmeters are entered as a library. \n",
    "    \n",
    "    Inputs:\n",
    "    params: library of input parameters, must include .... \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    model = GradientBoostingRegressor(loss = 'squared_error', \n",
    "                                      learning_rate = params['mod_learning_rate'], \n",
    "                                      n_estimators = params['mod_n_estimators'], \n",
    "                                      subsample = params['mod_subsample'],   #Set to less than 1 to help with overfitting\n",
    "                                      min_samples_split = params['mod_min_samples_split'], #Min to split into two branches\n",
    "                                      min_samples_leaf = params['mod_min_samples_leaf'], #Min in each branch at a split-can help with overfitting\n",
    "                                      max_depth = params['mod_max_depth'], \n",
    "                                      validation_fraction = 0.1, \n",
    "                                      n_iter_no_change = params['mod_validation']) \n",
    "    \n",
    "    model.fit(train_data, train_target)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "260a3d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GBDT_run_for_log(model, train_data, train_target, test_data, test_target, params):\n",
    "    \n",
    "    \"\"\" \n",
    "    Trains an input model on the input train data, then collects various scoring metrics of both the \n",
    "    train and test data. The input parameters dictionary is then concatenated with the metrics to provide \n",
    "    a dictionary of both the metrics and input parameters used. \n",
    "    \n",
    "    Inputs:\n",
    "    \n",
    "    Model: Gradient-Boosted Decision Tree model from the previous function above ('make_and_train_GBDT') \n",
    "    or GBDT defined via other means\n",
    "    \n",
    "    Various data inputs: Train and Test, plus targets\n",
    "    \n",
    "    params: library of parameters. Must include 'perform_validation' and '#_epochs'.\n",
    "    \n",
    "    Output: library of train and test parameters, along with parameters included in the 'params' input. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    logger = {}\n",
    "    \n",
    "    y_hat_train = model.predict(train_data)\n",
    "    y_hat_test = model.predict(test_data)\n",
    "    \n",
    "    logger[\"train_MSE\"] = mean_squared_error(train_target, y_hat_train).item()\n",
    "    logger[\"test_MSE\"] = mean_squared_error(test_target, y_hat_test).item()\n",
    "    \n",
    "    logger[\"train_RMSE\"] = np.sqrt(mean_squared_error(train_target, y_hat_train)).item()\n",
    "    logger[\"test_RMSE\"] = np.sqrt(mean_squared_error(test_target, y_hat_test)).item()\n",
    "    \n",
    "    logger[\"train_MAE\"] = mean_absolute_error(train_target, y_hat_train).item()\n",
    "    logger[\"test_MAE\"] = mean_absolute_error(test_target, y_hat_test).item()\n",
    "    \n",
    "    logger[\"train_MAPE\"] = np.mean(np.abs((train_target - y_hat_train) / y_hat_train)).item() * 100\n",
    "    logger[\"test_MAPE\"] = np.mean(np.abs((test_target - y_hat_test) / y_hat_test)).item() * 100\n",
    "    \n",
    "    logger[\"train_R2\"] = r2_score(train_target, y_hat_train)\n",
    "    logger[\"test_R2\"] = r2_score(test_target, y_hat_test)\n",
    "    \n",
    "    logger.update(params)\n",
    "    \n",
    "    return logger\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad676214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_logger(new_instance, existing_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes in a new instance of the function 'GBDT_run_for_log' which returns the performance metrics \n",
    "    for a GBDT using the listed input parameters. It then adds that instance to a dictionary of lists,\n",
    "    where each index in the list represents a new run of 'GBDT_run_for_log'. This is intended to be used\n",
    "    in running loops during parameter tuning to keep track of which parameters perform the best. \n",
    "    \n",
    "    Input:\n",
    "    new_instance: a dictionary of the most recent parameters and performance metrics\n",
    "    existing_dict: a dictionary of lists that keep a record of performance metrics and the parameters that\n",
    "            led to those results\n",
    "    \n",
    "    Output:\n",
    "    An updated record of parameters/performance metrics in which the most recent parameters are added to the record\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if existing_dict == None:\n",
    "        record = {}\n",
    "        for key in new_instance.keys():\n",
    "            record[key] = []\n",
    "    else:\n",
    "        record = existing_dict.copy()\n",
    "        \n",
    "    for key in record.keys():\n",
    "        l = record[key]\n",
    "        if key in new_instance.keys():\n",
    "            l.append(new_instance[key])     \n",
    "        else:\n",
    "            l.append(np.nan)\n",
    "        record[key] = l\n",
    "        \n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "715ef389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_through_parameters(loops, \n",
    "                            parameters, \n",
    "                            train, \n",
    "                            y_train, \n",
    "                            test, \n",
    "                            y_test):\n",
    "    \"\"\"\n",
    "    Runs parameter loops for model and records the resulting metrics. Returns a dictionary that is \n",
    "    a log of the results, where each key represents a parameter or performance metric, and each item is\n",
    "    a list where the indexes represent the runs in chronological order. \n",
    "    \n",
    "    Inputs:\n",
    "    loops: a dictionary of the the keys and values to loop through.\n",
    "    params: a dictionary with all the parameters neccessary to build the CNN, train it, and acquire the \n",
    "    results using the functions defined previously.\n",
    "    \n",
    "    Output:\n",
    "    A dictionary of lists with input parameters and resultant performance metrics. Can easily be used\n",
    "    to construct a dataframe. \n",
    "    \"\"\"\n",
    "    \n",
    "    record = None\n",
    "    keys = list(loops.keys())\n",
    "    \n",
    "    def nested_function(p1 = None, p2 = None, p3 = None, p4 = None):\n",
    "        parameters[keys[0]] = p1\n",
    "        if len(keys) > 1:\n",
    "            parameters[keys[1]] = p2\n",
    "        if len(keys) > 2:\n",
    "            parameters[keys[2]] = p3\n",
    "        if len(keys) > 3:\n",
    "            parameters[keys[3]] = p4\n",
    "            \n",
    "#         print(parameters)\n",
    "#         print(test.columns)\n",
    "\n",
    "        trn, tst, trn_tar, d = process_data(parameters, train, test, y_train)\n",
    "\n",
    "        trn = trn.iloc[:,2:]\n",
    "        tst = tst.iloc[:,2:]\n",
    "#         print(trn.shape)\n",
    "#         print(tst.shape)\n",
    "#         print(trn_tar.shape)\n",
    "#         print(y_test)\n",
    "        \n",
    "        model = make_and_train_GBDT(parameters, trn, trn_tar)\n",
    "        \n",
    "        new_instance = GBDT_run_for_log(model, trn, trn_tar, tst, y_test, parameters)\n",
    "        \n",
    "        for key in d.keys():\n",
    "            new_instance[key] = d[key]\n",
    "        \n",
    "        r = add_to_logger(new_instance, record)\n",
    "        \n",
    "        return r\n",
    "        \n",
    "    if len(loops.keys()) == 1:\n",
    "        for p_1 in loops[keys[0]]:\n",
    "            print(\"Starting first loop with value \", p_1, \".\")\n",
    "            record = nested_function(p1 = p_1)\n",
    "            \n",
    "    elif len(loops.keys()) == 2:\n",
    "        for p_1 in loops[keys[0]]:\n",
    "            print(\"Starting first loop with value \", p_1, \".\")\n",
    "            for p_2 in loops[keys[1]]:\n",
    "                record = nested_function(p1 = p_1, p2 = p_2)\n",
    "                \n",
    "    elif len(loops.keys()) == 3:\n",
    "        for p_1 in loops[keys[0]]:\n",
    "            print(\"Starting first loop with value \", p_1, \".\")\n",
    "            for p_2 in loops[keys[1]]:\n",
    "                for p_3 in loops[keys[2]]:\n",
    "                    record = nested_function(p1 = p_1, p2 = p_2, p3 = p_3)\n",
    "                    \n",
    "    else:\n",
    "        for p_1 in loops[keys[0]]:\n",
    "            print(\"Starting first loop with value \", p_1, \".\")\n",
    "            for p_2 in loops[keys[1]]:\n",
    "                for p_3 in loops[keys[2]]:\n",
    "                    for p_4 in loops[keys[3]]:\n",
    "                        print(\"     Running with variables \", p_2, \", \", p_3, \", and \", p_4, \".\")\n",
    "                        record = nested_function(p1 = p_1, p2 = p_2, p3 = p_3, p4 = p_4)\n",
    "                        \n",
    "    return record\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28ff984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_GBDT_log(record, link = 'GBDT_log.csv', save_changes = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Combines most recent group of models with those saved in the log file. Includes designating a\n",
    "    tuning group based on the most recent tuning group in the log file.\n",
    "    \n",
    "    Inputs:\n",
    "    record: most recent record set of parameter tunings, as returned by above functions.\n",
    "    link: pathway and filename for the saved log file, it if exists. If it doesn't exist, this \n",
    "        function won't work.\n",
    "    save_changes: designates whether to save the updates to the CSV file that stores the model parameter tuning results.\n",
    "    \n",
    "    Output:\n",
    "    A dataframe of the combines records on file and the most recent turning group. \n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(link)\n",
    "    group_num = df['tuning_group'].max() + 1\n",
    "    r = pd.DataFrame(record)\n",
    "    r.insert(0, 'tuning_group', group_num)\n",
    "    \n",
    "    df = pd.concat([df, r], ignore_index = True)\n",
    "\n",
    "    if save_changes == True:\n",
    "        df.to_csv(link, index = False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bfd66aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(data, fields):\n",
    "    \n",
    "    \"\"\"\n",
    "    Makes a simple Altair Chart for compairing results visually.\n",
    "    \n",
    "    Input:\n",
    "    data: Dataframe that includes the fields from the most current record or from the CNN_log saved as a CSV.\n",
    "    fields: designated fields to encode using shape and color. Default are the first two designated in the \n",
    "        most recent record.\n",
    "        \n",
    "    Output:\n",
    "    A chart comparing changes in the designated fields, mapped against test RMSE and difference between\n",
    "        train and test RMSE.\n",
    "    \"\"\"\n",
    "\n",
    "    data['RMSE_diff'] = data['test_RMSE'] - data['train_RMSE']\n",
    "    fields_to_keep = [\"test_RMSE\", \"train_RMSE\", \"RMSE_diff\"] + fields\n",
    "    data = data[fields_to_keep]\n",
    "    \n",
    "    if len(fields) > 1:\n",
    "        chart = alt.Chart(data).mark_point().encode(x = alt.X(\"test_RMSE\").scale(zero = False), \n",
    "                                                y = 'RMSE_diff', \n",
    "                                                color = fields[0] + \":N\", \n",
    "                                                shape = fields[1] + \":N\")\n",
    "    else:\n",
    "        chart = alt.Chart(data).mark_point().encode(x = alt.X(\"test_RMSE\").scale(zero = False), \n",
    "                                                y = 'RMSE_diff', \n",
    "                                                shape = fields[0] + \":N\",\n",
    "                                                color = fields[0] + \":N\"\n",
    "                                                )\n",
    "\n",
    "    return chart\n",
    "\n",
    "def show_df_of_results(data, fields):\n",
    "    data['RMSE_diff'] = data['test_RMSE'] - data['train_RMSE']\n",
    "    fields_to_keep = [\"test_RMSE\", \"train_RMSE\", \"RMSE_diff\"] + fields\n",
    "    data = data[fields_to_keep]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b837de9",
   "metadata": {},
   "source": [
    "# 3.0 Building Models and Exploring Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c61ce7b",
   "metadata": {},
   "source": [
    "Different processing procedures (for example, different window sizes and additional fields added) and model input parameters were used to explore the best data input variation and the best model parameter selection. The functions defined in Sections 2.1 and 2.2 are utilized to perform looping of different variations of model and data architecture. Results are stored in a .CSV file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b255cd5",
   "metadata": {},
   "source": [
    "## 3.1 Define the default parameters and those to change while looping. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbacb39",
   "metadata": {},
   "source": [
    "The cell below was used while tuning the GBDT model. Different \"tuning groups\" were used in loops and then investigated by studying plots and dataframes. Thereafter, a new tuning group would be created for further investigation. The goal was to find the best model that maximized the accuracy but minimized overtraining. \n",
    "\n",
    "The dictionary variable \"parameters\" hold default parameters used by the processing/model. The dictionary variable \"loops\" shows the fields that are looped through for each tuning group. If a field is not included in \"loops\", then the default value is used for each model iteration. \n",
    "\n",
    "For future reference, each tuning group was commented out after the results were recorded. \n",
    "\n",
    "NOTE FOR SMOOTHED DATA ANALYSIS: Only one tuning group was performed for the smoothed data. The models did not generalize; it was assumed this was due to an issue with the smoothing, and further analysis was abandoned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "69527ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter List\n",
    "parameters = {'scaler': None,  #Left as none because data is already scaled\n",
    "            'first_window': None, \n",
    "            'first_window_type': 'abs', #options: avg, dif, acc, abs\n",
    "            'second_window': None, \n",
    "            'second_window_type': 'avg', \n",
    "            'drop_nan_train': True,\n",
    "            'min_periods': None, \n",
    "            'mod_loss': 'squared_error', \n",
    "            'mod_learning_rate': 0.2, \n",
    "            'mod_n_estimators': 400, \n",
    "            'mod_subsample': 1.0,\n",
    "            'mod_min_samples_split': 2, \n",
    "            'mod_min_samples_leaf': 1, \n",
    "            'mod_max_depth': 3, \n",
    "            'mod_validation': None  #requires integer as input - number of iterations with no change\n",
    "            }\n",
    "\n",
    "loops = {\n",
    "         'mod_learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5], #GROUP 1 - CHOOSE AROUND 0.4\n",
    "         'mod_n_estimators': [10, 20, 50, 100, 200, 300, 500], #GROUP 1 - CHOOSE B/T 20 AND 100\n",
    "         'mod_max_depth': [3, 5, 7, 9], #GROUP 1 - CHOOSE 2-5\n",
    "#          'scaler': ['standard', 'minmax', None], #GROUP 1 - MAKES NO DIFFERENCE, STAY WITH STANDARD\n",
    "#          'mod_learning_rate': [3.75, 0.4, 0.425, 0.45, 0.475], #GROUP 2 - CHOOSE 0.425\n",
    "#          'mod_n_estimators': [15, 20, 25, 30, 35, 40, 45, 50, 55, 60], #GROUP 2 - CHOOSE 55\n",
    "#          'mod_max_depth': [2, 3, 4], #GROUP 2 - CHOOSE 3\n",
    "#          'mod_validation': [None, 2], #GROUP 2 - GO W/ NONE\n",
    "#          'first_window': [3, 5, 7, 10, 15, 20], #GROUP 3 - try higher window sizes\n",
    "#          'first_window_type': ['avg', 'dif', 'acc', 'abs'], #GROUP 3 - stick to avg and abs\n",
    "#          'mod_n_estimators': [50, 55, 60, 70, 80, 100], #GROUP 3 - try higher number of estimators\n",
    "#          'mod_learning_rate': [0.1, 0.425], #GROUP 3 - try wider range\n",
    "#          'first_window': [12, 18, 20, 25, 30], #GROUP 4 - go with 30\n",
    "#          'first_window_type': ['avg', 'abs'], #GROUP 4 - GO WITH avg\n",
    "#          'mod_n_estimators': [100, 200, 300], #GROUP 4 - try 200 - 600\n",
    "#          'mod_learning_rate': [0.05, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5] #GROUP 4 - TRY .18 TO .32\n",
    "#          'first_window': [20, 22, 24, 26, 28, 30], #GROUP 5 - KEEP 30\n",
    "#          'first_window_type': ['avg', 'abs', 'acc'], #GROUP 5 - KEEP ABS\n",
    "#          'mod_n_estimators': [250, 300, 350, 400, 450, 500], #GROUP 5 - KEEP 400\n",
    "#          'mod_learning_rate': [0.175, 0.2, 0.225, 0.25, 0.275, 0.3, 0.325] #GROUP 5 - KEEP 0.2, BEST PROBABLY B/T .2 AND .25\n",
    "#          'second_window': [3, 5, 10, 20], #GROUP 6\n",
    "#          'second_window_type': ['avg', 'abs', 'acc', 'dif'], #GROUP 6\n",
    "#          'mod_n_estimators': [300, 400, 500, 600], #GROUP 6\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5fd973",
   "metadata": {},
   "source": [
    "## 3.2 Run processing/model loops and study results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0078e772",
   "metadata": {},
   "source": [
    "Each tuning group was assessed manually and individually. The results were used to determine the looping parameters to use in the consecutive tuning group. Results are stored in the .CSV file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7da995e",
   "metadata": {},
   "source": [
    "### 3.2.1 Run processing/model loops as defined in Section 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2162d27a",
   "metadata": {},
   "source": [
    "The loops are ran with in the block below using the inputs designated in the block above.\n",
    "\n",
    "The function below is commented out when not in use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2eb617d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for each key and associated list in 'loops', make a record of results for different parameters.\n",
    "\n",
    "# record = loop_through_parameters(loops, parameters, smooth_train, smooth_y_train, smooth_test, smooth_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f765649d",
   "metadata": {},
   "source": [
    "### 3.2.2 Compare results graphically and in a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcda1db",
   "metadata": {},
   "source": [
    "COMMENT FOR SMOOTHED DATA ANALYSIS: The below sets the log file equal to 'record' so it can be visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a59ea4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = pd.read_csv(\"GBDT_SMOOTH_Data_Log.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9463bb5",
   "metadata": {},
   "source": [
    "Results from the most recent tuning group were viewed below. \n",
    "\n",
    "COMMENT FOR SMOOTHED DATA ANALYSIS: As can be seen below, the RMSE is significantly worse than for the unsmoothed data, while the difference in RMSE between the test and train set is not significantly less than 3 (poor generalization). This is better results with the smoothed data than with the CNN model, however not considered promising, so further analysis was abandoned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "baba79b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mod_learning_rate', 'mod_n_estimators', 'mod_max_depth'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-bc542bb9e1ac4522bb6c399ce1c9e663.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-bc542bb9e1ac4522bb6c399ce1c9e663.vega-embed details,\n",
       "  #altair-viz-bc542bb9e1ac4522bb6c399ce1c9e663.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-bc542bb9e1ac4522bb6c399ce1c9e663\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-bc542bb9e1ac4522bb6c399ce1c9e663\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-bc542bb9e1ac4522bb6c399ce1c9e663\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-92ec34712e28d8ea34b142eddb19494c\"}, \"mark\": {\"type\": \"point\"}, \"encoding\": {\"color\": {\"field\": \"mod_max_depth\", \"type\": \"nominal\"}, \"shape\": {\"field\": \"mod_max_depth\", \"type\": \"nominal\"}, \"x\": {\"field\": \"test_RMSE\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"field\": \"RMSE_diff\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-92ec34712e28d8ea34b142eddb19494c\": [{\"test_RMSE\": 42.94889308864739, \"train_RMSE\": 38.45820271910945, \"RMSE_diff\": 4.490690369537937, \"mod_max_depth\": 3}, {\"test_RMSE\": 42.64469343044005, \"train_RMSE\": 38.30207562066866, \"RMSE_diff\": 4.34261780977139, \"mod_max_depth\": 5}, {\"test_RMSE\": 42.51578543771746, \"train_RMSE\": 38.20426944923785, \"RMSE_diff\": 4.311515988479613, \"mod_max_depth\": 7}, {\"test_RMSE\": 42.45577863013835, \"train_RMSE\": 38.08341005294838, \"RMSE_diff\": 4.372368577189967, \"mod_max_depth\": 9}, {\"test_RMSE\": 39.388162630148784, \"train_RMSE\": 35.60166808377512, \"RMSE_diff\": 3.7864945463736674, \"mod_max_depth\": 3}, {\"test_RMSE\": 38.76730816041604, \"train_RMSE\": 35.300599663541306, \"RMSE_diff\": 3.4667084968747375, \"mod_max_depth\": 5}, {\"test_RMSE\": 38.518095088631, \"train_RMSE\": 35.10667506209064, \"RMSE_diff\": 3.4114200265403625, \"mod_max_depth\": 7}, {\"test_RMSE\": 38.38501013773397, \"train_RMSE\": 34.86105736687048, \"RMSE_diff\": 3.523952770863488, \"mod_max_depth\": 9}, {\"test_RMSE\": 32.033405240345104, \"train_RMSE\": 28.828551561632462, \"RMSE_diff\": 3.2048536787126416, \"mod_max_depth\": 3}, {\"test_RMSE\": 31.07372668528954, \"train_RMSE\": 28.17709153440521, \"RMSE_diff\": 2.896635150884329, \"mod_max_depth\": 5}, {\"test_RMSE\": 30.49902590170546, \"train_RMSE\": 27.666355692408317, \"RMSE_diff\": 2.8326702092971416, \"mod_max_depth\": 7}, {\"test_RMSE\": 30.567545882140543, \"train_RMSE\": 27.02660969184937, \"RMSE_diff\": 3.5409361902911733, \"mod_max_depth\": 9}, {\"test_RMSE\": 27.942005868729733, \"train_RMSE\": 21.940636342392484, \"RMSE_diff\": 6.00136952633725, \"mod_max_depth\": 3}, {\"test_RMSE\": 27.413535836268785, \"train_RMSE\": 20.97827719864343, \"RMSE_diff\": 6.435258637625356, \"mod_max_depth\": 5}, {\"test_RMSE\": 27.32156158272152, \"train_RMSE\": 19.912369004442954, \"RMSE_diff\": 7.409192578278567, \"mod_max_depth\": 7}, {\"test_RMSE\": 27.841820896907542, \"train_RMSE\": 18.536480107537205, \"RMSE_diff\": 9.305340789370337, \"mod_max_depth\": 9}, {\"test_RMSE\": 30.214896118356005, \"train_RMSE\": 16.837793354547735, \"RMSE_diff\": 13.37710276380827, \"mod_max_depth\": 3}, {\"test_RMSE\": 30.92978967025571, \"train_RMSE\": 15.611314364625043, \"RMSE_diff\": 15.318475305630665, \"mod_max_depth\": 5}, {\"test_RMSE\": 32.174774323482545, \"train_RMSE\": 13.651546249637349, \"RMSE_diff\": 18.523228073845196, \"mod_max_depth\": 7}, {\"test_RMSE\": 32.64949289208776, \"train_RMSE\": 10.98725334672805, \"RMSE_diff\": 21.662239545359707, \"mod_max_depth\": 9}, {\"test_RMSE\": 32.61721456565814, \"train_RMSE\": 15.666793549545613, \"RMSE_diff\": 16.950421016112525, \"mod_max_depth\": 3}, {\"test_RMSE\": 34.26979279509076, \"train_RMSE\": 14.027706293829318, \"RMSE_diff\": 20.24208650126144, \"mod_max_depth\": 5}, {\"test_RMSE\": 35.61341048124254, \"train_RMSE\": 11.457755508794378, \"RMSE_diff\": 24.15565497244816, \"mod_max_depth\": 7}, {\"test_RMSE\": 36.18102641198628, \"train_RMSE\": 8.390611715828653, \"RMSE_diff\": 27.790414696157626, \"mod_max_depth\": 9}, {\"test_RMSE\": 34.74881353169465, \"train_RMSE\": 15.004334530706306, \"RMSE_diff\": 19.744479000988346, \"mod_max_depth\": 3}, {\"test_RMSE\": 37.27706825986567, \"train_RMSE\": 12.740248187605244, \"RMSE_diff\": 24.536820072260426, \"mod_max_depth\": 5}, {\"test_RMSE\": 38.16578691430095, \"train_RMSE\": 9.255498207535268, \"RMSE_diff\": 28.910288706765684, \"mod_max_depth\": 7}, {\"test_RMSE\": 38.50710735912418, \"train_RMSE\": 5.926443864668889, \"RMSE_diff\": 32.58066349445529, \"mod_max_depth\": 9}, {\"test_RMSE\": 31.94412161412375, \"train_RMSE\": 28.63239595912083, \"RMSE_diff\": 3.311725655002917, \"mod_max_depth\": 3}, {\"test_RMSE\": 30.784299843149583, \"train_RMSE\": 27.98627273270431, \"RMSE_diff\": 2.798027110445272, \"mod_max_depth\": 5}, {\"test_RMSE\": 30.27820940950041, \"train_RMSE\": 27.467333180683525, \"RMSE_diff\": 2.810876228816884, \"mod_max_depth\": 7}, {\"test_RMSE\": 30.489072119085197, \"train_RMSE\": 26.804479673825544, \"RMSE_diff\": 3.6845924452596535, \"mod_max_depth\": 9}, {\"test_RMSE\": 27.97262824873041, \"train_RMSE\": 21.755008272537584, \"RMSE_diff\": 6.217619976192825, \"mod_max_depth\": 3}, {\"test_RMSE\": 27.49182979016832, \"train_RMSE\": 20.78617760646744, \"RMSE_diff\": 6.705652183700881, \"mod_max_depth\": 5}, {\"test_RMSE\": 27.197247119915783, \"train_RMSE\": 19.68532888723905, \"RMSE_diff\": 7.511918232676734, \"mod_max_depth\": 7}, {\"test_RMSE\": 28.22147527869969, \"train_RMSE\": 18.259883725670758, \"RMSE_diff\": 9.961591553028931, \"mod_max_depth\": 9}, {\"test_RMSE\": 31.57783587686829, \"train_RMSE\": 16.044330363712326, \"RMSE_diff\": 15.533505513155962, \"mod_max_depth\": 3}, {\"test_RMSE\": 32.86882370146414, \"train_RMSE\": 14.560205259585135, \"RMSE_diff\": 18.308618441879002, \"mod_max_depth\": 5}, {\"test_RMSE\": 34.14911099498624, \"train_RMSE\": 12.355357553028638, \"RMSE_diff\": 21.7937534419576, \"mod_max_depth\": 7}, {\"test_RMSE\": 35.16813376125395, \"train_RMSE\": 9.441080525151284, \"RMSE_diff\": 25.727053236102662, \"mod_max_depth\": 9}, {\"test_RMSE\": 34.82117565108924, \"train_RMSE\": 15.003041565500522, \"RMSE_diff\": 19.818134085588717, \"mod_max_depth\": 3}, {\"test_RMSE\": 36.90907066405634, \"train_RMSE\": 12.71745597676729, \"RMSE_diff\": 24.191614687289047, \"mod_max_depth\": 5}, {\"test_RMSE\": 38.182546752483816, \"train_RMSE\": 9.213801493746343, \"RMSE_diff\": 28.96874525873747, \"mod_max_depth\": 7}, {\"test_RMSE\": 38.867804513310325, \"train_RMSE\": 5.906621797549837, \"RMSE_diff\": 32.961182715760486, \"mod_max_depth\": 9}, {\"test_RMSE\": 36.88023587126432, \"train_RMSE\": 14.13884939123692, \"RMSE_diff\": 22.741386480027398, \"mod_max_depth\": 3}, {\"test_RMSE\": 39.01305653323575, \"train_RMSE\": 10.635668589161211, \"RMSE_diff\": 28.377387944074535, \"mod_max_depth\": 5}, {\"test_RMSE\": 39.67701794745211, \"train_RMSE\": 6.348310859186067, \"RMSE_diff\": 33.32870708826604, \"mod_max_depth\": 7}, {\"test_RMSE\": 40.47469469014997, \"train_RMSE\": 2.700688556189046, \"RMSE_diff\": 37.774006133960924, \"mod_max_depth\": 9}, {\"test_RMSE\": 38.46989154720325, \"train_RMSE\": 13.381419344321806, \"RMSE_diff\": 25.08847220288144, \"mod_max_depth\": 3}, {\"test_RMSE\": 40.959442704731806, \"train_RMSE\": 9.098649042141194, \"RMSE_diff\": 31.860793662590613, \"mod_max_depth\": 5}, {\"test_RMSE\": 41.48325091485719, \"train_RMSE\": 4.667050612951319, \"RMSE_diff\": 36.816200301905866, \"mod_max_depth\": 7}, {\"test_RMSE\": 40.909241082384256, \"train_RMSE\": 1.6686898356653677, \"RMSE_diff\": 39.24055124671889, \"mod_max_depth\": 9}, {\"test_RMSE\": 40.99841120590103, \"train_RMSE\": 12.242078079410328, \"RMSE_diff\": 28.756333126490702, \"mod_max_depth\": 3}, {\"test_RMSE\": 44.28541881457093, \"train_RMSE\": 7.035742117555873, \"RMSE_diff\": 37.24967669701506, \"mod_max_depth\": 5}, {\"test_RMSE\": 42.90926694671622, \"train_RMSE\": 2.87541530617097, \"RMSE_diff\": 40.03385164054525, \"mod_max_depth\": 7}, {\"test_RMSE\": 41.60493851847616, \"train_RMSE\": 0.8414117289088833, \"RMSE_diff\": 40.76352678956728, \"mod_max_depth\": 9}, {\"test_RMSE\": 27.892715274653337, \"train_RMSE\": 21.557352707006416, \"RMSE_diff\": 6.335362567646921, \"mod_max_depth\": 3}, {\"test_RMSE\": 27.483473617011573, \"train_RMSE\": 20.540194885603352, \"RMSE_diff\": 6.9432787314082205, \"mod_max_depth\": 5}, {\"test_RMSE\": 27.49718755633946, \"train_RMSE\": 19.424669187796606, \"RMSE_diff\": 8.072518368542852, \"mod_max_depth\": 7}, {\"test_RMSE\": 27.92144131075555, \"train_RMSE\": 18.023806661792328, \"RMSE_diff\": 9.897634648963223, \"mod_max_depth\": 9}, {\"test_RMSE\": 30.45551883497358, \"train_RMSE\": 16.702052726479486, \"RMSE_diff\": 13.753466108494095, \"mod_max_depth\": 3}, {\"test_RMSE\": 31.460339890938965, \"train_RMSE\": 15.398080291006483, \"RMSE_diff\": 16.06225959993248, \"mod_max_depth\": 5}, {\"test_RMSE\": 32.240726219261525, \"train_RMSE\": 13.352085315015623, \"RMSE_diff\": 18.888640904245904, \"mod_max_depth\": 7}, {\"test_RMSE\": 33.000359569028554, \"train_RMSE\": 10.703173312610298, \"RMSE_diff\": 22.297186256418257, \"mod_max_depth\": 9}, {\"test_RMSE\": 34.93820433675725, \"train_RMSE\": 15.044248216088013, \"RMSE_diff\": 19.893956120669237, \"mod_max_depth\": 3}, {\"test_RMSE\": 37.24834507656719, \"train_RMSE\": 12.756372250923972, \"RMSE_diff\": 24.491972825643217, \"mod_max_depth\": 5}, {\"test_RMSE\": 38.834421742776975, \"train_RMSE\": 9.109152327790524, \"RMSE_diff\": 29.72526941498645, \"mod_max_depth\": 7}, {\"test_RMSE\": 38.52699794081104, \"train_RMSE\": 5.868757254534083, \"RMSE_diff\": 32.65824068627696, \"mod_max_depth\": 9}, {\"test_RMSE\": 36.77430551569913, \"train_RMSE\": 14.120902539045094, \"RMSE_diff\": 22.65340297665404, \"mod_max_depth\": 3}, {\"test_RMSE\": 39.44063965553556, \"train_RMSE\": 10.63115662269686, \"RMSE_diff\": 28.809483032838703, \"mod_max_depth\": 5}, {\"test_RMSE\": 40.86504432665169, \"train_RMSE\": 6.263062275163999, \"RMSE_diff\": 34.601982051487695, \"mod_max_depth\": 7}, {\"test_RMSE\": 40.19043723384565, \"train_RMSE\": 2.8211922271739405, \"RMSE_diff\": 37.36924500667171, \"mod_max_depth\": 9}, {\"test_RMSE\": 40.3238567683295, \"train_RMSE\": 12.79625641208029, \"RMSE_diff\": 27.52760035624921, \"mod_max_depth\": 3}, {\"test_RMSE\": 41.91332338419736, \"train_RMSE\": 8.008209424452748, \"RMSE_diff\": 33.90511395974461, \"mod_max_depth\": 5}, {\"test_RMSE\": 42.73016789382323, \"train_RMSE\": 3.4868711717223304, \"RMSE_diff\": 39.2432967221009, \"mod_max_depth\": 7}, {\"test_RMSE\": 41.27882596345084, \"train_RMSE\": 1.188423662311766, \"RMSE_diff\": 40.09040230113908, \"mod_max_depth\": 9}, {\"test_RMSE\": 42.67551615254095, \"train_RMSE\": 11.66467390136136, \"RMSE_diff\": 31.01084225117959, \"mod_max_depth\": 3}, {\"test_RMSE\": 44.094895960238894, \"train_RMSE\": 6.240116119111558, \"RMSE_diff\": 37.85477984112734, \"mod_max_depth\": 5}, {\"test_RMSE\": 44.33886949277768, \"train_RMSE\": 2.3110778473607767, \"RMSE_diff\": 42.027791645416904, \"mod_max_depth\": 7}, {\"test_RMSE\": 41.08217454560869, \"train_RMSE\": 0.7073208700508276, \"RMSE_diff\": 40.37485367555786, \"mod_max_depth\": 9}, {\"test_RMSE\": 47.18387520380126, \"train_RMSE\": 10.195414232789387, \"RMSE_diff\": 36.98846097101187, \"mod_max_depth\": 3}, {\"test_RMSE\": 46.95272892694504, \"train_RMSE\": 4.385173996074999, \"RMSE_diff\": 42.567554930870045, \"mod_max_depth\": 5}, {\"test_RMSE\": 45.63597300016762, \"train_RMSE\": 1.3207119241854892, \"RMSE_diff\": 44.31526107598213, \"mod_max_depth\": 7}, {\"test_RMSE\": 41.82824622635642, \"train_RMSE\": 0.3334901487803306, \"RMSE_diff\": 41.49475607757609, \"mod_max_depth\": 9}, {\"test_RMSE\": 31.01004769616233, \"train_RMSE\": 16.580801523491964, \"RMSE_diff\": 14.429246172670368, \"mod_max_depth\": 3}, {\"test_RMSE\": 32.07235305600344, \"train_RMSE\": 15.294029203238988, \"RMSE_diff\": 16.778323852764455, \"mod_max_depth\": 5}, {\"test_RMSE\": 33.65378502687985, \"train_RMSE\": 13.396511777971488, \"RMSE_diff\": 20.257273248908362, \"mod_max_depth\": 7}, {\"test_RMSE\": 33.308621944436844, \"train_RMSE\": 10.522724287766412, \"RMSE_diff\": 22.785897656670432, \"mod_max_depth\": 9}, {\"test_RMSE\": 34.43568091079783, \"train_RMSE\": 15.291399840473057, \"RMSE_diff\": 19.144281070324773, \"mod_max_depth\": 3}, {\"test_RMSE\": 37.151380611911655, \"train_RMSE\": 13.110675282133329, \"RMSE_diff\": 24.040705329778326, \"mod_max_depth\": 5}, {\"test_RMSE\": 39.6055859208646, \"train_RMSE\": 9.856561374494342, \"RMSE_diff\": 29.749024546370258, \"mod_max_depth\": 7}, {\"test_RMSE\": 37.72121235609684, \"train_RMSE\": 6.858763095589984, \"RMSE_diff\": 30.862449260506857, \"mod_max_depth\": 9}, {\"test_RMSE\": 36.85677137836302, \"train_RMSE\": 14.240754836971057, \"RMSE_diff\": 22.616016541391964, \"mod_max_depth\": 3}, {\"test_RMSE\": 38.86244617285552, \"train_RMSE\": 10.50279923643236, \"RMSE_diff\": 28.35964693642316, \"mod_max_depth\": 5}, {\"test_RMSE\": 42.01923120870335, \"train_RMSE\": 6.094634297582394, \"RMSE_diff\": 35.92459691112096, \"mod_max_depth\": 7}, {\"test_RMSE\": 39.366077402841725, \"train_RMSE\": 2.981819428531353, \"RMSE_diff\": 36.38425797431037, \"mod_max_depth\": 9}, {\"test_RMSE\": 40.15788632289421, \"train_RMSE\": 12.66313517773856, \"RMSE_diff\": 27.494751145155647, \"mod_max_depth\": 3}, {\"test_RMSE\": 43.37128871628013, \"train_RMSE\": 7.612202247127737, \"RMSE_diff\": 35.75908646915239, \"mod_max_depth\": 5}, {\"test_RMSE\": 45.25921674102347, \"train_RMSE\": 3.370407113952429, \"RMSE_diff\": 41.88880962707104, \"mod_max_depth\": 7}, {\"test_RMSE\": 41.17779382834484, \"train_RMSE\": 1.3578186894389876, \"RMSE_diff\": 39.81997513890585, \"mod_max_depth\": 9}, {\"test_RMSE\": 44.37727362999775, \"train_RMSE\": 10.89340668075934, \"RMSE_diff\": 33.48386694923841, \"mod_max_depth\": 3}, {\"test_RMSE\": 46.12382571739624, \"train_RMSE\": 4.907654047181151, \"RMSE_diff\": 41.21617167021508, \"mod_max_depth\": 5}, {\"test_RMSE\": 45.40584663152949, \"train_RMSE\": 1.7235185328686673, \"RMSE_diff\": 43.682328098660825, \"mod_max_depth\": 7}, {\"test_RMSE\": 40.633899944626, \"train_RMSE\": 0.5481182330433138, \"RMSE_diff\": 40.08578171158269, \"mod_max_depth\": 9}, {\"test_RMSE\": 48.01411550604022, \"train_RMSE\": 9.762611514691857, \"RMSE_diff\": 38.251503991348365, \"mod_max_depth\": 3}, {\"test_RMSE\": 47.7671572189292, \"train_RMSE\": 3.563831358695788, \"RMSE_diff\": 44.20332586023341, \"mod_max_depth\": 5}, {\"test_RMSE\": 47.66196589848863, \"train_RMSE\": 1.1096766527289912, \"RMSE_diff\": 46.55228924575964, \"mod_max_depth\": 7}, {\"test_RMSE\": 43.136191206020655, \"train_RMSE\": 0.313918898892976, \"RMSE_diff\": 42.822272307127676, \"mod_max_depth\": 9}, {\"test_RMSE\": 52.99164314299181, \"train_RMSE\": 8.071040225133169, \"RMSE_diff\": 44.920602917858645, \"mod_max_depth\": 3}, {\"test_RMSE\": 49.53768660677706, \"train_RMSE\": 2.30108146751227, \"RMSE_diff\": 47.23660513926479, \"mod_max_depth\": 5}, {\"test_RMSE\": 47.87584679267601, \"train_RMSE\": 0.6031784800011867, \"RMSE_diff\": 47.272668312674824, \"mod_max_depth\": 7}, {\"test_RMSE\": 40.79760519033674, \"train_RMSE\": 0.1408909343802732, \"RMSE_diff\": 40.656714255956466, \"mod_max_depth\": 9}, {\"test_RMSE\": 33.76078067091748, \"train_RMSE\": 15.710244547874508, \"RMSE_diff\": 18.050536123042967, \"mod_max_depth\": 3}, {\"test_RMSE\": 34.947736317863075, \"train_RMSE\": 14.00235015410344, \"RMSE_diff\": 20.945386163759636, \"mod_max_depth\": 5}, {\"test_RMSE\": 36.8154202616199, \"train_RMSE\": 11.276927168244676, \"RMSE_diff\": 25.538493093375223, \"mod_max_depth\": 7}, {\"test_RMSE\": 36.97654632975085, \"train_RMSE\": 8.042900742162198, \"RMSE_diff\": 28.933645587588657, \"mod_max_depth\": 9}, {\"test_RMSE\": 35.662496588767674, \"train_RMSE\": 14.966115749243713, \"RMSE_diff\": 20.69638083952396, \"mod_max_depth\": 3}, {\"test_RMSE\": 39.21740387192585, \"train_RMSE\": 12.346149745105688, \"RMSE_diff\": 26.871254126820165, \"mod_max_depth\": 5}, {\"test_RMSE\": 39.35887864323041, \"train_RMSE\": 8.543514971500707, \"RMSE_diff\": 30.815363671729706, \"mod_max_depth\": 7}, {\"test_RMSE\": 40.28661298169107, \"train_RMSE\": 4.763818763674365, \"RMSE_diff\": 35.522794218016706, \"mod_max_depth\": 9}, {\"test_RMSE\": 38.45049076916623, \"train_RMSE\": 13.550314402823716, \"RMSE_diff\": 24.900176366342514, \"mod_max_depth\": 3}, {\"test_RMSE\": 42.88837244619527, \"train_RMSE\": 8.979068194191875, \"RMSE_diff\": 33.909304252003395, \"mod_max_depth\": 5}, {\"test_RMSE\": 42.32978355233755, \"train_RMSE\": 4.51375601490211, \"RMSE_diff\": 37.816027537435446, \"mod_max_depth\": 7}, {\"test_RMSE\": 39.992318916914776, \"train_RMSE\": 1.84571316715668, \"RMSE_diff\": 38.146605749758095, \"mod_max_depth\": 9}, {\"test_RMSE\": 42.05497696362241, \"train_RMSE\": 11.855999867588087, \"RMSE_diff\": 30.19897709603432, \"mod_max_depth\": 3}, {\"test_RMSE\": 47.40338487539671, \"train_RMSE\": 6.258498366428537, \"RMSE_diff\": 41.14488650896817, \"mod_max_depth\": 5}, {\"test_RMSE\": 44.65307604428534, \"train_RMSE\": 2.485606887770064, \"RMSE_diff\": 42.16746915651528, \"mod_max_depth\": 7}, {\"test_RMSE\": 40.37186167035844, \"train_RMSE\": 0.8524245026740974, \"RMSE_diff\": 39.519437167684345, \"mod_max_depth\": 9}, {\"test_RMSE\": 46.28182809890174, \"train_RMSE\": 9.73398988858146, \"RMSE_diff\": 36.54783821032028, \"mod_max_depth\": 3}, {\"test_RMSE\": 53.0276466450656, \"train_RMSE\": 3.728239864296169, \"RMSE_diff\": 49.29940678076943, \"mod_max_depth\": 5}, {\"test_RMSE\": 45.24524623433504, \"train_RMSE\": 1.2486780990471569, \"RMSE_diff\": 43.99656813528789, \"mod_max_depth\": 7}, {\"test_RMSE\": 41.789996798812695, \"train_RMSE\": 0.3801247855382505, \"RMSE_diff\": 41.409872013274445, \"mod_max_depth\": 9}, {\"test_RMSE\": 49.89771044301331, \"train_RMSE\": 8.498537124938789, \"RMSE_diff\": 41.39917331807452, \"mod_max_depth\": 3}, {\"test_RMSE\": 55.462744113961264, \"train_RMSE\": 2.734313301502949, \"RMSE_diff\": 52.72843081245831, \"mod_max_depth\": 5}, {\"test_RMSE\": 45.96077061107357, \"train_RMSE\": 0.7897557076894919, \"RMSE_diff\": 45.171014903384076, \"mod_max_depth\": 7}, {\"test_RMSE\": 43.20626858745009, \"train_RMSE\": 0.1974462144015288, \"RMSE_diff\": 43.00882237304856, \"mod_max_depth\": 9}, {\"test_RMSE\": 55.44735715919694, \"train_RMSE\": 6.722110914912429, \"RMSE_diff\": 48.72524624428451, \"mod_max_depth\": 3}, {\"test_RMSE\": 55.89074765214684, \"train_RMSE\": 1.697052493902897, \"RMSE_diff\": 54.19369515824395, \"mod_max_depth\": 5}, {\"test_RMSE\": 46.992781356660274, \"train_RMSE\": 0.4002568202041505, \"RMSE_diff\": 46.592524536456125, \"mod_max_depth\": 7}, {\"test_RMSE\": 43.92645271333736, \"train_RMSE\": 0.0729207982109905, \"RMSE_diff\": 43.853531915126375, \"mod_max_depth\": 9}, {\"test_RMSE\": 35.70560880094571, \"train_RMSE\": 15.24282488522042, \"RMSE_diff\": 20.46278391572529, \"mod_max_depth\": 3}, {\"test_RMSE\": 37.29445289678224, \"train_RMSE\": 13.392437808187964, \"RMSE_diff\": 23.902015088594275, \"mod_max_depth\": 5}, {\"test_RMSE\": 38.91950430504996, \"train_RMSE\": 10.24091206254316, \"RMSE_diff\": 28.678592242506802, \"mod_max_depth\": 7}, {\"test_RMSE\": 41.68178570481863, \"train_RMSE\": 6.706030776368682, \"RMSE_diff\": 34.975754928449945, \"mod_max_depth\": 9}, {\"test_RMSE\": 37.97276573171551, \"train_RMSE\": 14.436136822081997, \"RMSE_diff\": 23.536628909633514, \"mod_max_depth\": 3}, {\"test_RMSE\": 39.73250234189891, \"train_RMSE\": 11.472537791874396, \"RMSE_diff\": 28.259964550024513, \"mod_max_depth\": 5}, {\"test_RMSE\": 39.61941309407715, \"train_RMSE\": 7.33508221624555, \"RMSE_diff\": 32.2843308778316, \"mod_max_depth\": 7}, {\"test_RMSE\": 40.22369207161424, \"train_RMSE\": 3.311298387044699, \"RMSE_diff\": 36.91239368456954, \"mod_max_depth\": 9}, {\"test_RMSE\": 42.859213541052576, \"train_RMSE\": 12.783750154907338, \"RMSE_diff\": 30.075463386145238, \"mod_max_depth\": 3}, {\"test_RMSE\": 45.239958138813535, \"train_RMSE\": 7.888277318339999, \"RMSE_diff\": 37.35168082047353, \"mod_max_depth\": 5}, {\"test_RMSE\": 44.26220916190682, \"train_RMSE\": 3.665759378515761, \"RMSE_diff\": 40.59644978339106, \"mod_max_depth\": 7}, {\"test_RMSE\": 43.41509310572607, \"train_RMSE\": 1.477666552019715, \"RMSE_diff\": 41.93742655370636, \"mod_max_depth\": 9}, {\"test_RMSE\": 45.024522564365405, \"train_RMSE\": 11.014726661863335, \"RMSE_diff\": 34.00979590250207, \"mod_max_depth\": 3}, {\"test_RMSE\": 51.320499213532216, \"train_RMSE\": 5.418690906585499, \"RMSE_diff\": 45.90180830694672, \"mod_max_depth\": 5}, {\"test_RMSE\": 43.74829444215074, \"train_RMSE\": 1.9885340837486092, \"RMSE_diff\": 41.759760358402126, \"mod_max_depth\": 7}, {\"test_RMSE\": 42.86169880565249, \"train_RMSE\": 0.7135977760515897, \"RMSE_diff\": 42.148101029600895, \"mod_max_depth\": 9}, {\"test_RMSE\": 51.33588786755062, \"train_RMSE\": 8.908911778725596, \"RMSE_diff\": 42.42697608882502, \"mod_max_depth\": 3}, {\"test_RMSE\": 57.30414494665901, \"train_RMSE\": 3.3048863575061467, \"RMSE_diff\": 53.99925858915286, \"mod_max_depth\": 5}, {\"test_RMSE\": 48.657383647733866, \"train_RMSE\": 1.042026754127889, \"RMSE_diff\": 47.61535689360598, \"mod_max_depth\": 7}, {\"test_RMSE\": 44.423387870540125, \"train_RMSE\": 0.2804006351190549, \"RMSE_diff\": 44.14298723542107, \"mod_max_depth\": 9}, {\"test_RMSE\": 56.08304596209091, \"train_RMSE\": 7.6066335865564465, \"RMSE_diff\": 48.47641237553446, \"mod_max_depth\": 3}, {\"test_RMSE\": 58.81992356005533, \"train_RMSE\": 2.3232427093336514, \"RMSE_diff\": 56.49668085072168, \"mod_max_depth\": 5}, {\"test_RMSE\": 44.12097224789523, \"train_RMSE\": 0.5979014824521369, \"RMSE_diff\": 43.523070765443094, \"mod_max_depth\": 7}, {\"test_RMSE\": 42.35487889466184, \"train_RMSE\": 0.1406107966197421, \"RMSE_diff\": 42.2142680980421, \"mod_max_depth\": 9}, {\"test_RMSE\": 61.914605270207446, \"train_RMSE\": 5.855324128525549, \"RMSE_diff\": 56.05928114168189, \"mod_max_depth\": 3}, {\"test_RMSE\": 58.96039346927974, \"train_RMSE\": 1.4147162761818353, \"RMSE_diff\": 57.5456771930979, \"mod_max_depth\": 5}, {\"test_RMSE\": 47.288264924605045, \"train_RMSE\": 0.2767244443766223, \"RMSE_diff\": 47.011540480228426, \"mod_max_depth\": 7}, {\"test_RMSE\": 44.17252080076839, \"train_RMSE\": 0.0400990076618962, \"RMSE_diff\": 44.132421793106495, \"mod_max_depth\": 9}, {\"test_RMSE\": 36.108067356649165, \"train_RMSE\": 15.138177641234485, \"RMSE_diff\": 20.96988971541468, \"mod_max_depth\": 3}, {\"test_RMSE\": 36.96402031397315, \"train_RMSE\": 13.274698598999844, \"RMSE_diff\": 23.689321714973307, \"mod_max_depth\": 5}, {\"test_RMSE\": 39.61468964518344, \"train_RMSE\": 9.680381590382408, \"RMSE_diff\": 29.93430805480103, \"mod_max_depth\": 7}, {\"test_RMSE\": 43.56944535044478, \"train_RMSE\": 5.667053396848618, \"RMSE_diff\": 37.902391953596165, \"mod_max_depth\": 9}, {\"test_RMSE\": 39.30111148121991, \"train_RMSE\": 14.356607142918543, \"RMSE_diff\": 24.94450433830137, \"mod_max_depth\": 3}, {\"test_RMSE\": 41.19289901724105, \"train_RMSE\": 10.843494371254126, \"RMSE_diff\": 30.349404645986922, \"mod_max_depth\": 5}, {\"test_RMSE\": 42.97156294276687, \"train_RMSE\": 6.469608670818438, \"RMSE_diff\": 36.501954271948435, \"mod_max_depth\": 7}, {\"test_RMSE\": 44.04951355564291, \"train_RMSE\": 2.989631784104331, \"RMSE_diff\": 41.05988177153858, \"mod_max_depth\": 9}, {\"test_RMSE\": 41.97596016230101, \"train_RMSE\": 12.461261002446774, \"RMSE_diff\": 29.51469915985423, \"mod_max_depth\": 3}, {\"test_RMSE\": 49.53805939219268, \"train_RMSE\": 7.387989399281962, \"RMSE_diff\": 42.150069992910716, \"mod_max_depth\": 5}, {\"test_RMSE\": 44.87620459341979, \"train_RMSE\": 3.272922865912332, \"RMSE_diff\": 41.60328172750746, \"mod_max_depth\": 7}, {\"test_RMSE\": 46.64218502586418, \"train_RMSE\": 1.2954522506773016, \"RMSE_diff\": 45.34673277518688, \"mod_max_depth\": 9}, {\"test_RMSE\": 45.26143073063649, \"train_RMSE\": 10.65120351593541, \"RMSE_diff\": 34.610227214701084, \"mod_max_depth\": 3}, {\"test_RMSE\": 58.39079536164876, \"train_RMSE\": 4.916567853844308, \"RMSE_diff\": 53.47422750780446, \"mod_max_depth\": 5}, {\"test_RMSE\": 47.22872883604619, \"train_RMSE\": 1.7048584208722195, \"RMSE_diff\": 45.52387041517397, \"mod_max_depth\": 7}, {\"test_RMSE\": 44.136239202997245, \"train_RMSE\": 0.6365822435665186, \"RMSE_diff\": 43.49965695943073, \"mod_max_depth\": 9}, {\"test_RMSE\": 50.602974238184345, \"train_RMSE\": 8.356134237685648, \"RMSE_diff\": 42.24684000049869, \"mod_max_depth\": 3}, {\"test_RMSE\": 62.02367671483597, \"train_RMSE\": 2.9241163420191176, \"RMSE_diff\": 59.09956037281685, \"mod_max_depth\": 5}, {\"test_RMSE\": 50.92242572027043, \"train_RMSE\": 0.8791638285520422, \"RMSE_diff\": 50.04326189171839, \"mod_max_depth\": 7}, {\"test_RMSE\": 46.60160640052594, \"train_RMSE\": 0.2181455338050191, \"RMSE_diff\": 46.38346086672092, \"mod_max_depth\": 9}, {\"test_RMSE\": 53.01432515279015, \"train_RMSE\": 7.000546697865994, \"RMSE_diff\": 46.01377845492416, \"mod_max_depth\": 3}, {\"test_RMSE\": 64.42691678582563, \"train_RMSE\": 2.12249709221665, \"RMSE_diff\": 62.30441969360898, \"mod_max_depth\": 5}, {\"test_RMSE\": 48.92755627312404, \"train_RMSE\": 0.5019550390915235, \"RMSE_diff\": 48.42560123403251, \"mod_max_depth\": 7}, {\"test_RMSE\": 46.73381631145846, \"train_RMSE\": 0.0922375885215072, \"RMSE_diff\": 46.641578722936956, \"mod_max_depth\": 9}, {\"test_RMSE\": 59.628465959989136, \"train_RMSE\": 5.298901478551345, \"RMSE_diff\": 54.32956448143779, \"mod_max_depth\": 3}, {\"test_RMSE\": 63.17103408245477, \"train_RMSE\": 1.2392468604278224, \"RMSE_diff\": 61.93178722202695, \"mod_max_depth\": 5}, {\"test_RMSE\": 49.62494287751727, \"train_RMSE\": 0.2082736470548865, \"RMSE_diff\": 49.41666923046238, \"mod_max_depth\": 7}, {\"test_RMSE\": 43.79612701810125, \"train_RMSE\": 0.0205895831809294, \"RMSE_diff\": 43.775537434920324, \"mod_max_depth\": 9}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-d570cdaef7a8431d9e30d43918f7e7e1.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-d570cdaef7a8431d9e30d43918f7e7e1.vega-embed details,\n",
       "  #altair-viz-d570cdaef7a8431d9e30d43918f7e7e1.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-d570cdaef7a8431d9e30d43918f7e7e1\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-d570cdaef7a8431d9e30d43918f7e7e1\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-d570cdaef7a8431d9e30d43918f7e7e1\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-f7b801aeb96435cac97052723da88808\"}, \"mark\": {\"type\": \"point\"}, \"encoding\": {\"color\": {\"field\": \"mod_n_estimators\", \"type\": \"nominal\"}, \"shape\": {\"field\": \"mod_n_estimators\", \"type\": \"nominal\"}, \"x\": {\"field\": \"test_RMSE\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"field\": \"RMSE_diff\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-f7b801aeb96435cac97052723da88808\": [{\"test_RMSE\": 42.94889308864739, \"train_RMSE\": 38.45820271910945, \"RMSE_diff\": 4.490690369537937, \"mod_n_estimators\": 10}, {\"test_RMSE\": 42.64469343044005, \"train_RMSE\": 38.30207562066866, \"RMSE_diff\": 4.34261780977139, \"mod_n_estimators\": 10}, {\"test_RMSE\": 42.51578543771746, \"train_RMSE\": 38.20426944923785, \"RMSE_diff\": 4.311515988479613, \"mod_n_estimators\": 10}, {\"test_RMSE\": 42.45577863013835, \"train_RMSE\": 38.08341005294838, \"RMSE_diff\": 4.372368577189967, \"mod_n_estimators\": 10}, {\"test_RMSE\": 39.388162630148784, \"train_RMSE\": 35.60166808377512, \"RMSE_diff\": 3.7864945463736674, \"mod_n_estimators\": 20}, {\"test_RMSE\": 38.76730816041604, \"train_RMSE\": 35.300599663541306, \"RMSE_diff\": 3.4667084968747375, \"mod_n_estimators\": 20}, {\"test_RMSE\": 38.518095088631, \"train_RMSE\": 35.10667506209064, \"RMSE_diff\": 3.4114200265403625, \"mod_n_estimators\": 20}, {\"test_RMSE\": 38.38501013773397, \"train_RMSE\": 34.86105736687048, \"RMSE_diff\": 3.523952770863488, \"mod_n_estimators\": 20}, {\"test_RMSE\": 32.033405240345104, \"train_RMSE\": 28.828551561632462, \"RMSE_diff\": 3.2048536787126416, \"mod_n_estimators\": 50}, {\"test_RMSE\": 31.07372668528954, \"train_RMSE\": 28.17709153440521, \"RMSE_diff\": 2.896635150884329, \"mod_n_estimators\": 50}, {\"test_RMSE\": 30.49902590170546, \"train_RMSE\": 27.666355692408317, \"RMSE_diff\": 2.8326702092971416, \"mod_n_estimators\": 50}, {\"test_RMSE\": 30.567545882140543, \"train_RMSE\": 27.02660969184937, \"RMSE_diff\": 3.5409361902911733, \"mod_n_estimators\": 50}, {\"test_RMSE\": 27.942005868729733, \"train_RMSE\": 21.940636342392484, \"RMSE_diff\": 6.00136952633725, \"mod_n_estimators\": 100}, {\"test_RMSE\": 27.413535836268785, \"train_RMSE\": 20.97827719864343, \"RMSE_diff\": 6.435258637625356, \"mod_n_estimators\": 100}, {\"test_RMSE\": 27.32156158272152, \"train_RMSE\": 19.912369004442954, \"RMSE_diff\": 7.409192578278567, \"mod_n_estimators\": 100}, {\"test_RMSE\": 27.841820896907542, \"train_RMSE\": 18.536480107537205, \"RMSE_diff\": 9.305340789370337, \"mod_n_estimators\": 100}, {\"test_RMSE\": 30.214896118356005, \"train_RMSE\": 16.837793354547735, \"RMSE_diff\": 13.37710276380827, \"mod_n_estimators\": 200}, {\"test_RMSE\": 30.92978967025571, \"train_RMSE\": 15.611314364625043, \"RMSE_diff\": 15.318475305630665, \"mod_n_estimators\": 200}, {\"test_RMSE\": 32.174774323482545, \"train_RMSE\": 13.651546249637349, \"RMSE_diff\": 18.523228073845196, \"mod_n_estimators\": 200}, {\"test_RMSE\": 32.64949289208776, \"train_RMSE\": 10.98725334672805, \"RMSE_diff\": 21.662239545359707, \"mod_n_estimators\": 200}, {\"test_RMSE\": 32.61721456565814, \"train_RMSE\": 15.666793549545613, \"RMSE_diff\": 16.950421016112525, \"mod_n_estimators\": 300}, {\"test_RMSE\": 34.26979279509076, \"train_RMSE\": 14.027706293829318, \"RMSE_diff\": 20.24208650126144, \"mod_n_estimators\": 300}, {\"test_RMSE\": 35.61341048124254, \"train_RMSE\": 11.457755508794378, \"RMSE_diff\": 24.15565497244816, \"mod_n_estimators\": 300}, {\"test_RMSE\": 36.18102641198628, \"train_RMSE\": 8.390611715828653, \"RMSE_diff\": 27.790414696157626, \"mod_n_estimators\": 300}, {\"test_RMSE\": 34.74881353169465, \"train_RMSE\": 15.004334530706306, \"RMSE_diff\": 19.744479000988346, \"mod_n_estimators\": 500}, {\"test_RMSE\": 37.27706825986567, \"train_RMSE\": 12.740248187605244, \"RMSE_diff\": 24.536820072260426, \"mod_n_estimators\": 500}, {\"test_RMSE\": 38.16578691430095, \"train_RMSE\": 9.255498207535268, \"RMSE_diff\": 28.910288706765684, \"mod_n_estimators\": 500}, {\"test_RMSE\": 38.50710735912418, \"train_RMSE\": 5.926443864668889, \"RMSE_diff\": 32.58066349445529, \"mod_n_estimators\": 500}, {\"test_RMSE\": 31.94412161412375, \"train_RMSE\": 28.63239595912083, \"RMSE_diff\": 3.311725655002917, \"mod_n_estimators\": 10}, {\"test_RMSE\": 30.784299843149583, \"train_RMSE\": 27.98627273270431, \"RMSE_diff\": 2.798027110445272, \"mod_n_estimators\": 10}, {\"test_RMSE\": 30.27820940950041, \"train_RMSE\": 27.467333180683525, \"RMSE_diff\": 2.810876228816884, \"mod_n_estimators\": 10}, {\"test_RMSE\": 30.489072119085197, \"train_RMSE\": 26.804479673825544, \"RMSE_diff\": 3.6845924452596535, \"mod_n_estimators\": 10}, {\"test_RMSE\": 27.97262824873041, \"train_RMSE\": 21.755008272537584, \"RMSE_diff\": 6.217619976192825, \"mod_n_estimators\": 20}, {\"test_RMSE\": 27.49182979016832, \"train_RMSE\": 20.78617760646744, \"RMSE_diff\": 6.705652183700881, \"mod_n_estimators\": 20}, {\"test_RMSE\": 27.197247119915783, \"train_RMSE\": 19.68532888723905, \"RMSE_diff\": 7.511918232676734, \"mod_n_estimators\": 20}, {\"test_RMSE\": 28.22147527869969, \"train_RMSE\": 18.259883725670758, \"RMSE_diff\": 9.961591553028931, \"mod_n_estimators\": 20}, {\"test_RMSE\": 31.57783587686829, \"train_RMSE\": 16.044330363712326, \"RMSE_diff\": 15.533505513155962, \"mod_n_estimators\": 50}, {\"test_RMSE\": 32.86882370146414, \"train_RMSE\": 14.560205259585135, \"RMSE_diff\": 18.308618441879002, \"mod_n_estimators\": 50}, {\"test_RMSE\": 34.14911099498624, \"train_RMSE\": 12.355357553028638, \"RMSE_diff\": 21.7937534419576, \"mod_n_estimators\": 50}, {\"test_RMSE\": 35.16813376125395, \"train_RMSE\": 9.441080525151284, \"RMSE_diff\": 25.727053236102662, \"mod_n_estimators\": 50}, {\"test_RMSE\": 34.82117565108924, \"train_RMSE\": 15.003041565500522, \"RMSE_diff\": 19.818134085588717, \"mod_n_estimators\": 100}, {\"test_RMSE\": 36.90907066405634, \"train_RMSE\": 12.71745597676729, \"RMSE_diff\": 24.191614687289047, \"mod_n_estimators\": 100}, {\"test_RMSE\": 38.182546752483816, \"train_RMSE\": 9.213801493746343, \"RMSE_diff\": 28.96874525873747, \"mod_n_estimators\": 100}, {\"test_RMSE\": 38.867804513310325, \"train_RMSE\": 5.906621797549837, \"RMSE_diff\": 32.961182715760486, \"mod_n_estimators\": 100}, {\"test_RMSE\": 36.88023587126432, \"train_RMSE\": 14.13884939123692, \"RMSE_diff\": 22.741386480027398, \"mod_n_estimators\": 200}, {\"test_RMSE\": 39.01305653323575, \"train_RMSE\": 10.635668589161211, \"RMSE_diff\": 28.377387944074535, \"mod_n_estimators\": 200}, {\"test_RMSE\": 39.67701794745211, \"train_RMSE\": 6.348310859186067, \"RMSE_diff\": 33.32870708826604, \"mod_n_estimators\": 200}, {\"test_RMSE\": 40.47469469014997, \"train_RMSE\": 2.700688556189046, \"RMSE_diff\": 37.774006133960924, \"mod_n_estimators\": 200}, {\"test_RMSE\": 38.46989154720325, \"train_RMSE\": 13.381419344321806, \"RMSE_diff\": 25.08847220288144, \"mod_n_estimators\": 300}, {\"test_RMSE\": 40.959442704731806, \"train_RMSE\": 9.098649042141194, \"RMSE_diff\": 31.860793662590613, \"mod_n_estimators\": 300}, {\"test_RMSE\": 41.48325091485719, \"train_RMSE\": 4.667050612951319, \"RMSE_diff\": 36.816200301905866, \"mod_n_estimators\": 300}, {\"test_RMSE\": 40.909241082384256, \"train_RMSE\": 1.6686898356653677, \"RMSE_diff\": 39.24055124671889, \"mod_n_estimators\": 300}, {\"test_RMSE\": 40.99841120590103, \"train_RMSE\": 12.242078079410328, \"RMSE_diff\": 28.756333126490702, \"mod_n_estimators\": 500}, {\"test_RMSE\": 44.28541881457093, \"train_RMSE\": 7.035742117555873, \"RMSE_diff\": 37.24967669701506, \"mod_n_estimators\": 500}, {\"test_RMSE\": 42.90926694671622, \"train_RMSE\": 2.87541530617097, \"RMSE_diff\": 40.03385164054525, \"mod_n_estimators\": 500}, {\"test_RMSE\": 41.60493851847616, \"train_RMSE\": 0.8414117289088833, \"RMSE_diff\": 40.76352678956728, \"mod_n_estimators\": 500}, {\"test_RMSE\": 27.892715274653337, \"train_RMSE\": 21.557352707006416, \"RMSE_diff\": 6.335362567646921, \"mod_n_estimators\": 10}, {\"test_RMSE\": 27.483473617011573, \"train_RMSE\": 20.540194885603352, \"RMSE_diff\": 6.9432787314082205, \"mod_n_estimators\": 10}, {\"test_RMSE\": 27.49718755633946, \"train_RMSE\": 19.424669187796606, \"RMSE_diff\": 8.072518368542852, \"mod_n_estimators\": 10}, {\"test_RMSE\": 27.92144131075555, \"train_RMSE\": 18.023806661792328, \"RMSE_diff\": 9.897634648963223, \"mod_n_estimators\": 10}, {\"test_RMSE\": 30.45551883497358, \"train_RMSE\": 16.702052726479486, \"RMSE_diff\": 13.753466108494095, \"mod_n_estimators\": 20}, {\"test_RMSE\": 31.460339890938965, \"train_RMSE\": 15.398080291006483, \"RMSE_diff\": 16.06225959993248, \"mod_n_estimators\": 20}, {\"test_RMSE\": 32.240726219261525, \"train_RMSE\": 13.352085315015623, \"RMSE_diff\": 18.888640904245904, \"mod_n_estimators\": 20}, {\"test_RMSE\": 33.000359569028554, \"train_RMSE\": 10.703173312610298, \"RMSE_diff\": 22.297186256418257, \"mod_n_estimators\": 20}, {\"test_RMSE\": 34.93820433675725, \"train_RMSE\": 15.044248216088013, \"RMSE_diff\": 19.893956120669237, \"mod_n_estimators\": 50}, {\"test_RMSE\": 37.24834507656719, \"train_RMSE\": 12.756372250923972, \"RMSE_diff\": 24.491972825643217, \"mod_n_estimators\": 50}, {\"test_RMSE\": 38.834421742776975, \"train_RMSE\": 9.109152327790524, \"RMSE_diff\": 29.72526941498645, \"mod_n_estimators\": 50}, {\"test_RMSE\": 38.52699794081104, \"train_RMSE\": 5.868757254534083, \"RMSE_diff\": 32.65824068627696, \"mod_n_estimators\": 50}, {\"test_RMSE\": 36.77430551569913, \"train_RMSE\": 14.120902539045094, \"RMSE_diff\": 22.65340297665404, \"mod_n_estimators\": 100}, {\"test_RMSE\": 39.44063965553556, \"train_RMSE\": 10.63115662269686, \"RMSE_diff\": 28.809483032838703, \"mod_n_estimators\": 100}, {\"test_RMSE\": 40.86504432665169, \"train_RMSE\": 6.263062275163999, \"RMSE_diff\": 34.601982051487695, \"mod_n_estimators\": 100}, {\"test_RMSE\": 40.19043723384565, \"train_RMSE\": 2.8211922271739405, \"RMSE_diff\": 37.36924500667171, \"mod_n_estimators\": 100}, {\"test_RMSE\": 40.3238567683295, \"train_RMSE\": 12.79625641208029, \"RMSE_diff\": 27.52760035624921, \"mod_n_estimators\": 200}, {\"test_RMSE\": 41.91332338419736, \"train_RMSE\": 8.008209424452748, \"RMSE_diff\": 33.90511395974461, \"mod_n_estimators\": 200}, {\"test_RMSE\": 42.73016789382323, \"train_RMSE\": 3.4868711717223304, \"RMSE_diff\": 39.2432967221009, \"mod_n_estimators\": 200}, {\"test_RMSE\": 41.27882596345084, \"train_RMSE\": 1.188423662311766, \"RMSE_diff\": 40.09040230113908, \"mod_n_estimators\": 200}, {\"test_RMSE\": 42.67551615254095, \"train_RMSE\": 11.66467390136136, \"RMSE_diff\": 31.01084225117959, \"mod_n_estimators\": 300}, {\"test_RMSE\": 44.094895960238894, \"train_RMSE\": 6.240116119111558, \"RMSE_diff\": 37.85477984112734, \"mod_n_estimators\": 300}, {\"test_RMSE\": 44.33886949277768, \"train_RMSE\": 2.3110778473607767, \"RMSE_diff\": 42.027791645416904, \"mod_n_estimators\": 300}, {\"test_RMSE\": 41.08217454560869, \"train_RMSE\": 0.7073208700508276, \"RMSE_diff\": 40.37485367555786, \"mod_n_estimators\": 300}, {\"test_RMSE\": 47.18387520380126, \"train_RMSE\": 10.195414232789387, \"RMSE_diff\": 36.98846097101187, \"mod_n_estimators\": 500}, {\"test_RMSE\": 46.95272892694504, \"train_RMSE\": 4.385173996074999, \"RMSE_diff\": 42.567554930870045, \"mod_n_estimators\": 500}, {\"test_RMSE\": 45.63597300016762, \"train_RMSE\": 1.3207119241854892, \"RMSE_diff\": 44.31526107598213, \"mod_n_estimators\": 500}, {\"test_RMSE\": 41.82824622635642, \"train_RMSE\": 0.3334901487803306, \"RMSE_diff\": 41.49475607757609, \"mod_n_estimators\": 500}, {\"test_RMSE\": 31.01004769616233, \"train_RMSE\": 16.580801523491964, \"RMSE_diff\": 14.429246172670368, \"mod_n_estimators\": 10}, {\"test_RMSE\": 32.07235305600344, \"train_RMSE\": 15.294029203238988, \"RMSE_diff\": 16.778323852764455, \"mod_n_estimators\": 10}, {\"test_RMSE\": 33.65378502687985, \"train_RMSE\": 13.396511777971488, \"RMSE_diff\": 20.257273248908362, \"mod_n_estimators\": 10}, {\"test_RMSE\": 33.308621944436844, \"train_RMSE\": 10.522724287766412, \"RMSE_diff\": 22.785897656670432, \"mod_n_estimators\": 10}, {\"test_RMSE\": 34.43568091079783, \"train_RMSE\": 15.291399840473057, \"RMSE_diff\": 19.144281070324773, \"mod_n_estimators\": 20}, {\"test_RMSE\": 37.151380611911655, \"train_RMSE\": 13.110675282133329, \"RMSE_diff\": 24.040705329778326, \"mod_n_estimators\": 20}, {\"test_RMSE\": 39.6055859208646, \"train_RMSE\": 9.856561374494342, \"RMSE_diff\": 29.749024546370258, \"mod_n_estimators\": 20}, {\"test_RMSE\": 37.72121235609684, \"train_RMSE\": 6.858763095589984, \"RMSE_diff\": 30.862449260506857, \"mod_n_estimators\": 20}, {\"test_RMSE\": 36.85677137836302, \"train_RMSE\": 14.240754836971057, \"RMSE_diff\": 22.616016541391964, \"mod_n_estimators\": 50}, {\"test_RMSE\": 38.86244617285552, \"train_RMSE\": 10.50279923643236, \"RMSE_diff\": 28.35964693642316, \"mod_n_estimators\": 50}, {\"test_RMSE\": 42.01923120870335, \"train_RMSE\": 6.094634297582394, \"RMSE_diff\": 35.92459691112096, \"mod_n_estimators\": 50}, {\"test_RMSE\": 39.366077402841725, \"train_RMSE\": 2.981819428531353, \"RMSE_diff\": 36.38425797431037, \"mod_n_estimators\": 50}, {\"test_RMSE\": 40.15788632289421, \"train_RMSE\": 12.66313517773856, \"RMSE_diff\": 27.494751145155647, \"mod_n_estimators\": 100}, {\"test_RMSE\": 43.37128871628013, \"train_RMSE\": 7.612202247127737, \"RMSE_diff\": 35.75908646915239, \"mod_n_estimators\": 100}, {\"test_RMSE\": 45.25921674102347, \"train_RMSE\": 3.370407113952429, \"RMSE_diff\": 41.88880962707104, \"mod_n_estimators\": 100}, {\"test_RMSE\": 41.17779382834484, \"train_RMSE\": 1.3578186894389876, \"RMSE_diff\": 39.81997513890585, \"mod_n_estimators\": 100}, {\"test_RMSE\": 44.37727362999775, \"train_RMSE\": 10.89340668075934, \"RMSE_diff\": 33.48386694923841, \"mod_n_estimators\": 200}, {\"test_RMSE\": 46.12382571739624, \"train_RMSE\": 4.907654047181151, \"RMSE_diff\": 41.21617167021508, \"mod_n_estimators\": 200}, {\"test_RMSE\": 45.40584663152949, \"train_RMSE\": 1.7235185328686673, \"RMSE_diff\": 43.682328098660825, \"mod_n_estimators\": 200}, {\"test_RMSE\": 40.633899944626, \"train_RMSE\": 0.5481182330433138, \"RMSE_diff\": 40.08578171158269, \"mod_n_estimators\": 200}, {\"test_RMSE\": 48.01411550604022, \"train_RMSE\": 9.762611514691857, \"RMSE_diff\": 38.251503991348365, \"mod_n_estimators\": 300}, {\"test_RMSE\": 47.7671572189292, \"train_RMSE\": 3.563831358695788, \"RMSE_diff\": 44.20332586023341, \"mod_n_estimators\": 300}, {\"test_RMSE\": 47.66196589848863, \"train_RMSE\": 1.1096766527289912, \"RMSE_diff\": 46.55228924575964, \"mod_n_estimators\": 300}, {\"test_RMSE\": 43.136191206020655, \"train_RMSE\": 0.313918898892976, \"RMSE_diff\": 42.822272307127676, \"mod_n_estimators\": 300}, {\"test_RMSE\": 52.99164314299181, \"train_RMSE\": 8.071040225133169, \"RMSE_diff\": 44.920602917858645, \"mod_n_estimators\": 500}, {\"test_RMSE\": 49.53768660677706, \"train_RMSE\": 2.30108146751227, \"RMSE_diff\": 47.23660513926479, \"mod_n_estimators\": 500}, {\"test_RMSE\": 47.87584679267601, \"train_RMSE\": 0.6031784800011867, \"RMSE_diff\": 47.272668312674824, \"mod_n_estimators\": 500}, {\"test_RMSE\": 40.79760519033674, \"train_RMSE\": 0.1408909343802732, \"RMSE_diff\": 40.656714255956466, \"mod_n_estimators\": 500}, {\"test_RMSE\": 33.76078067091748, \"train_RMSE\": 15.710244547874508, \"RMSE_diff\": 18.050536123042967, \"mod_n_estimators\": 10}, {\"test_RMSE\": 34.947736317863075, \"train_RMSE\": 14.00235015410344, \"RMSE_diff\": 20.945386163759636, \"mod_n_estimators\": 10}, {\"test_RMSE\": 36.8154202616199, \"train_RMSE\": 11.276927168244676, \"RMSE_diff\": 25.538493093375223, \"mod_n_estimators\": 10}, {\"test_RMSE\": 36.97654632975085, \"train_RMSE\": 8.042900742162198, \"RMSE_diff\": 28.933645587588657, \"mod_n_estimators\": 10}, {\"test_RMSE\": 35.662496588767674, \"train_RMSE\": 14.966115749243713, \"RMSE_diff\": 20.69638083952396, \"mod_n_estimators\": 20}, {\"test_RMSE\": 39.21740387192585, \"train_RMSE\": 12.346149745105688, \"RMSE_diff\": 26.871254126820165, \"mod_n_estimators\": 20}, {\"test_RMSE\": 39.35887864323041, \"train_RMSE\": 8.543514971500707, \"RMSE_diff\": 30.815363671729706, \"mod_n_estimators\": 20}, {\"test_RMSE\": 40.28661298169107, \"train_RMSE\": 4.763818763674365, \"RMSE_diff\": 35.522794218016706, \"mod_n_estimators\": 20}, {\"test_RMSE\": 38.45049076916623, \"train_RMSE\": 13.550314402823716, \"RMSE_diff\": 24.900176366342514, \"mod_n_estimators\": 50}, {\"test_RMSE\": 42.88837244619527, \"train_RMSE\": 8.979068194191875, \"RMSE_diff\": 33.909304252003395, \"mod_n_estimators\": 50}, {\"test_RMSE\": 42.32978355233755, \"train_RMSE\": 4.51375601490211, \"RMSE_diff\": 37.816027537435446, \"mod_n_estimators\": 50}, {\"test_RMSE\": 39.992318916914776, \"train_RMSE\": 1.84571316715668, \"RMSE_diff\": 38.146605749758095, \"mod_n_estimators\": 50}, {\"test_RMSE\": 42.05497696362241, \"train_RMSE\": 11.855999867588087, \"RMSE_diff\": 30.19897709603432, \"mod_n_estimators\": 100}, {\"test_RMSE\": 47.40338487539671, \"train_RMSE\": 6.258498366428537, \"RMSE_diff\": 41.14488650896817, \"mod_n_estimators\": 100}, {\"test_RMSE\": 44.65307604428534, \"train_RMSE\": 2.485606887770064, \"RMSE_diff\": 42.16746915651528, \"mod_n_estimators\": 100}, {\"test_RMSE\": 40.37186167035844, \"train_RMSE\": 0.8524245026740974, \"RMSE_diff\": 39.519437167684345, \"mod_n_estimators\": 100}, {\"test_RMSE\": 46.28182809890174, \"train_RMSE\": 9.73398988858146, \"RMSE_diff\": 36.54783821032028, \"mod_n_estimators\": 200}, {\"test_RMSE\": 53.0276466450656, \"train_RMSE\": 3.728239864296169, \"RMSE_diff\": 49.29940678076943, \"mod_n_estimators\": 200}, {\"test_RMSE\": 45.24524623433504, \"train_RMSE\": 1.2486780990471569, \"RMSE_diff\": 43.99656813528789, \"mod_n_estimators\": 200}, {\"test_RMSE\": 41.789996798812695, \"train_RMSE\": 0.3801247855382505, \"RMSE_diff\": 41.409872013274445, \"mod_n_estimators\": 200}, {\"test_RMSE\": 49.89771044301331, \"train_RMSE\": 8.498537124938789, \"RMSE_diff\": 41.39917331807452, \"mod_n_estimators\": 300}, {\"test_RMSE\": 55.462744113961264, \"train_RMSE\": 2.734313301502949, \"RMSE_diff\": 52.72843081245831, \"mod_n_estimators\": 300}, {\"test_RMSE\": 45.96077061107357, \"train_RMSE\": 0.7897557076894919, \"RMSE_diff\": 45.171014903384076, \"mod_n_estimators\": 300}, {\"test_RMSE\": 43.20626858745009, \"train_RMSE\": 0.1974462144015288, \"RMSE_diff\": 43.00882237304856, \"mod_n_estimators\": 300}, {\"test_RMSE\": 55.44735715919694, \"train_RMSE\": 6.722110914912429, \"RMSE_diff\": 48.72524624428451, \"mod_n_estimators\": 500}, {\"test_RMSE\": 55.89074765214684, \"train_RMSE\": 1.697052493902897, \"RMSE_diff\": 54.19369515824395, \"mod_n_estimators\": 500}, {\"test_RMSE\": 46.992781356660274, \"train_RMSE\": 0.4002568202041505, \"RMSE_diff\": 46.592524536456125, \"mod_n_estimators\": 500}, {\"test_RMSE\": 43.92645271333736, \"train_RMSE\": 0.0729207982109905, \"RMSE_diff\": 43.853531915126375, \"mod_n_estimators\": 500}, {\"test_RMSE\": 35.70560880094571, \"train_RMSE\": 15.24282488522042, \"RMSE_diff\": 20.46278391572529, \"mod_n_estimators\": 10}, {\"test_RMSE\": 37.29445289678224, \"train_RMSE\": 13.392437808187964, \"RMSE_diff\": 23.902015088594275, \"mod_n_estimators\": 10}, {\"test_RMSE\": 38.91950430504996, \"train_RMSE\": 10.24091206254316, \"RMSE_diff\": 28.678592242506802, \"mod_n_estimators\": 10}, {\"test_RMSE\": 41.68178570481863, \"train_RMSE\": 6.706030776368682, \"RMSE_diff\": 34.975754928449945, \"mod_n_estimators\": 10}, {\"test_RMSE\": 37.97276573171551, \"train_RMSE\": 14.436136822081997, \"RMSE_diff\": 23.536628909633514, \"mod_n_estimators\": 20}, {\"test_RMSE\": 39.73250234189891, \"train_RMSE\": 11.472537791874396, \"RMSE_diff\": 28.259964550024513, \"mod_n_estimators\": 20}, {\"test_RMSE\": 39.61941309407715, \"train_RMSE\": 7.33508221624555, \"RMSE_diff\": 32.2843308778316, \"mod_n_estimators\": 20}, {\"test_RMSE\": 40.22369207161424, \"train_RMSE\": 3.311298387044699, \"RMSE_diff\": 36.91239368456954, \"mod_n_estimators\": 20}, {\"test_RMSE\": 42.859213541052576, \"train_RMSE\": 12.783750154907338, \"RMSE_diff\": 30.075463386145238, \"mod_n_estimators\": 50}, {\"test_RMSE\": 45.239958138813535, \"train_RMSE\": 7.888277318339999, \"RMSE_diff\": 37.35168082047353, \"mod_n_estimators\": 50}, {\"test_RMSE\": 44.26220916190682, \"train_RMSE\": 3.665759378515761, \"RMSE_diff\": 40.59644978339106, \"mod_n_estimators\": 50}, {\"test_RMSE\": 43.41509310572607, \"train_RMSE\": 1.477666552019715, \"RMSE_diff\": 41.93742655370636, \"mod_n_estimators\": 50}, {\"test_RMSE\": 45.024522564365405, \"train_RMSE\": 11.014726661863335, \"RMSE_diff\": 34.00979590250207, \"mod_n_estimators\": 100}, {\"test_RMSE\": 51.320499213532216, \"train_RMSE\": 5.418690906585499, \"RMSE_diff\": 45.90180830694672, \"mod_n_estimators\": 100}, {\"test_RMSE\": 43.74829444215074, \"train_RMSE\": 1.9885340837486092, \"RMSE_diff\": 41.759760358402126, \"mod_n_estimators\": 100}, {\"test_RMSE\": 42.86169880565249, \"train_RMSE\": 0.7135977760515897, \"RMSE_diff\": 42.148101029600895, \"mod_n_estimators\": 100}, {\"test_RMSE\": 51.33588786755062, \"train_RMSE\": 8.908911778725596, \"RMSE_diff\": 42.42697608882502, \"mod_n_estimators\": 200}, {\"test_RMSE\": 57.30414494665901, \"train_RMSE\": 3.3048863575061467, \"RMSE_diff\": 53.99925858915286, \"mod_n_estimators\": 200}, {\"test_RMSE\": 48.657383647733866, \"train_RMSE\": 1.042026754127889, \"RMSE_diff\": 47.61535689360598, \"mod_n_estimators\": 200}, {\"test_RMSE\": 44.423387870540125, \"train_RMSE\": 0.2804006351190549, \"RMSE_diff\": 44.14298723542107, \"mod_n_estimators\": 200}, {\"test_RMSE\": 56.08304596209091, \"train_RMSE\": 7.6066335865564465, \"RMSE_diff\": 48.47641237553446, \"mod_n_estimators\": 300}, {\"test_RMSE\": 58.81992356005533, \"train_RMSE\": 2.3232427093336514, \"RMSE_diff\": 56.49668085072168, \"mod_n_estimators\": 300}, {\"test_RMSE\": 44.12097224789523, \"train_RMSE\": 0.5979014824521369, \"RMSE_diff\": 43.523070765443094, \"mod_n_estimators\": 300}, {\"test_RMSE\": 42.35487889466184, \"train_RMSE\": 0.1406107966197421, \"RMSE_diff\": 42.2142680980421, \"mod_n_estimators\": 300}, {\"test_RMSE\": 61.914605270207446, \"train_RMSE\": 5.855324128525549, \"RMSE_diff\": 56.05928114168189, \"mod_n_estimators\": 500}, {\"test_RMSE\": 58.96039346927974, \"train_RMSE\": 1.4147162761818353, \"RMSE_diff\": 57.5456771930979, \"mod_n_estimators\": 500}, {\"test_RMSE\": 47.288264924605045, \"train_RMSE\": 0.2767244443766223, \"RMSE_diff\": 47.011540480228426, \"mod_n_estimators\": 500}, {\"test_RMSE\": 44.17252080076839, \"train_RMSE\": 0.0400990076618962, \"RMSE_diff\": 44.132421793106495, \"mod_n_estimators\": 500}, {\"test_RMSE\": 36.108067356649165, \"train_RMSE\": 15.138177641234485, \"RMSE_diff\": 20.96988971541468, \"mod_n_estimators\": 10}, {\"test_RMSE\": 36.96402031397315, \"train_RMSE\": 13.274698598999844, \"RMSE_diff\": 23.689321714973307, \"mod_n_estimators\": 10}, {\"test_RMSE\": 39.61468964518344, \"train_RMSE\": 9.680381590382408, \"RMSE_diff\": 29.93430805480103, \"mod_n_estimators\": 10}, {\"test_RMSE\": 43.56944535044478, \"train_RMSE\": 5.667053396848618, \"RMSE_diff\": 37.902391953596165, \"mod_n_estimators\": 10}, {\"test_RMSE\": 39.30111148121991, \"train_RMSE\": 14.356607142918543, \"RMSE_diff\": 24.94450433830137, \"mod_n_estimators\": 20}, {\"test_RMSE\": 41.19289901724105, \"train_RMSE\": 10.843494371254126, \"RMSE_diff\": 30.349404645986922, \"mod_n_estimators\": 20}, {\"test_RMSE\": 42.97156294276687, \"train_RMSE\": 6.469608670818438, \"RMSE_diff\": 36.501954271948435, \"mod_n_estimators\": 20}, {\"test_RMSE\": 44.04951355564291, \"train_RMSE\": 2.989631784104331, \"RMSE_diff\": 41.05988177153858, \"mod_n_estimators\": 20}, {\"test_RMSE\": 41.97596016230101, \"train_RMSE\": 12.461261002446774, \"RMSE_diff\": 29.51469915985423, \"mod_n_estimators\": 50}, {\"test_RMSE\": 49.53805939219268, \"train_RMSE\": 7.387989399281962, \"RMSE_diff\": 42.150069992910716, \"mod_n_estimators\": 50}, {\"test_RMSE\": 44.87620459341979, \"train_RMSE\": 3.272922865912332, \"RMSE_diff\": 41.60328172750746, \"mod_n_estimators\": 50}, {\"test_RMSE\": 46.64218502586418, \"train_RMSE\": 1.2954522506773016, \"RMSE_diff\": 45.34673277518688, \"mod_n_estimators\": 50}, {\"test_RMSE\": 45.26143073063649, \"train_RMSE\": 10.65120351593541, \"RMSE_diff\": 34.610227214701084, \"mod_n_estimators\": 100}, {\"test_RMSE\": 58.39079536164876, \"train_RMSE\": 4.916567853844308, \"RMSE_diff\": 53.47422750780446, \"mod_n_estimators\": 100}, {\"test_RMSE\": 47.22872883604619, \"train_RMSE\": 1.7048584208722195, \"RMSE_diff\": 45.52387041517397, \"mod_n_estimators\": 100}, {\"test_RMSE\": 44.136239202997245, \"train_RMSE\": 0.6365822435665186, \"RMSE_diff\": 43.49965695943073, \"mod_n_estimators\": 100}, {\"test_RMSE\": 50.602974238184345, \"train_RMSE\": 8.356134237685648, \"RMSE_diff\": 42.24684000049869, \"mod_n_estimators\": 200}, {\"test_RMSE\": 62.02367671483597, \"train_RMSE\": 2.9241163420191176, \"RMSE_diff\": 59.09956037281685, \"mod_n_estimators\": 200}, {\"test_RMSE\": 50.92242572027043, \"train_RMSE\": 0.8791638285520422, \"RMSE_diff\": 50.04326189171839, \"mod_n_estimators\": 200}, {\"test_RMSE\": 46.60160640052594, \"train_RMSE\": 0.2181455338050191, \"RMSE_diff\": 46.38346086672092, \"mod_n_estimators\": 200}, {\"test_RMSE\": 53.01432515279015, \"train_RMSE\": 7.000546697865994, \"RMSE_diff\": 46.01377845492416, \"mod_n_estimators\": 300}, {\"test_RMSE\": 64.42691678582563, \"train_RMSE\": 2.12249709221665, \"RMSE_diff\": 62.30441969360898, \"mod_n_estimators\": 300}, {\"test_RMSE\": 48.92755627312404, \"train_RMSE\": 0.5019550390915235, \"RMSE_diff\": 48.42560123403251, \"mod_n_estimators\": 300}, {\"test_RMSE\": 46.73381631145846, \"train_RMSE\": 0.0922375885215072, \"RMSE_diff\": 46.641578722936956, \"mod_n_estimators\": 300}, {\"test_RMSE\": 59.628465959989136, \"train_RMSE\": 5.298901478551345, \"RMSE_diff\": 54.32956448143779, \"mod_n_estimators\": 500}, {\"test_RMSE\": 63.17103408245477, \"train_RMSE\": 1.2392468604278224, \"RMSE_diff\": 61.93178722202695, \"mod_n_estimators\": 500}, {\"test_RMSE\": 49.62494287751727, \"train_RMSE\": 0.2082736470548865, \"RMSE_diff\": 49.41666923046238, \"mod_n_estimators\": 500}, {\"test_RMSE\": 43.79612701810125, \"train_RMSE\": 0.0205895831809294, \"RMSE_diff\": 43.775537434920324, \"mod_n_estimators\": 500}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-cefee98126d74fe5a80b48746cd15f26.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-cefee98126d74fe5a80b48746cd15f26.vega-embed details,\n",
       "  #altair-viz-cefee98126d74fe5a80b48746cd15f26.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-cefee98126d74fe5a80b48746cd15f26\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-cefee98126d74fe5a80b48746cd15f26\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-cefee98126d74fe5a80b48746cd15f26\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-2cfe498156ca2ba0c9f4522e6126041e\"}, \"mark\": {\"type\": \"point\"}, \"encoding\": {\"color\": {\"field\": \"mod_learning_rate\", \"type\": \"nominal\"}, \"shape\": {\"field\": \"mod_learning_rate\", \"type\": \"nominal\"}, \"x\": {\"field\": \"test_RMSE\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"field\": \"RMSE_diff\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-2cfe498156ca2ba0c9f4522e6126041e\": [{\"test_RMSE\": 42.94889308864739, \"train_RMSE\": 38.45820271910945, \"RMSE_diff\": 4.490690369537937, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 42.64469343044005, \"train_RMSE\": 38.30207562066866, \"RMSE_diff\": 4.34261780977139, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 42.51578543771746, \"train_RMSE\": 38.20426944923785, \"RMSE_diff\": 4.311515988479613, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 42.45577863013835, \"train_RMSE\": 38.08341005294838, \"RMSE_diff\": 4.372368577189967, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 39.388162630148784, \"train_RMSE\": 35.60166808377512, \"RMSE_diff\": 3.7864945463736674, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 38.76730816041604, \"train_RMSE\": 35.300599663541306, \"RMSE_diff\": 3.4667084968747375, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 38.518095088631, \"train_RMSE\": 35.10667506209064, \"RMSE_diff\": 3.4114200265403625, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 38.38501013773397, \"train_RMSE\": 34.86105736687048, \"RMSE_diff\": 3.523952770863488, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 32.033405240345104, \"train_RMSE\": 28.828551561632462, \"RMSE_diff\": 3.2048536787126416, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 31.07372668528954, \"train_RMSE\": 28.17709153440521, \"RMSE_diff\": 2.896635150884329, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 30.49902590170546, \"train_RMSE\": 27.666355692408317, \"RMSE_diff\": 2.8326702092971416, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 30.567545882140543, \"train_RMSE\": 27.02660969184937, \"RMSE_diff\": 3.5409361902911733, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 27.942005868729733, \"train_RMSE\": 21.940636342392484, \"RMSE_diff\": 6.00136952633725, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 27.413535836268785, \"train_RMSE\": 20.97827719864343, \"RMSE_diff\": 6.435258637625356, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 27.32156158272152, \"train_RMSE\": 19.912369004442954, \"RMSE_diff\": 7.409192578278567, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 27.841820896907542, \"train_RMSE\": 18.536480107537205, \"RMSE_diff\": 9.305340789370337, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 30.214896118356005, \"train_RMSE\": 16.837793354547735, \"RMSE_diff\": 13.37710276380827, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 30.92978967025571, \"train_RMSE\": 15.611314364625043, \"RMSE_diff\": 15.318475305630665, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 32.174774323482545, \"train_RMSE\": 13.651546249637349, \"RMSE_diff\": 18.523228073845196, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 32.64949289208776, \"train_RMSE\": 10.98725334672805, \"RMSE_diff\": 21.662239545359707, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 32.61721456565814, \"train_RMSE\": 15.666793549545613, \"RMSE_diff\": 16.950421016112525, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 34.26979279509076, \"train_RMSE\": 14.027706293829318, \"RMSE_diff\": 20.24208650126144, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 35.61341048124254, \"train_RMSE\": 11.457755508794378, \"RMSE_diff\": 24.15565497244816, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 36.18102641198628, \"train_RMSE\": 8.390611715828653, \"RMSE_diff\": 27.790414696157626, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 34.74881353169465, \"train_RMSE\": 15.004334530706306, \"RMSE_diff\": 19.744479000988346, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 37.27706825986567, \"train_RMSE\": 12.740248187605244, \"RMSE_diff\": 24.536820072260426, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 38.16578691430095, \"train_RMSE\": 9.255498207535268, \"RMSE_diff\": 28.910288706765684, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 38.50710735912418, \"train_RMSE\": 5.926443864668889, \"RMSE_diff\": 32.58066349445529, \"mod_learning_rate\": 0.01}, {\"test_RMSE\": 31.94412161412375, \"train_RMSE\": 28.63239595912083, \"RMSE_diff\": 3.311725655002917, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 30.784299843149583, \"train_RMSE\": 27.98627273270431, \"RMSE_diff\": 2.798027110445272, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 30.27820940950041, \"train_RMSE\": 27.467333180683525, \"RMSE_diff\": 2.810876228816884, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 30.489072119085197, \"train_RMSE\": 26.804479673825544, \"RMSE_diff\": 3.6845924452596535, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 27.97262824873041, \"train_RMSE\": 21.755008272537584, \"RMSE_diff\": 6.217619976192825, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 27.49182979016832, \"train_RMSE\": 20.78617760646744, \"RMSE_diff\": 6.705652183700881, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 27.197247119915783, \"train_RMSE\": 19.68532888723905, \"RMSE_diff\": 7.511918232676734, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 28.22147527869969, \"train_RMSE\": 18.259883725670758, \"RMSE_diff\": 9.961591553028931, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 31.57783587686829, \"train_RMSE\": 16.044330363712326, \"RMSE_diff\": 15.533505513155962, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 32.86882370146414, \"train_RMSE\": 14.560205259585135, \"RMSE_diff\": 18.308618441879002, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 34.14911099498624, \"train_RMSE\": 12.355357553028638, \"RMSE_diff\": 21.7937534419576, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 35.16813376125395, \"train_RMSE\": 9.441080525151284, \"RMSE_diff\": 25.727053236102662, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 34.82117565108924, \"train_RMSE\": 15.003041565500522, \"RMSE_diff\": 19.818134085588717, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 36.90907066405634, \"train_RMSE\": 12.71745597676729, \"RMSE_diff\": 24.191614687289047, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 38.182546752483816, \"train_RMSE\": 9.213801493746343, \"RMSE_diff\": 28.96874525873747, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 38.867804513310325, \"train_RMSE\": 5.906621797549837, \"RMSE_diff\": 32.961182715760486, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 36.88023587126432, \"train_RMSE\": 14.13884939123692, \"RMSE_diff\": 22.741386480027398, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 39.01305653323575, \"train_RMSE\": 10.635668589161211, \"RMSE_diff\": 28.377387944074535, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 39.67701794745211, \"train_RMSE\": 6.348310859186067, \"RMSE_diff\": 33.32870708826604, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 40.47469469014997, \"train_RMSE\": 2.700688556189046, \"RMSE_diff\": 37.774006133960924, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 38.46989154720325, \"train_RMSE\": 13.381419344321806, \"RMSE_diff\": 25.08847220288144, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 40.959442704731806, \"train_RMSE\": 9.098649042141194, \"RMSE_diff\": 31.860793662590613, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 41.48325091485719, \"train_RMSE\": 4.667050612951319, \"RMSE_diff\": 36.816200301905866, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 40.909241082384256, \"train_RMSE\": 1.6686898356653677, \"RMSE_diff\": 39.24055124671889, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 40.99841120590103, \"train_RMSE\": 12.242078079410328, \"RMSE_diff\": 28.756333126490702, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 44.28541881457093, \"train_RMSE\": 7.035742117555873, \"RMSE_diff\": 37.24967669701506, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 42.90926694671622, \"train_RMSE\": 2.87541530617097, \"RMSE_diff\": 40.03385164054525, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 41.60493851847616, \"train_RMSE\": 0.8414117289088833, \"RMSE_diff\": 40.76352678956728, \"mod_learning_rate\": 0.05}, {\"test_RMSE\": 27.892715274653337, \"train_RMSE\": 21.557352707006416, \"RMSE_diff\": 6.335362567646921, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 27.483473617011573, \"train_RMSE\": 20.540194885603352, \"RMSE_diff\": 6.9432787314082205, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 27.49718755633946, \"train_RMSE\": 19.424669187796606, \"RMSE_diff\": 8.072518368542852, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 27.92144131075555, \"train_RMSE\": 18.023806661792328, \"RMSE_diff\": 9.897634648963223, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 30.45551883497358, \"train_RMSE\": 16.702052726479486, \"RMSE_diff\": 13.753466108494095, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 31.460339890938965, \"train_RMSE\": 15.398080291006483, \"RMSE_diff\": 16.06225959993248, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 32.240726219261525, \"train_RMSE\": 13.352085315015623, \"RMSE_diff\": 18.888640904245904, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 33.000359569028554, \"train_RMSE\": 10.703173312610298, \"RMSE_diff\": 22.297186256418257, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 34.93820433675725, \"train_RMSE\": 15.044248216088013, \"RMSE_diff\": 19.893956120669237, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 37.24834507656719, \"train_RMSE\": 12.756372250923972, \"RMSE_diff\": 24.491972825643217, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 38.834421742776975, \"train_RMSE\": 9.109152327790524, \"RMSE_diff\": 29.72526941498645, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 38.52699794081104, \"train_RMSE\": 5.868757254534083, \"RMSE_diff\": 32.65824068627696, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 36.77430551569913, \"train_RMSE\": 14.120902539045094, \"RMSE_diff\": 22.65340297665404, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 39.44063965553556, \"train_RMSE\": 10.63115662269686, \"RMSE_diff\": 28.809483032838703, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 40.86504432665169, \"train_RMSE\": 6.263062275163999, \"RMSE_diff\": 34.601982051487695, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 40.19043723384565, \"train_RMSE\": 2.8211922271739405, \"RMSE_diff\": 37.36924500667171, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 40.3238567683295, \"train_RMSE\": 12.79625641208029, \"RMSE_diff\": 27.52760035624921, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 41.91332338419736, \"train_RMSE\": 8.008209424452748, \"RMSE_diff\": 33.90511395974461, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 42.73016789382323, \"train_RMSE\": 3.4868711717223304, \"RMSE_diff\": 39.2432967221009, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 41.27882596345084, \"train_RMSE\": 1.188423662311766, \"RMSE_diff\": 40.09040230113908, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 42.67551615254095, \"train_RMSE\": 11.66467390136136, \"RMSE_diff\": 31.01084225117959, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 44.094895960238894, \"train_RMSE\": 6.240116119111558, \"RMSE_diff\": 37.85477984112734, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 44.33886949277768, \"train_RMSE\": 2.3110778473607767, \"RMSE_diff\": 42.027791645416904, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 41.08217454560869, \"train_RMSE\": 0.7073208700508276, \"RMSE_diff\": 40.37485367555786, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 47.18387520380126, \"train_RMSE\": 10.195414232789387, \"RMSE_diff\": 36.98846097101187, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 46.95272892694504, \"train_RMSE\": 4.385173996074999, \"RMSE_diff\": 42.567554930870045, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 45.63597300016762, \"train_RMSE\": 1.3207119241854892, \"RMSE_diff\": 44.31526107598213, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 41.82824622635642, \"train_RMSE\": 0.3334901487803306, \"RMSE_diff\": 41.49475607757609, \"mod_learning_rate\": 0.1}, {\"test_RMSE\": 31.01004769616233, \"train_RMSE\": 16.580801523491964, \"RMSE_diff\": 14.429246172670368, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 32.07235305600344, \"train_RMSE\": 15.294029203238988, \"RMSE_diff\": 16.778323852764455, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 33.65378502687985, \"train_RMSE\": 13.396511777971488, \"RMSE_diff\": 20.257273248908362, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 33.308621944436844, \"train_RMSE\": 10.522724287766412, \"RMSE_diff\": 22.785897656670432, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 34.43568091079783, \"train_RMSE\": 15.291399840473057, \"RMSE_diff\": 19.144281070324773, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 37.151380611911655, \"train_RMSE\": 13.110675282133329, \"RMSE_diff\": 24.040705329778326, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 39.6055859208646, \"train_RMSE\": 9.856561374494342, \"RMSE_diff\": 29.749024546370258, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 37.72121235609684, \"train_RMSE\": 6.858763095589984, \"RMSE_diff\": 30.862449260506857, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 36.85677137836302, \"train_RMSE\": 14.240754836971057, \"RMSE_diff\": 22.616016541391964, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 38.86244617285552, \"train_RMSE\": 10.50279923643236, \"RMSE_diff\": 28.35964693642316, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 42.01923120870335, \"train_RMSE\": 6.094634297582394, \"RMSE_diff\": 35.92459691112096, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 39.366077402841725, \"train_RMSE\": 2.981819428531353, \"RMSE_diff\": 36.38425797431037, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 40.15788632289421, \"train_RMSE\": 12.66313517773856, \"RMSE_diff\": 27.494751145155647, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 43.37128871628013, \"train_RMSE\": 7.612202247127737, \"RMSE_diff\": 35.75908646915239, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 45.25921674102347, \"train_RMSE\": 3.370407113952429, \"RMSE_diff\": 41.88880962707104, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 41.17779382834484, \"train_RMSE\": 1.3578186894389876, \"RMSE_diff\": 39.81997513890585, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 44.37727362999775, \"train_RMSE\": 10.89340668075934, \"RMSE_diff\": 33.48386694923841, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 46.12382571739624, \"train_RMSE\": 4.907654047181151, \"RMSE_diff\": 41.21617167021508, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 45.40584663152949, \"train_RMSE\": 1.7235185328686673, \"RMSE_diff\": 43.682328098660825, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 40.633899944626, \"train_RMSE\": 0.5481182330433138, \"RMSE_diff\": 40.08578171158269, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 48.01411550604022, \"train_RMSE\": 9.762611514691857, \"RMSE_diff\": 38.251503991348365, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 47.7671572189292, \"train_RMSE\": 3.563831358695788, \"RMSE_diff\": 44.20332586023341, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 47.66196589848863, \"train_RMSE\": 1.1096766527289912, \"RMSE_diff\": 46.55228924575964, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 43.136191206020655, \"train_RMSE\": 0.313918898892976, \"RMSE_diff\": 42.822272307127676, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 52.99164314299181, \"train_RMSE\": 8.071040225133169, \"RMSE_diff\": 44.920602917858645, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 49.53768660677706, \"train_RMSE\": 2.30108146751227, \"RMSE_diff\": 47.23660513926479, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 47.87584679267601, \"train_RMSE\": 0.6031784800011867, \"RMSE_diff\": 47.272668312674824, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 40.79760519033674, \"train_RMSE\": 0.1408909343802732, \"RMSE_diff\": 40.656714255956466, \"mod_learning_rate\": 0.2}, {\"test_RMSE\": 33.76078067091748, \"train_RMSE\": 15.710244547874508, \"RMSE_diff\": 18.050536123042967, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 34.947736317863075, \"train_RMSE\": 14.00235015410344, \"RMSE_diff\": 20.945386163759636, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 36.8154202616199, \"train_RMSE\": 11.276927168244676, \"RMSE_diff\": 25.538493093375223, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 36.97654632975085, \"train_RMSE\": 8.042900742162198, \"RMSE_diff\": 28.933645587588657, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 35.662496588767674, \"train_RMSE\": 14.966115749243713, \"RMSE_diff\": 20.69638083952396, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 39.21740387192585, \"train_RMSE\": 12.346149745105688, \"RMSE_diff\": 26.871254126820165, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 39.35887864323041, \"train_RMSE\": 8.543514971500707, \"RMSE_diff\": 30.815363671729706, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 40.28661298169107, \"train_RMSE\": 4.763818763674365, \"RMSE_diff\": 35.522794218016706, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 38.45049076916623, \"train_RMSE\": 13.550314402823716, \"RMSE_diff\": 24.900176366342514, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 42.88837244619527, \"train_RMSE\": 8.979068194191875, \"RMSE_diff\": 33.909304252003395, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 42.32978355233755, \"train_RMSE\": 4.51375601490211, \"RMSE_diff\": 37.816027537435446, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 39.992318916914776, \"train_RMSE\": 1.84571316715668, \"RMSE_diff\": 38.146605749758095, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 42.05497696362241, \"train_RMSE\": 11.855999867588087, \"RMSE_diff\": 30.19897709603432, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 47.40338487539671, \"train_RMSE\": 6.258498366428537, \"RMSE_diff\": 41.14488650896817, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 44.65307604428534, \"train_RMSE\": 2.485606887770064, \"RMSE_diff\": 42.16746915651528, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 40.37186167035844, \"train_RMSE\": 0.8524245026740974, \"RMSE_diff\": 39.519437167684345, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 46.28182809890174, \"train_RMSE\": 9.73398988858146, \"RMSE_diff\": 36.54783821032028, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 53.0276466450656, \"train_RMSE\": 3.728239864296169, \"RMSE_diff\": 49.29940678076943, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 45.24524623433504, \"train_RMSE\": 1.2486780990471569, \"RMSE_diff\": 43.99656813528789, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 41.789996798812695, \"train_RMSE\": 0.3801247855382505, \"RMSE_diff\": 41.409872013274445, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 49.89771044301331, \"train_RMSE\": 8.498537124938789, \"RMSE_diff\": 41.39917331807452, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 55.462744113961264, \"train_RMSE\": 2.734313301502949, \"RMSE_diff\": 52.72843081245831, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 45.96077061107357, \"train_RMSE\": 0.7897557076894919, \"RMSE_diff\": 45.171014903384076, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 43.20626858745009, \"train_RMSE\": 0.1974462144015288, \"RMSE_diff\": 43.00882237304856, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 55.44735715919694, \"train_RMSE\": 6.722110914912429, \"RMSE_diff\": 48.72524624428451, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 55.89074765214684, \"train_RMSE\": 1.697052493902897, \"RMSE_diff\": 54.19369515824395, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 46.992781356660274, \"train_RMSE\": 0.4002568202041505, \"RMSE_diff\": 46.592524536456125, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 43.92645271333736, \"train_RMSE\": 0.0729207982109905, \"RMSE_diff\": 43.853531915126375, \"mod_learning_rate\": 0.3}, {\"test_RMSE\": 35.70560880094571, \"train_RMSE\": 15.24282488522042, \"RMSE_diff\": 20.46278391572529, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 37.29445289678224, \"train_RMSE\": 13.392437808187964, \"RMSE_diff\": 23.902015088594275, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 38.91950430504996, \"train_RMSE\": 10.24091206254316, \"RMSE_diff\": 28.678592242506802, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 41.68178570481863, \"train_RMSE\": 6.706030776368682, \"RMSE_diff\": 34.975754928449945, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 37.97276573171551, \"train_RMSE\": 14.436136822081997, \"RMSE_diff\": 23.536628909633514, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 39.73250234189891, \"train_RMSE\": 11.472537791874396, \"RMSE_diff\": 28.259964550024513, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 39.61941309407715, \"train_RMSE\": 7.33508221624555, \"RMSE_diff\": 32.2843308778316, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 40.22369207161424, \"train_RMSE\": 3.311298387044699, \"RMSE_diff\": 36.91239368456954, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 42.859213541052576, \"train_RMSE\": 12.783750154907338, \"RMSE_diff\": 30.075463386145238, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 45.239958138813535, \"train_RMSE\": 7.888277318339999, \"RMSE_diff\": 37.35168082047353, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 44.26220916190682, \"train_RMSE\": 3.665759378515761, \"RMSE_diff\": 40.59644978339106, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 43.41509310572607, \"train_RMSE\": 1.477666552019715, \"RMSE_diff\": 41.93742655370636, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 45.024522564365405, \"train_RMSE\": 11.014726661863335, \"RMSE_diff\": 34.00979590250207, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 51.320499213532216, \"train_RMSE\": 5.418690906585499, \"RMSE_diff\": 45.90180830694672, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 43.74829444215074, \"train_RMSE\": 1.9885340837486092, \"RMSE_diff\": 41.759760358402126, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 42.86169880565249, \"train_RMSE\": 0.7135977760515897, \"RMSE_diff\": 42.148101029600895, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 51.33588786755062, \"train_RMSE\": 8.908911778725596, \"RMSE_diff\": 42.42697608882502, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 57.30414494665901, \"train_RMSE\": 3.3048863575061467, \"RMSE_diff\": 53.99925858915286, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 48.657383647733866, \"train_RMSE\": 1.042026754127889, \"RMSE_diff\": 47.61535689360598, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 44.423387870540125, \"train_RMSE\": 0.2804006351190549, \"RMSE_diff\": 44.14298723542107, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 56.08304596209091, \"train_RMSE\": 7.6066335865564465, \"RMSE_diff\": 48.47641237553446, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 58.81992356005533, \"train_RMSE\": 2.3232427093336514, \"RMSE_diff\": 56.49668085072168, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 44.12097224789523, \"train_RMSE\": 0.5979014824521369, \"RMSE_diff\": 43.523070765443094, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 42.35487889466184, \"train_RMSE\": 0.1406107966197421, \"RMSE_diff\": 42.2142680980421, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 61.914605270207446, \"train_RMSE\": 5.855324128525549, \"RMSE_diff\": 56.05928114168189, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 58.96039346927974, \"train_RMSE\": 1.4147162761818353, \"RMSE_diff\": 57.5456771930979, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 47.288264924605045, \"train_RMSE\": 0.2767244443766223, \"RMSE_diff\": 47.011540480228426, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 44.17252080076839, \"train_RMSE\": 0.0400990076618962, \"RMSE_diff\": 44.132421793106495, \"mod_learning_rate\": 0.4}, {\"test_RMSE\": 36.108067356649165, \"train_RMSE\": 15.138177641234485, \"RMSE_diff\": 20.96988971541468, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 36.96402031397315, \"train_RMSE\": 13.274698598999844, \"RMSE_diff\": 23.689321714973307, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 39.61468964518344, \"train_RMSE\": 9.680381590382408, \"RMSE_diff\": 29.93430805480103, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 43.56944535044478, \"train_RMSE\": 5.667053396848618, \"RMSE_diff\": 37.902391953596165, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 39.30111148121991, \"train_RMSE\": 14.356607142918543, \"RMSE_diff\": 24.94450433830137, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 41.19289901724105, \"train_RMSE\": 10.843494371254126, \"RMSE_diff\": 30.349404645986922, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 42.97156294276687, \"train_RMSE\": 6.469608670818438, \"RMSE_diff\": 36.501954271948435, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 44.04951355564291, \"train_RMSE\": 2.989631784104331, \"RMSE_diff\": 41.05988177153858, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 41.97596016230101, \"train_RMSE\": 12.461261002446774, \"RMSE_diff\": 29.51469915985423, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 49.53805939219268, \"train_RMSE\": 7.387989399281962, \"RMSE_diff\": 42.150069992910716, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 44.87620459341979, \"train_RMSE\": 3.272922865912332, \"RMSE_diff\": 41.60328172750746, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 46.64218502586418, \"train_RMSE\": 1.2954522506773016, \"RMSE_diff\": 45.34673277518688, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 45.26143073063649, \"train_RMSE\": 10.65120351593541, \"RMSE_diff\": 34.610227214701084, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 58.39079536164876, \"train_RMSE\": 4.916567853844308, \"RMSE_diff\": 53.47422750780446, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 47.22872883604619, \"train_RMSE\": 1.7048584208722195, \"RMSE_diff\": 45.52387041517397, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 44.136239202997245, \"train_RMSE\": 0.6365822435665186, \"RMSE_diff\": 43.49965695943073, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 50.602974238184345, \"train_RMSE\": 8.356134237685648, \"RMSE_diff\": 42.24684000049869, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 62.02367671483597, \"train_RMSE\": 2.9241163420191176, \"RMSE_diff\": 59.09956037281685, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 50.92242572027043, \"train_RMSE\": 0.8791638285520422, \"RMSE_diff\": 50.04326189171839, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 46.60160640052594, \"train_RMSE\": 0.2181455338050191, \"RMSE_diff\": 46.38346086672092, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 53.01432515279015, \"train_RMSE\": 7.000546697865994, \"RMSE_diff\": 46.01377845492416, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 64.42691678582563, \"train_RMSE\": 2.12249709221665, \"RMSE_diff\": 62.30441969360898, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 48.92755627312404, \"train_RMSE\": 0.5019550390915235, \"RMSE_diff\": 48.42560123403251, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 46.73381631145846, \"train_RMSE\": 0.0922375885215072, \"RMSE_diff\": 46.641578722936956, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 59.628465959989136, \"train_RMSE\": 5.298901478551345, \"RMSE_diff\": 54.32956448143779, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 63.17103408245477, \"train_RMSE\": 1.2392468604278224, \"RMSE_diff\": 61.93178722202695, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 49.62494287751727, \"train_RMSE\": 0.2082736470548865, \"RMSE_diff\": 49.41666923046238, \"mod_learning_rate\": 0.5}, {\"test_RMSE\": 43.79612701810125, \"train_RMSE\": 0.0205895831809294, \"RMSE_diff\": 43.775537434920324, \"mod_learning_rate\": 0.5}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(loops.keys())\n",
    "plot_results(pd.DataFrame(record), list(loops.keys()))\n",
    "\n",
    "display(plot_results(pd.DataFrame(record), ['mod_max_depth']))\n",
    "display(plot_results(pd.DataFrame(record), ['mod_n_estimators']))\n",
    "display(plot_results(pd.DataFrame(record), ['mod_learning_rate']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9e3b69",
   "metadata": {},
   "source": [
    "A table of the most recent results was viewed below, sorted by test RMSE or train/test performance difference. Only the fields that changed with each iterations are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "95e8783c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_RMSE</th>\n",
       "      <th>train_RMSE</th>\n",
       "      <th>RMSE_diff</th>\n",
       "      <th>mod_learning_rate</th>\n",
       "      <th>mod_n_estimators</th>\n",
       "      <th>mod_max_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.784300</td>\n",
       "      <td>27.986273</td>\n",
       "      <td>2.798027</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30.278209</td>\n",
       "      <td>27.467333</td>\n",
       "      <td>2.810876</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30.499026</td>\n",
       "      <td>27.666356</td>\n",
       "      <td>2.832670</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31.073727</td>\n",
       "      <td>28.177092</td>\n",
       "      <td>2.896635</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32.033405</td>\n",
       "      <td>28.828552</td>\n",
       "      <td>3.204854</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>31.944122</td>\n",
       "      <td>28.632396</td>\n",
       "      <td>3.311726</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38.518095</td>\n",
       "      <td>35.106675</td>\n",
       "      <td>3.411420</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>38.767308</td>\n",
       "      <td>35.300600</td>\n",
       "      <td>3.466708</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>38.385010</td>\n",
       "      <td>34.861057</td>\n",
       "      <td>3.523953</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30.567546</td>\n",
       "      <td>27.026610</td>\n",
       "      <td>3.540936</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_RMSE  train_RMSE  RMSE_diff  mod_learning_rate  mod_n_estimators  \\\n",
       "29  30.784300   27.986273   2.798027               0.05                10   \n",
       "30  30.278209   27.467333   2.810876               0.05                10   \n",
       "10  30.499026   27.666356   2.832670               0.01                50   \n",
       "9   31.073727   28.177092   2.896635               0.01                50   \n",
       "8   32.033405   28.828552   3.204854               0.01                50   \n",
       "28  31.944122   28.632396   3.311726               0.05                10   \n",
       "6   38.518095   35.106675   3.411420               0.01                20   \n",
       "5   38.767308   35.300600   3.466708               0.01                20   \n",
       "7   38.385010   34.861057   3.523953               0.01                20   \n",
       "11  30.567546   27.026610   3.540936               0.01                50   \n",
       "\n",
       "    mod_max_depth  \n",
       "29              5  \n",
       "30              7  \n",
       "10              7  \n",
       "9               5  \n",
       "8               3  \n",
       "28              3  \n",
       "6               7  \n",
       "5               5  \n",
       "7               9  \n",
       "11              9  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = show_df_of_results(pd.DataFrame(record), list(loops.keys()))\n",
    "# df = df[abs(df[\"RMSE_diff\"]) < 0.5].sort_values(\"RMSE_diff\")\n",
    "df = df.sort_values(\"RMSE_diff\")[0:10]\n",
    "# df.sort_values(\"test_RMSE\")[0:10]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ae72ac",
   "metadata": {},
   "source": [
    "The cell below was used to <b>initialize</b> the performance log CSV. This cell should not be uncommented unless the user wants to initialize a new log file for looping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2dcb00ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the log with the first tuning group. \n",
    "#FILENAME REMOVED - DO NOT OVERWRITE LOG!\n",
    "\n",
    "# df = pd.DataFrame(record)\n",
    "\n",
    "# df.insert(0, \"tuning_group\", 1)\n",
    "\n",
    "# df.to_csv(\"GBDT_SMOOTH_Data_Log.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269bce39",
   "metadata": {},
   "source": [
    "The below block saves the most recent tuning group to the CSV log. The value for 'tuning_group' is determined based on the last entry into the log. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9bad5c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_to_GBDT_log(record, save_changes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d80e18",
   "metadata": {},
   "source": [
    "The below block is used to explore the entire CSV log to compare results. Also organized by performace/overfitting to find the best parameters to test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "acb0ce19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tuning_group</th>\n",
       "      <th>train_RMSE</th>\n",
       "      <th>test_RMSE</th>\n",
       "      <th>RMSE_diff</th>\n",
       "      <th>scaler</th>\n",
       "      <th>first_window</th>\n",
       "      <th>first_window_type</th>\n",
       "      <th>second_window</th>\n",
       "      <th>second_window_type</th>\n",
       "      <th>mod_loss</th>\n",
       "      <th>mod_learning_rate</th>\n",
       "      <th>mod_n_estimators</th>\n",
       "      <th>mod_subsample</th>\n",
       "      <th>mod_max_depth</th>\n",
       "      <th>mod_validation</th>\n",
       "      <th>num_features</th>\n",
       "      <th>train_samples_dropped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>19.685329</td>\n",
       "      <td>27.197247</td>\n",
       "      <td>7.511918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>avg</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>0.05</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>19.912369</td>\n",
       "      <td>27.321562</td>\n",
       "      <td>7.409193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>avg</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>20.978277</td>\n",
       "      <td>27.413536</td>\n",
       "      <td>6.435259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>avg</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1</td>\n",
       "      <td>20.540195</td>\n",
       "      <td>27.483474</td>\n",
       "      <td>6.943279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>avg</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>20.786178</td>\n",
       "      <td>27.491830</td>\n",
       "      <td>6.705652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>avg</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>0.05</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>19.424669</td>\n",
       "      <td>27.497188</td>\n",
       "      <td>8.072518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>avg</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>18.536480</td>\n",
       "      <td>27.841821</td>\n",
       "      <td>9.305341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>avg</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1</td>\n",
       "      <td>21.557353</td>\n",
       "      <td>27.892715</td>\n",
       "      <td>6.335363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>avg</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "      <td>18.023807</td>\n",
       "      <td>27.921441</td>\n",
       "      <td>9.897635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>avg</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>21.940636</td>\n",
       "      <td>27.942006</td>\n",
       "      <td>6.001370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>avg</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tuning_group  train_RMSE  test_RMSE  RMSE_diff  scaler  first_window  \\\n",
       "34             1   19.685329  27.197247   7.511918     NaN           NaN   \n",
       "14             1   19.912369  27.321562   7.409193     NaN           NaN   \n",
       "13             1   20.978277  27.413536   6.435259     NaN           NaN   \n",
       "57             1   20.540195  27.483474   6.943279     NaN           NaN   \n",
       "33             1   20.786178  27.491830   6.705652     NaN           NaN   \n",
       "58             1   19.424669  27.497188   8.072518     NaN           NaN   \n",
       "15             1   18.536480  27.841821   9.305341     NaN           NaN   \n",
       "56             1   21.557353  27.892715   6.335363     NaN           NaN   \n",
       "59             1   18.023807  27.921441   9.897635     NaN           NaN   \n",
       "12             1   21.940636  27.942006   6.001370     NaN           NaN   \n",
       "\n",
       "   first_window_type  second_window second_window_type       mod_loss  \\\n",
       "34               abs            NaN                avg  squared_error   \n",
       "14               abs            NaN                avg  squared_error   \n",
       "13               abs            NaN                avg  squared_error   \n",
       "57               abs            NaN                avg  squared_error   \n",
       "33               abs            NaN                avg  squared_error   \n",
       "58               abs            NaN                avg  squared_error   \n",
       "15               abs            NaN                avg  squared_error   \n",
       "56               abs            NaN                avg  squared_error   \n",
       "59               abs            NaN                avg  squared_error   \n",
       "12               abs            NaN                avg  squared_error   \n",
       "\n",
       "    mod_learning_rate  mod_n_estimators  mod_subsample  mod_max_depth  \\\n",
       "34               0.05                20            1.0              7   \n",
       "14               0.01               100            1.0              7   \n",
       "13               0.01               100            1.0              5   \n",
       "57               0.10                10            1.0              5   \n",
       "33               0.05                20            1.0              5   \n",
       "58               0.10                10            1.0              7   \n",
       "15               0.01               100            1.0              9   \n",
       "56               0.10                10            1.0              3   \n",
       "59               0.10                10            1.0              9   \n",
       "12               0.01               100            1.0              3   \n",
       "\n",
       "    mod_validation  num_features  train_samples_dropped  \n",
       "34             NaN            14                      0  \n",
       "14             NaN            14                      0  \n",
       "13             NaN            14                      0  \n",
       "57             NaN            14                      0  \n",
       "33             NaN            14                      0  \n",
       "58             NaN            14                      0  \n",
       "15             NaN            14                      0  \n",
       "56             NaN            14                      0  \n",
       "59             NaN            14                      0  \n",
       "12             NaN            14                      0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"GBDT_SMOOTH_Data_Log.csv\")\n",
    "\n",
    "##USE CTRL + \"/\" TO COMMENT OUT FIELDS\n",
    "df = df[[ 'tuning_group',\n",
    "#          'train_MSE', \n",
    "#          'test_MSE', \n",
    "         'train_RMSE', \n",
    "         'test_RMSE', \n",
    "#          'train_MAE', \n",
    "#          'test_MAE', \n",
    "#          'train_MAPE', \n",
    "#          'test_MAPE', \n",
    "#          'train_R2', \n",
    "#          'test_R2', \n",
    "         'scaler',\n",
    "         'first_window', \n",
    "         'first_window_type', \n",
    "         'second_window',\n",
    "         'second_window_type', \n",
    "#          'drop_nan_train', \n",
    "#          'min_periods', \n",
    "         'mod_loss',\n",
    "         'mod_learning_rate', \n",
    "         'mod_n_estimators', \n",
    "         'mod_subsample',\n",
    "#          'mod_min_samples_split',\n",
    "#          'mod_min_samples_leaf', \n",
    "         'mod_max_depth',\n",
    "         'mod_validation', \n",
    "         'num_features', \n",
    "         'train_samples_dropped'\n",
    "        ]]\n",
    "df.insert(3, \"RMSE_diff\", df[\"test_RMSE\"] - df[\"train_RMSE\"])\n",
    "pd.set_option('display.max_rows', None)\n",
    "#df = df.sort_values(\"test_RMSE\").reset_index(drop = True)[:20]\n",
    "df.sort_values(\"test_RMSE\")[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ff7592",
   "metadata": {},
   "source": [
    "# 4.0 Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d85c13",
   "metadata": {},
   "source": [
    "COMMENT REGARDING SMOOTHED DATA ANALYSIS: Since modeling results in the first tuning group were not promising, this analysis was ceased and no final model was determined. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
